{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trajectories.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurelkeys/machine-learning/blob/master/assignment-4/Trajectories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z29bPFt3BKSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "# PATH_TO_DATA = os.path.join(\"drive\", \"My Drive\", \"unicamp\", \"MC886\", \"atari\")\n",
        "\n",
        "PATH_TO_DATA = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yg8oJkJBPW1",
        "colab_type": "code",
        "outputId": "951acce0-4391-4b7f-b2b2-5dfa45f38304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "SAVE_DIR = os.path.join(PATH_TO_DATA, \"data\")\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "SAVE_DIR # where the trajectories for each game will be saved to"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-pfFDVVBTX6",
        "colab_type": "code",
        "outputId": "61fe583a-80ac-451d-fb74-4acc5002daa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "LOG_DIR = os.path.join(PATH_TO_DATA, \"data\", \"results\")\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "LOG_DIR # where the stats for each game will be saved to"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data/results'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxiF53dtcx5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of trajectories to generate\n",
        "N_OF_TRAJECTORIES = 45\n",
        "\n",
        "# number of steps per trajectory\n",
        "N_OF_STEPS = 1000\n",
        "\n",
        "# list of string tuples in the format (RL Algorithm, Game Environment)\n",
        "GAMES = [\n",
        "    (\"PPO2\", \"BreakoutNoFrameskip-v4\"),\n",
        "    (\"PPO2\", \"PongNoFrameskip-v4\"),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0nFoCbqBlhv",
        "colab_type": "text"
      },
      "source": [
        "## Install dependencies\n",
        "Note that we're not installing [MPI](https://mpi4py.readthedocs.io/en/stable/), so these algorithms will probably not work: `DDPG`, `GAIL`, `PPO1`, `TRPO`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHfq9U0pBpEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get update                                                  > /dev/null 2>&1\n",
        "!apt-get install swig cmake zlib1g-dev ffmpeg freeglut3-dev xvfb > /dev/null 2>&1\n",
        "!pip install pytablewriter                                       > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kObMTO5_BzKK",
        "colab_type": "code",
        "outputId": "18b1eeea-4eea-43af-d1a8-b59ea97c96a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#### Stable Baselines only supports TF 1.x for now ####\n",
        "try:\n",
        "    # Colab only\n",
        "    %tensorflow_version 1.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrzGDVIYB4TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from time import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# NOTE use tqdm.write() instead of print() inside of tqdm wrapped loops\n",
        "from tqdm import tqdm\n",
        "\n",
        "import gym\n",
        "from gym.envs.atari.atari_env import ACTION_MEANING"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtHWjpwKCAqF",
        "colab_type": "text"
      },
      "source": [
        "### Update [Stable Baselines](https://github.com/hill-a/stable-baselines) and clone [RL Zoo Baselines](https://github.com/araffin/rl-baselines-zoo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGg59yj4CCWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!yes | pip uninstall stable-baselines                           > /dev/null 2>&1\n",
        "!pip install git+https://github.com/hill-a/stable-baselines.git > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uoafLRoCEM1",
        "colab_type": "code",
        "outputId": "d606ae87-b223-45fa-9f71-1eeeecba9a4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from stable_baselines.common.cmd_util import make_atari_env\n",
        "from stable_baselines.common.vec_env import VecFrameStack\n",
        "\n",
        "# HACK to save logs\n",
        "from stable_baselines import logger\n",
        "os.environ[\"OPENAI_LOG_FORMAT\"] = 'stdout,log,csv,tensorboard'\n",
        "os.environ[\"OPENAI_LOGDIR\"] = os.path.abspath(LOG_DIR)\n",
        "logger.configure()\n",
        "\n",
        "# NOTE add more algorithms here if you want to use them\n",
        "from stable_baselines import PPO2, ACER, ACKTR\n",
        "ALGO_IMPL = {\n",
        "    'PPO2': PPO2,\n",
        "    'ACER': ACER,\n",
        "    'ACKTR': ACKTR,\n",
        "}"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /content/data/results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMaHETmpCKms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/araffin/rl-baselines-zoo.git > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjB4SzAnCPlT",
        "colab_type": "text"
      },
      "source": [
        "## Load pre-trained agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ9jc42VCVNl",
        "colab_type": "code",
        "outputId": "fff29a49-d71c-48ba-c819-02c4cbae12ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "PATH_TO_AGENTS = os.path.join(\"rl-baselines-zoo\", \"trained_agents\")\n",
        "!ls rl-baselines-zoo/trained_agents/"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a2c  acer  acktr  ddpg\tdqn  her  ppo2\tsac  td3  trpo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKIUEECQCXtB",
        "colab_type": "code",
        "outputId": "90e3f99a-9da2-4caa-917e-37f722b8dc63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "ext = \"NoFrameskip-v4.pkl\"\n",
        "# check the available pre-trained models\n",
        "algorithms = [\"PPO2\"]\n",
        "for algo in algorithms:\n",
        "    algo_path = os.path.join(PATH_TO_AGENTS, algo.lower())\n",
        "    print(algo_path + '/')\n",
        "    for f in sorted(os.listdir(algo_path), key=lambda x: x[::-1]):\n",
        "        # sort by the reverse filename, so env types get grouped together\n",
        "        if f.endswith(ext):\n",
        "            print(\"├──\", f)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rl-baselines-zoo/trained_agents/ppo2/\n",
            "├── PongNoFrameskip-v4.pkl\n",
            "├── MsPacmanNoFrameskip-v4.pkl\n",
            "├── EnduroNoFrameskip-v4.pkl\n",
            "├── BeamRiderNoFrameskip-v4.pkl\n",
            "├── SpaceInvadersNoFrameskip-v4.pkl\n",
            "├── QbertNoFrameskip-v4.pkl\n",
            "├── SeaquestNoFrameskip-v4.pkl\n",
            "├── BreakoutNoFrameskip-v4.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6CwssmOCb9E",
        "colab_type": "code",
        "outputId": "0612705f-75aa-47e8-dc4f-962850e98cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "for i in range(2):\n",
        "    clear_output() # HACK to remove TensorFlow warnings\n",
        "    for algo, env_id in GAMES:\n",
        "        print(f\"('{algo}', '{env_id}')\")\n",
        "        agent_path = os.path.join(PATH_TO_AGENTS, algo.lower(), env_id + '.pkl')\n",
        "        model = ALGO_IMPL[algo].load(agent_path, verbose=0)\n",
        "        print(\"observation_space:\", model.observation_space)\n",
        "        print(\"action_space:\", model.action_space)\n",
        "        print()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('PPO2', 'BreakoutNoFrameskip-v4')\n",
            "observation_space: Box(84, 84, 4)\n",
            "action_space: Discrete(4)\n",
            "\n",
            "('PPO2', 'PongNoFrameskip-v4')\n",
            "observation_space: Box(84, 84, 4)\n",
            "action_space: Discrete(6)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaxY9IxFCyaZ",
        "colab_type": "text"
      },
      "source": [
        "## Generate trajectories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS3Jr8O5C-A-",
        "colab_type": "code",
        "outputId": "e531e71d-47f9-459f-f582-9a25e9fde336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "VERBOSE = 2 # 0, 1 or 2\n",
        "\n",
        "print(\"N_OF_STEPS:\", N_OF_STEPS)\n",
        "print(\"N_OF_TRAJECTORIES:\", N_OF_TRAJECTORIES)\n",
        "print(N_OF_STEPS, \"*\", N_OF_TRAJECTORIES, \"=\", N_OF_STEPS * N_OF_TRAJECTORIES)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N_OF_STEPS: 1000\n",
            "N_OF_TRAJECTORIES: 45\n",
            "1000 * 45 = 45000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls6Uw4PnDAsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGES_FOLDER = \"images\" # name of the folder in which to save the observations\n",
        "FILE_NAME = \"trajectory\" # name of the .npz trajectory file\n",
        "\n",
        "# set to False to save observations as PNG and store their location path, \n",
        "# instead of saving them as numpy arrays (which end up taking more space)\n",
        "SAVE_IMAGES_AS_NUMPY_ARRAYS = False\n",
        "\n",
        "PRINT_EARLY_DONE = False # print env resets in a trajectory\n",
        "PRINT_ACTIONS_TAKEN = True # print the meanings of actions\n",
        "\n",
        "# set to N_OF_TRAJECTORIES + 1 not to print\n",
        "PRINT_EVERY_N_TRAJECTORIES = N_OF_TRAJECTORIES // 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HSnlYyfEDrg",
        "colab_type": "code",
        "outputId": "098239c2-6b40-44f2-88a1-1bdeb32af32f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        }
      },
      "source": [
        "print(\"N_OF_STEPS:\", N_OF_STEPS)\n",
        "print(\"N_OF_TRAJECTORIES:\", N_OF_TRAJECTORIES)\n",
        "print(\"PRINT_EVERY_N_TRAJECTORIES:\", PRINT_EVERY_N_TRAJECTORIES)\n",
        "\n",
        "time_start = time()\n",
        "print(\"\\n================\")\n",
        "\n",
        "for algo, env_id in GAMES:\n",
        "    time_start_env = time()\n",
        "\n",
        "    env = make_atari_env(env_id, num_env=1, seed=0)\n",
        "    env = VecFrameStack(env, n_stack=4) # Frame-stacking with 4 frames\n",
        "    agent_path = os.path.join(PATH_TO_AGENTS, algo.lower(), env_id + '.pkl')\n",
        "\n",
        "    print(f\"('{algo}', '{env_id}')\")\n",
        "    print(f\"Getting pre-trained agent from: '{agent_path}'\\n\")\n",
        "    \n",
        "    # setup paths where data will be saved to\n",
        "    dataset_folder = f\"{env_id}_{algo}_{N_OF_STEPS}steps\"\n",
        "    if not SAVE_IMAGES_AS_NUMPY_ARRAYS:\n",
        "        images_folder = os.path.join(SAVE_DIR, dataset_folder, IMAGES_FOLDER)\n",
        "        os.makedirs(images_folder, exist_ok=True)\n",
        "        if VERBOSE > 0:\n",
        "            print(f\"Images will be recorded to '{images_folder}/'\\n\")\n",
        "\n",
        "    model = ALGO_IMPL[algo].load(agent_path, env)\n",
        "    \n",
        "    for trajectory in tqdm(range(N_OF_TRAJECTORIES), position=0, leave=True):\n",
        "        # store the \"obs -> action\" mapping\n",
        "        observed_states, actions_taken = [], []\n",
        "        \n",
        "        # episode stats\n",
        "        ep_rewards, ep_starts = np.zeros((N_OF_STEPS,)), [True]\n",
        "        \n",
        "        # NOTE action, obs, reward, done and info are \n",
        "        #      arrays as we're using a vectorized env\n",
        "        \n",
        "        obs = env.reset() # (84, 84, 4)\n",
        "        for step in range(N_OF_STEPS):\n",
        "            observed_states.append(obs[0])\n",
        "            action, _ = model.predict(obs)\n",
        "            actions_taken.append(action[0])\n",
        "            obs, reward, done, info = env.step(action)\n",
        "            ep_starts.append(done[0])\n",
        "            ep_rewards[step] = reward[0]\n",
        "            if done[0]:\n",
        "                obs = env.reset()\n",
        "                if PRINT_EARLY_DONE:\n",
        "                    tqdm.write(f\" Done at step {step} (reseting env)\")\n",
        "        \n",
        "        # left pad the trajectory number with 0's\n",
        "        trajectory_number = str(trajectory).zfill(len(str(N_OF_TRAJECTORIES - 1)))\n",
        "\n",
        "        if not SAVE_IMAGES_AS_NUMPY_ARRAYS:\n",
        "            _observed_states = [] # store image paths\n",
        "            for step, obs in enumerate(observed_states):\n",
        "                image_path = os.path.join(images_folder, trajectory_number, f\"{str(step).zfill(len(str(N_OF_STEPS)))}.png\")\n",
        "                os.makedirs(image_path, exist_ok=True)\n",
        "                if obs.shape[-1] == 3:\n",
        "                    obs = cv2.cvtColor(obs, cv2.COLOR_RGB2BGR)\n",
        "                cv2.imwrite(image_path, obs) # , [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
        "                _observed_states.append(image_path)\n",
        "            observed_states = np.array(_observed_states)\n",
        "        else:\n",
        "            observed_states = np.concatenate(observed_states).reshape((-1,) + env.observation_space.shape)\n",
        "\n",
        "        actions_taken = np.array(actions_taken)\n",
        "        ep_starts = np.array(ep_starts[:-1])\n",
        "\n",
        "        data = {\n",
        "            'actions': actions_taken,\n",
        "            'observations': observed_states,\n",
        "            'rewards': ep_rewards,\n",
        "            'episode_starts': ep_starts\n",
        "        } # type: Dict[str, np.ndarray]\n",
        "\n",
        "        save_path = os.path.join(SAVE_DIR, dataset_folder, trajectory_number, FILE_NAME)\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        np.savez_compressed(file=save_path, **data)\n",
        "        \n",
        "        if (trajectory + 1) % 10 == 0:\n",
        "            tqdm.write(f\" Saved trajectory {trajectory + 1} (of {N_OF_TRAJECTORIES})\")\n",
        "            if VERBOSE > 1:\n",
        "                tqdm.write(f\" Mean reward: {np.mean(ep_rewards):.2f}, ep_rewards.shape == {ep_rewards.shape}\")\n",
        "\n",
        "        if PRINT_ACTIONS_TAKEN and trajectory == N_OF_TRAJECTORIES - 1:\n",
        "            tqdm.write(f\"\\n Actions taken: {', '.join([ACTION_MEANING[action] for action in set(actions_taken)])}\")\n",
        "    \n",
        "    env.close()\n",
        "    print(f\" Δt = {(time() - time_start_env):.2f}s\")\n",
        "    print(\"================\\n\")\n",
        "\n",
        "print(f\"Total Δt = {(time() - time_start):.2f}s\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N_OF_STEPS: 1000\n",
            "N_OF_TRAJECTORIES: 45\n",
            "PRINT_EVERY_N_TRAJECTORIES: 4\n",
            "\n",
            "================\n",
            "('PPO2', 'BreakoutNoFrameskip-v4')\n",
            "Getting pre-trained agent from: 'rl-baselines-zoo/trained_agents/ppo2/BreakoutNoFrameskip-v4.pkl'\n",
            "\n",
            "Images will be recorded to 'data/BreakoutNoFrameskip-v4_PPO2_1000steps/images/'\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 10/45 [00:45<02:38,  4.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Saved trajectory 10 (of 45)\n",
            " Mean reward: 0.03, ep_rewards.shape == (1000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 20/45 [01:31<01:52,  4.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Saved trajectory 20 (of 45)\n",
            " Mean reward: 0.06, ep_rewards.shape == (1000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 30/45 [02:16<01:06,  4.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Saved trajectory 30 (of 45)\n",
            " Mean reward: 0.06, ep_rewards.shape == (1000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 40/45 [03:01<00:22,  4.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Saved trajectory 40 (of 45)\n",
            " Mean reward: 0.05, ep_rewards.shape == (1000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [03:24<00:00,  4.60s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Actions taken: NOOP, FIRE, UP, RIGHT\n",
            " Δt = 206.14s\n",
            "================\n",
            "\n",
            "('PPO2', 'PongNoFrameskip-v4')\n",
            "Getting pre-trained agent from: 'rl-baselines-zoo/trained_agents/ppo2/PongNoFrameskip-v4.pkl'\n",
            "\n",
            "Images will be recorded to 'data/PongNoFrameskip-v4_PPO2_1000steps/images/'\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 10/45 [00:46<02:45,  4.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Saved trajectory 10 (of 45)\n",
            " Mean reward: 0.01, ep_rewards.shape == (1000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 20/45 [01:37<02:04,  4.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Saved trajectory 20 (of 45)\n",
            " Mean reward: 0.01, ep_rewards.shape == (1000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 30/45 [02:35<01:28,  5.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Saved trajectory 30 (of 45)\n",
            " Mean reward: 0.01, ep_rewards.shape == (1000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 40/45 [03:32<00:26,  5.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Saved trajectory 40 (of 45)\n",
            " Mean reward: 0.01, ep_rewards.shape == (1000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [04:00<00:00,  5.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Actions taken: NOOP, FIRE, UP, RIGHT, LEFT, DOWN\n",
            " Δt = 242.02s\n",
            "================\n",
            "\n",
            "Total Δt = 448.16s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n6nR9pJjmg4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1ddd20e3-c196-4b25-bb44-a9c3f2065d27"
      },
      "source": [
        "!ls /content/data"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BreakoutNoFrameskip-v4_PPO2_1000steps  results\n",
            "PongNoFrameskip-v4_PPO2_1000steps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF4usP_fhpg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/data.zip /content/data > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q26xcGsWkME6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5d24c76e-0f5a-40eb-8332-d8b0ec31b9b9"
      },
      "source": [
        "!ls -la | grep .zip\n",
        "!ls -lh | grep .zip"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r--  1 root root 24072140 Dec  3 02:23 data.zip\n",
            "-rw-r--r--  1 root root  23M Dec  3 02:23 data.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phjtQowPGHqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWqkjFZ0k8a5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"/content/data.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txkWJnDElQbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# larger files may not work, try looking at:\n",
        "# https://stackoverflow.com/questions/49428332/how-to-download-large-files-like-weights-of-a-model-from-colaboratory"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}