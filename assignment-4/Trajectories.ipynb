{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trajectories.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurelkeys/machine-learning/blob/master/assignment-4/Trajectories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z29bPFt3BKSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "# PATH_TO_DATA = os.path.join(\"drive\", \"My Drive\", \"unicamp\", \"MC886\", \"atari\")\n",
        "\n",
        "PATH_TO_DATA = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yg8oJkJBPW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAVE_DIR = os.path.join(PATH_TO_DATA, \"data\")\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "SAVE_DIR # where the trajectories for each game will be saved to"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-pfFDVVBTX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = os.path.join(PATH_TO_DATA, \"data\", \"results\")\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "LOG_DIR # where the stats for each game will be saved to"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxiF53dtcx5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of trajectories to generate\n",
        "N_OF_TRAJECTORIES = 45\n",
        "\n",
        "# number of steps per trajectory\n",
        "N_OF_STEPS = 1000\n",
        "\n",
        "# list of string tuples in the format (RL Algorithm, Game Environment)\n",
        "GAMES = [\n",
        "    (\"PPO2\", \"BreakoutNoFrameskip-v4\"),\n",
        "    (\"PPO2\", \"PongNoFrameskip-v4\"),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0nFoCbqBlhv",
        "colab_type": "text"
      },
      "source": [
        "## Install dependencies\n",
        "Note that we're not installing [MPI](https://mpi4py.readthedocs.io/en/stable/), so these algorithms will probably not work: `DDPG`, `GAIL`, `PPO1`, `TRPO`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHfq9U0pBpEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get update                                                  > /dev/null 2>&1\n",
        "!apt-get install swig cmake zlib1g-dev ffmpeg freeglut3-dev xvfb > /dev/null 2>&1\n",
        "!pip install pytablewriter                                       > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kObMTO5_BzKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Stable Baselines only supports TF 1.x for now ####\n",
        "try:\n",
        "    # Colab only\n",
        "    %tensorflow_version 1.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrzGDVIYB4TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from time import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# NOTE use tqdm.write() instead of print() inside of tqdm wrapped loops\n",
        "from tqdm import tqdm\n",
        "\n",
        "import gym\n",
        "from gym.envs.atari.atari_env import ACTION_MEANING"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtHWjpwKCAqF",
        "colab_type": "text"
      },
      "source": [
        "### Update [Stable Baselines](https://github.com/hill-a/stable-baselines) and clone [RL Zoo Baselines](https://github.com/araffin/rl-baselines-zoo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGg59yj4CCWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!yes | pip uninstall stable-baselines                           > /dev/null 2>&1\n",
        "!pip install git+https://github.com/hill-a/stable-baselines.git > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uoafLRoCEM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from stable_baselines.common.cmd_util import make_atari_env\n",
        "from stable_baselines.common.vec_env import VecFrameStack\n",
        "\n",
        "# HACK to save logs\n",
        "from stable_baselines import logger\n",
        "os.environ[\"OPENAI_LOG_FORMAT\"] = 'stdout,log,csv,tensorboard'\n",
        "os.environ[\"OPENAI_LOGDIR\"] = os.path.abspath(LOG_DIR)\n",
        "logger.configure()\n",
        "\n",
        "# NOTE add more algorithms here if you want to use them\n",
        "from stable_baselines import PPO2, ACER, ACKTR\n",
        "ALGO_IMPL = {\n",
        "    'PPO2': PPO2,\n",
        "    'ACER': ACER,\n",
        "    'ACKTR': ACKTR,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMaHETmpCKms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/araffin/rl-baselines-zoo.git > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjB4SzAnCPlT",
        "colab_type": "text"
      },
      "source": [
        "## Load pre-trained agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ9jc42VCVNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_AGENTS = os.path.join(\"rl-baselines-zoo\", \"trained_agents\")\n",
        "!ls rl-baselines-zoo/trained_agents/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKIUEECQCXtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ext = \"NoFrameskip-v4.pkl\"\n",
        "# check the available pre-trained models\n",
        "algorithms = [\"PPO2\"]\n",
        "for algo in algorithms:\n",
        "    algo_path = os.path.join(PATH_TO_AGENTS, algo.lower())\n",
        "    print(algo_path + '/')\n",
        "    for f in sorted(os.listdir(algo_path), key=lambda x: x[::-1]):\n",
        "        # sort by the reversed filename, so env types get grouped together\n",
        "        if f.endswith(ext):\n",
        "            print(\"├──\", f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6CwssmOCb9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(2):\n",
        "    clear_output() # HACK to remove TensorFlow warnings\n",
        "    for algo, env_id in GAMES:\n",
        "        print(f\"('{algo}', '{env_id}')\")\n",
        "        agent_path = os.path.join(PATH_TO_AGENTS, algo.lower(), env_id + '.pkl')\n",
        "        model = ALGO_IMPL[algo].load(agent_path, verbose=0)\n",
        "        print(\"observation_space:\", model.observation_space)\n",
        "        print(\"action_space:\", model.action_space)\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaxY9IxFCyaZ",
        "colab_type": "text"
      },
      "source": [
        "## Generate trajectories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS3Jr8O5C-A-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VERBOSE = 2 # 0, 1 or 2\n",
        "\n",
        "print(\"N_OF_STEPS:\", N_OF_STEPS)\n",
        "print(\"N_OF_TRAJECTORIES:\", N_OF_TRAJECTORIES)\n",
        "print(N_OF_STEPS, \"*\", N_OF_TRAJECTORIES, \"=\", N_OF_STEPS * N_OF_TRAJECTORIES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls6Uw4PnDAsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set to False to save observations as PNG and store their location path, \n",
        "# instead of saving them as numpy arrays (which end up taking more space)\n",
        "SAVE_IMAGES_AS_NUMPY_ARRAYS = False\n",
        "\n",
        "PRINT_EARLY_DONE = False # print env resets in a trajectory\n",
        "PRINT_ACTIONS_TAKEN = True # print the meanings of actions\n",
        "\n",
        "# set to N_OF_TRAJECTORIES + 1 not to print\n",
        "PRINT_EVERY_N_TRAJECTORIES = N_OF_TRAJECTORIES // 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HSnlYyfEDrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"N_OF_STEPS:\", N_OF_STEPS)\n",
        "print(\"N_OF_TRAJECTORIES:\", N_OF_TRAJECTORIES)\n",
        "print(\"PRINT_EVERY_N_TRAJECTORIES:\", PRINT_EVERY_N_TRAJECTORIES)\n",
        "\n",
        "time_start = time()\n",
        "print(\"\\n================\")\n",
        "\n",
        "for algo, env_id in GAMES:\n",
        "    time_start_env = time()\n",
        "\n",
        "    env = make_atari_env(env_id, num_env=1, seed=0)\n",
        "    env = VecFrameStack(env, n_stack=4) # Frame-stacking with 4 frames\n",
        "    agent_path = os.path.join(PATH_TO_AGENTS, algo.lower(), env_id + '.pkl')\n",
        "\n",
        "    print(f\"('{algo}', '{env_id}')\")\n",
        "    print(f\"Getting pre-trained agent from: '{agent_path}'\\n\")\n",
        "    \n",
        "    # setup paths where data will be saved to\n",
        "    dataset_folder = f\"{env_id}_{algo}_{N_OF_STEPS}steps\"\n",
        "    if not SAVE_IMAGES_AS_NUMPY_ARRAYS:\n",
        "        images_folder = os.path.join(SAVE_DIR, dataset_folder, \"images\")\n",
        "        os.makedirs(images_folder, exist_ok=True)\n",
        "        if VERBOSE > 0:\n",
        "            print(f\"Images will be recorded to '{images_folder}/'\\n\")\n",
        "\n",
        "    model = ALGO_IMPL[algo].load(agent_path, env)\n",
        "    \n",
        "    for trajectory in tqdm(range(N_OF_TRAJECTORIES), position=0, leave=True):\n",
        "        # store the \"obs -> action\" mapping\n",
        "        observed_states, actions_taken = [], []\n",
        "        \n",
        "        # episode stats\n",
        "        ep_rewards, ep_starts = np.zeros((N_OF_STEPS,)), [True]\n",
        "        \n",
        "        # NOTE action, obs, reward, done and info are \n",
        "        #      arrays as we're using a vectorized env\n",
        "        \n",
        "        obs = env.reset() # (84, 84, 4)\n",
        "        for step in range(N_OF_STEPS):\n",
        "            observed_states.append(obs[0])\n",
        "            action, _ = model.predict(obs)\n",
        "            actions_taken.append(action[0])\n",
        "            obs, reward, done, info = env.step(action)\n",
        "            ep_starts.append(done[0])\n",
        "            ep_rewards[step] = reward[0]\n",
        "            if done[0]:\n",
        "                obs = env.reset()\n",
        "                if PRINT_EARLY_DONE:\n",
        "                    tqdm.write(f\" Done at step {step} (reseting env)\")\n",
        "        \n",
        "        # left pad the trajectory number with 0's\n",
        "        trajectory_number = str(trajectory).zfill(len(str(N_OF_TRAJECTORIES - 1)))\n",
        "\n",
        "        if not SAVE_IMAGES_AS_NUMPY_ARRAYS:\n",
        "            _observed_states = [] # store image paths\n",
        "            for step, obs in enumerate(observed_states):\n",
        "                image_folder = os.path.join(images_folder, trajectory_number)\n",
        "                os.makedirs(image_folder, exist_ok=True)\n",
        "                image_path = os.path.join(image_folder, f\"{str(step).zfill(len(str(N_OF_STEPS - 1)))}.png\")\n",
        "                if obs.shape[-1] == 3:\n",
        "                    obs = cv2.cvtColor(obs, cv2.COLOR_RGB2BGR)\n",
        "                cv2.imwrite(image_path, obs) #, [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
        "                _observed_states.append(image_path)\n",
        "            observed_states = np.array(_observed_states)\n",
        "        else:\n",
        "            observed_states = np.concatenate(observed_states).reshape((-1,) + env.observation_space.shape)\n",
        "\n",
        "        actions_taken = np.array(actions_taken)\n",
        "        ep_starts = np.array(ep_starts[:-1])\n",
        "\n",
        "        data = {\n",
        "            'actions': actions_taken,\n",
        "            'observations': observed_states,\n",
        "            'rewards': ep_rewards,\n",
        "            'episode_starts': ep_starts\n",
        "        } # type: Dict[str, np.ndarray]\n",
        "\n",
        "        save_folder = os.path.join(SAVE_DIR, dataset_folder, trajectory_number)\n",
        "        os.makedirs(save_folder, exist_ok=True)\n",
        "        np.savez_compressed(file=os.path.join(save_folder, \"trajectory\"), **data)\n",
        "        \n",
        "        if (trajectory + 1) % 10 == 0:\n",
        "            tqdm.write(f\" Saved trajectory {trajectory + 1} (of {N_OF_TRAJECTORIES})\")\n",
        "            if VERBOSE > 1:\n",
        "                tqdm.write(f\" Mean reward: {np.mean(ep_rewards):.2f}, ep_rewards.shape == {ep_rewards.shape}\")\n",
        "\n",
        "        if PRINT_ACTIONS_TAKEN and trajectory == N_OF_TRAJECTORIES - 1:\n",
        "            tqdm.write(f\"\\n Actions taken: {', '.join([ACTION_MEANING[action] for action in set(actions_taken)])}\")\n",
        "    \n",
        "    env.close()\n",
        "    print(f\" Δt = {(time() - time_start_env):.2f}s\")\n",
        "    print(\"================\\n\")\n",
        "\n",
        "print(f\"Total Δt = {(time() - time_start):.2f}s\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n6nR9pJjmg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF4usP_fhpg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/data.zip /content/data > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q26xcGsWkME6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -la | grep .zip\n",
        "!ls -lh | grep .zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phjtQowPGHqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWqkjFZ0k8a5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"/content/data.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txkWJnDElQbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# larger files may not work, try looking at:\n",
        "# https://stackoverflow.com/questions/49428332/how-to-download-large-files-like-weights-of-a-model-from-colaboratory"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}