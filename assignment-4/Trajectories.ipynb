{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trajectories.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurelkeys/machine-learning/blob/master/assignment-4/Trajectories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8D0TEl9vLJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "# PATH_TO_DATA = os.path.join(\"drive\", \"My Drive\", \"unicamp\", \"MC886\", \"atari\")\n",
        "\n",
        "import os\n",
        "PATH_TO_DATA = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSrCsl0Av6RV",
        "colab_type": "code",
        "outputId": "d11e3d19-4089-419b-e0d8-4b5b5f442889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "SAVE_DIR = os.path.join(PATH_TO_DATA, \"data\")\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "SAVE_DIR # where the trajectories for each game will be saved to"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zUPRZG8TOTv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d892c0e3-6637-4f89-a339-b499d7ba5e6d"
      },
      "source": [
        "LOG_DIR = os.path.join(PATH_TO_DATA, \"data\", \"results\")\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "LOG_DIR # where the stats for each game will be saved to"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data/results'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6rL58MEZRQh",
        "colab_type": "text"
      },
      "source": [
        "## Generate a dataset of trajectories from pre-trained RL agents on [Atari](https://gym.openai.com/envs/#atari) [environments](https://github.com/openai/gym/wiki/Table-of-environments).\n",
        "That is, by the end of this notebook we will have $observation \\rightarrow action$ mappings, where $observation$s are images of shape `IMG_SHAPE` and $action$s are integer values in the range $[0, 18)$, meaning:\n",
        "\n",
        "| 0 | 1 | 2 | 3 | 4 | 5 |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| NOOP | FIRE | UP | RIGHT | LEFT | DOWN |\n",
        "\n",
        "\n",
        "| 6 | 7 | 8 | 9 |\n",
        "| --- | --- | --- | --- |\n",
        "| UPRIGHT | UPLEFT | DOWNRIGHT | DOWNLEFT |\n",
        "\n",
        "\n",
        "| 10 | 11 | 12 | 13 |\n",
        "| --- | --- | --- | --- |\n",
        "| UPFIRE | RIGHTFIRE | LEFTFIRE | DOWNFIRE |\n",
        "\n",
        "\n",
        "| 14 | 15 | 16 | 17 |\n",
        "| --- | --- | --- | --- |\n",
        "| UPRIGHTFIRE | UPLEFTFIRE | DOWNRIGHTFIRE | DOWNLEFTFIRE |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxiF53dtcx5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of trajectories to generate\n",
        "N_OF_TRAJECTORIES = 5\n",
        "\n",
        "# number of steps per trajectory\n",
        "N_OF_STEPS = 500\n",
        "\n",
        "# list of string tuples in the format (RL Algorithm, Game Environment)\n",
        "GAMES = [\n",
        "    (\"PPO2\", \"BreakoutNoFrameskip-v4\"),\n",
        "    (\"PPO2\", \"PongNoFrameskip-v4\"),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xniuUnC1sohU",
        "colab_type": "code",
        "outputId": "fd0e6acd-ad5e-4835-9919-eda9b04da887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "[env_id for algo, env_id in GAMES]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BreakoutNoFrameskip-v4', 'PongNoFrameskip-v4']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANURED63lzYB",
        "colab_type": "text"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOvHHxnVn5rp",
        "colab_type": "text"
      },
      "source": [
        "Note that we're not installing [MPI](https://mpi4py.readthedocs.io/en/stable/), so the following algorithms will probably not work: `DDPG`, `GAIL`, `PPO1`, `TRPO`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmjBQE8sl8CP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f59ce7fb-9be6-4a8c-bafc-aed843c5422b"
      },
      "source": [
        "!apt-get update                                                  > /dev/null 2>&1\n",
        "!apt-get install swig cmake zlib1g-dev ffmpeg freeglut3-dev xvfb > /dev/null 2>&1\n",
        "!pip install pytablewriter #pyyaml optuna scikit-optimize         > /dev/null 2>&1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.6/dist-packages (0.46.1)\n",
            "Requirement already satisfied: tabledata<1.0.0,>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from pytablewriter) (0.9.1)\n",
            "Requirement already satisfied: DataProperty<1.0.0,>=0.43.1 in /usr/local/lib/python3.6/dist-packages (from pytablewriter) (0.43.1)\n",
            "Requirement already satisfied: mbstrdecoder[all]<1.0.0,>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from pytablewriter) (0.8.1)\n",
            "Requirement already satisfied: pathvalidate<1.0.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from pytablewriter) (0.29.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.6/dist-packages (from pytablewriter) (41.6.0)\n",
            "Requirement already satisfied: typepy[datetime]<1.0.0,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from pytablewriter) (0.6.0)\n",
            "Requirement already satisfied: msgfy<0.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from pytablewriter) (0.0.7)\n",
            "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytablewriter) (1.12.0)\n",
            "Requirement already satisfied: chardet<4.0.0,>=3.0.4; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from mbstrdecoder[all]<1.0.0,>=0.8.0->pytablewriter) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0; extra == \"datetime\" in /usr/local/lib/python3.6/dist-packages (from typepy[datetime]<1.0.0,>=0.6.0->pytablewriter) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2018.9; extra == \"datetime\" in /usr/local/lib/python3.6/dist-packages (from typepy[datetime]<1.0.0,>=0.6.0->pytablewriter) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_p5-8pYmEsa",
        "colab_type": "code",
        "outputId": "e1c5044b-c2a4-429d-b08d-945ac4eea3cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#### Stable Baselines only supports TF 1.x for now ####\n",
        "try:\n",
        "    # Colab only\n",
        "    # %tensorflow_version 2.x\n",
        "    %tensorflow_version 1.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYDsdxKLulZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from time import time\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# NOTE use tqdm.write() instead of print() inside tqdm wrapped loops\n",
        "from tqdm import tqdm\n",
        "\n",
        "import gym\n",
        "from gym.envs.atari.atari_env import ACTION_MEANING"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6d58ZxSm7BR",
        "colab_type": "text"
      },
      "source": [
        "### Update [Stable Baselines](https://github.com/hill-a/stable-baselines) and clone [RL Zoo Baselines](https://github.com/araffin/rl-baselines-zoo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mx9fivzl8KW",
        "colab_type": "code",
        "outputId": "0befbc57-7e20-4705-a668-b9357dd2bb0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip list | grep baselines"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stable-baselines         2.9.0a0    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPOfKIrIm3Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!yes | pip uninstall stable-baselines                           > /dev/null 2>&1\n",
        "!pip install git+https://github.com/hill-a/stable-baselines.git > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZG914mxnHN_",
        "colab_type": "code",
        "outputId": "3175f5f0-5e46-433f-bd8f-f8d062473ddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip list | grep baselines"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stable-baselines         2.9.0a0    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBZSNLAGnpkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/araffin/rl-baselines-zoo.git      > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULku9CT6ovu2",
        "colab_type": "code",
        "outputId": "0db595ec-7a36-47b1-e39e-5d18e905bf4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "from stable_baselines.common.cmd_util import make_atari_env\n",
        "\n",
        "from stable_baselines.common.vec_env import VecFrameStack, DummyVecEnv\n",
        "\n",
        "# NOTE add more algorithms here\n",
        "from stable_baselines import PPO2, ACER, ACKTR\n",
        "ALGO_IMPL = {\n",
        "    'PPO2': PPO2,\n",
        "    'ACER': ACER,\n",
        "    'ACKTR': ACKTR,\n",
        "}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZQhTCzfwAZT",
        "colab_type": "text"
      },
      "source": [
        "## Load the pre-trained agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BukuKWcxxaed",
        "colab_type": "code",
        "outputId": "48f8ddf2-3bff-49e1-9348-6a2c449a073b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls rl-baselines-zoo/trained_agents/"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a2c  acer  acktr  ddpg\tdqn  her  ppo2\tsac  td3  trpo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhFU5ULCxYEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_AGENTS = os.path.join(\"rl-baselines-zoo\", \"trained_agents\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGcL8fuWUdHT",
        "colab_type": "code",
        "outputId": "3def0172-2d3c-4ee9-b2e2-7afc3ebdf5d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "source": [
        "# check the available pre-trained models\n",
        "algorithms = [\"PPO2\"]\n",
        "for algo in algorithms:\n",
        "    algo_path = os.path.join(PATH_TO_AGENTS, algo.lower())\n",
        "    print(algo_path + '/')\n",
        "    for f in sorted(os.listdir(algo_path), key=lambda x: x[::-1]):\n",
        "        # sort by the reverse filename, so env types get grouped together\n",
        "        if f.endswith(\".pkl\"):\n",
        "            print(\"|___\", f)\n",
        "            # uncomment to print the model's observation and action spaces\n",
        "            # try:\n",
        "            #     model = ALGO_IMPL[algo].load(os.path.join(algo_path, f), verbose=0)\n",
        "            #     print(\"     observation_space:\", model.observation_space)\n",
        "            #     print(\"     action_space:\", model.action_space)\n",
        "            # except:\n",
        "            #     print(\"     ERROR: couldn't load model\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rl-baselines-zoo/trained_agents/ppo2/\n",
            "|___ Pendulum-v0.pkl\n",
            "|___ MountainCar-v0.pkl\n",
            "|___ MountainCarContinuous-v0.pkl\n",
            "|___ MinitaurBulletDuckEnv-v0.pkl\n",
            "|___ Walker2DBulletEnv-v0.pkl\n",
            "|___ HumanoidBulletEnv-v0.pkl\n",
            "|___ HalfCheetahBulletEnv-v0.pkl\n",
            "|___ InvertedDoublePendulumBulletEnv-v0.pkl\n",
            "|___ InvertedPendulumSwingupBulletEnv-v0.pkl\n",
            "|___ ReacherBulletEnv-v0.pkl\n",
            "|___ HopperBulletEnv-v0.pkl\n",
            "|___ MinitaurBulletEnv-v0.pkl\n",
            "|___ AntBulletEnv-v0.pkl\n",
            "|___ CartPole-v1.pkl\n",
            "|___ Acrobot-v1.pkl\n",
            "|___ BipedalWalkerHardcore-v2.pkl\n",
            "|___ LunarLander-v2.pkl\n",
            "|___ BipedalWalker-v2.pkl\n",
            "|___ LunarLanderContinuous-v2.pkl\n",
            "|___ PongNoFrameskip-v4.pkl\n",
            "|___ MsPacmanNoFrameskip-v4.pkl\n",
            "|___ EnduroNoFrameskip-v4.pkl\n",
            "|___ BeamRiderNoFrameskip-v4.pkl\n",
            "|___ SpaceInvadersNoFrameskip-v4.pkl\n",
            "|___ QbertNoFrameskip-v4.pkl\n",
            "|___ SeaquestNoFrameskip-v4.pkl\n",
            "|___ BreakoutNoFrameskip-v4.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5ye3CG3NzJo",
        "colab_type": "code",
        "outputId": "e7cc0aa7-d06a-4bc6-e452-8bd0dffbd3c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "for algo, env_id in GAMES:\n",
        "    print(f\"('{algo}', '{env_id}')\")\n",
        "    agent_path = os.path.join(PATH_TO_AGENTS, algo.lower(), env_id + '.pkl')\n",
        "    model = ALGO_IMPL[algo].load(agent_path, verbose=0)\n",
        "    print(\"observation_space:\", model.observation_space)\n",
        "    print(\"action_space:\", model.action_space)\n",
        "    print()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('PPO2', 'BreakoutNoFrameskip-v4')\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:58: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:67: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/policies.py:115: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/a2c/utils.py:136: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/distributions.py:326: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/distributions.py:327: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:194: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:202: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:210: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:246: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "observation_space: Box(84, 84, 4)\n",
            "action_space: Discrete(4)\n",
            "\n",
            "('PPO2', 'PongNoFrameskip-v4')\n",
            "observation_space: Box(84, 84, 4)\n",
            "action_space: Discrete(6)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwdzhBHua5ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VERBOSE = 2 # 0, 1 or 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwoq2YnzShiU",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate agents\n",
        "Let's evaluate a few trajectories of each game from `GAMES` to get a sense of how the agents are performing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70P1Tq1eTE6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of trajectories to evaluate each agent on\n",
        "N_OF_EVAL_TRAJECTORIES = 2\n",
        "\n",
        "results = {\n",
        "    'algo': [],\n",
        "    'env_id': [],\n",
        "    'mean_reward': [],\n",
        "    'std_reward': [],\n",
        "    'n_timesteps': [],\n",
        "    'n_episodes': []\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZfWQPo6fD4K",
        "colab_type": "text"
      },
      "source": [
        "### Import `create_test_env` from inside the `rl-baselines-zoo/` folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6uO-rBye8gR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64f45a96-846f-40be-b5d1-841d21fc0b37"
      },
      "source": [
        "cd rl-baselines-zoo/"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/rl-baselines-zoo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCtDWiDmdM3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils import create_test_env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNt-dN5UfAx_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "01af554a-acc0-4ea5-fabc-7bc10e8710dd"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClxDKFaISpJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "0b62245e-9306-4575-cf77-afa7d529a53d"
      },
      "source": [
        "time_start = time()\n",
        "print(\"================\")\n",
        "for algo, env_id in GAMES:\n",
        "    time_start_env = time()\n",
        "\n",
        "    env = create_test_env(env_id, n_envs=1, seed=0, \n",
        "                          is_atari=True, should_render=False, \n",
        "                          log_dir=LOG_DIR, hyperparams={})\n",
        "    agent_path = os.path.join(PATH_TO_AGENTS, algo.lower(), env_id + '.pkl')\n",
        "    \n",
        "    print(f\"('{algo}', '{env_id}')\")\n",
        "    print(f\"Getting pre-trained agent from: '{agent_path}'\")\n",
        "    if VERBOSE > 1:\n",
        "        print(f\"env.envs: {env.envs}\")\n",
        "    print()\n",
        "    \n",
        "    model = ALGO_IMPL[algo].load(agent_path, env)\n",
        "    \n",
        "    for trajectory in tqdm(range(N_OF_EVAL_TRAJECTORIES), position=0, leave=True):\n",
        "        # episode stats\n",
        "        ep_len, ep_reward, ep_rewards = 0, 0.0, []\n",
        "\n",
        "        obs = env.reset() # (84, 84, 4)\n",
        "        for step in range(N_OF_STEPS):\n",
        "            action = model.predict(obs)\n",
        "            # clip action to avoid out of bound errors\n",
        "            if isinstance(env.action_space, gym.spaces.Box):\n",
        "                action = np.clip(action, env.action_space.low, env.action_space.high)\n",
        "            \n",
        "            obs, reward, done, infos = env.step(action)\n",
        "\n",
        "            # NOTE the return reward is not the Atari score\n",
        "            #      so we have to get it from the infos dict\n",
        "            ep_infos = infos[0].get('episode')\n",
        "            if ep_infos is not None:\n",
        "                tqdm.write(f\"\\nAtari Episode Score: {ep_infos['r']:.2f}\")\n",
        "                tqdm.write(f\"Atari Episode Length: {ep_infos['l']}\")\n",
        "            \n",
        "            # FIXME ep_infos is always None \n",
        "            # try checking stable-baselines' Monitor.step()\n",
        "            if infos is not None: # debug\n",
        "                # if step == 0:\n",
        "                #     tqdm.write(f\"(DEBUG) step == 0: {infos}\")\n",
        "                if len(infos) > 1:\n",
        "                    tqdm.write(f\"(DEBUG) infos: {infos}\")\n",
        "                elif len(infos[0].keys()) > 1:\n",
        "                    if 'terminal_observation' not in infos[0].keys() or len(infos[0].keys()) > 2:\n",
        "                        tqdm.write(f\"(DEBUG) infos[0]: {infos[0]}\")\n",
        "\n",
        "            ep_len += 1\n",
        "            ep_reward += reward[0]\n",
        "            if done:\n",
        "                obs = env.reset()\n",
        "                ep_rewards.append(ep_reward)\n",
        "                if VERBOSE > 1:\n",
        "                    tqdm.write(f\"\\nEpisode Reward: {ep_reward:.2f}\")\n",
        "                    tqdm.write(f\"Episode Length: {ep_len}\")\n",
        "                ep_reward = 0.0\n",
        "                ep_len = 0\n",
        "        \n",
        "        if VERBOSE > 0:\n",
        "            tqdm.write(\"\\nMean reward: {:.2f}, len(ep_rewards) == {}\".format(\n",
        "                       np.mean(ep_rewards) if len(ep_rewards) > 0 else 0.0, \n",
        "                       len(ep_rewards)))\n",
        "\n",
        "    env.close()\n",
        "    print(f\"Δt = {(time() - time_start_env):.2f}s\")\n",
        "    print(\"================\")\n",
        "\n",
        "print(f\"Total Δt = {(time() - time_start):.2f}s\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================\n",
            "Using Atari wrapper\n",
            "('PPO2', 'BreakoutNoFrameskip-v4')\n",
            "Getting pre-trained agent from: 'rl-baselines-zoo/trained_agents/ppo2/BreakoutNoFrameskip-v4.pkl'\n",
            "env.envs: [<ClipRewardEnv<WarpFrame<FireResetEnv<EpisodicLifeEnv<Monitor<MaxAndSkipEnv<NoopResetEnv<TimeLimit<AtariEnv<BreakoutNoFrameskip-v4>>>>>>>>>>]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1/2 [00:02<00:02,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mean reward: 0.00, len(ep_rewards) == 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:04<00:00,  2.16s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mean reward: 0.00, len(ep_rewards) == 0\n",
            "Δt = 6.35s\n",
            "================\n",
            "Using Atari wrapper\n",
            "('PPO2', 'PongNoFrameskip-v4')\n",
            "Getting pre-trained agent from: 'rl-baselines-zoo/trained_agents/ppo2/PongNoFrameskip-v4.pkl'\n",
            "env.envs: [<ClipRewardEnv<WarpFrame<FireResetEnv<EpisodicLifeEnv<Monitor<MaxAndSkipEnv<NoopResetEnv<TimeLimit<AtariEnv<PongNoFrameskip-v4>>>>>>>>>>]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1/2 [00:02<00:02,  2.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mean reward: 0.00, len(ep_rewards) == 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:04<00:00,  2.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Mean reward: 0.00, len(ep_rewards) == 0\n",
            "Δt = 6.31s\n",
            "================\n",
            "Total Δt = 12.66s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVTn0snAndBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "11ce59fe-604c-4046-b8bc-aa819b06f208"
      },
      "source": [
        "!ls data/results/"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.monitor.csv  progress.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHrpWV5vNviz",
        "colab_type": "text"
      },
      "source": [
        "## Generate trajectories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFvNuI8vb75g",
        "colab_type": "text"
      },
      "source": [
        "Note that we use `make_atari_env` + `VecFrameStack` for `NoFrameskip-v4` environments, so each frame is converted to grayscale and downscaled from 210x160 to 84x84. Therefore, the $observation$ shape is `(84, 84, 4)` (four stacked frames), and **not** `(210, 160, 3)`, nor `(84, 84, 1)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2ugXR8sZ6RM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRINT_EARLY_DONE = False\n",
        "PRINT_ACTIONS_TAKEN = False\n",
        "\n",
        "PRINT_EVERY_N_TRAJECTORIES = N_OF_TRAJECTORIES // 10\n",
        "# uncomment below not to print\n",
        "# PRINT_EVERY_N_TRAJECTORIES = N_OF_TRAJECTORIES + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAKJ7SOIjA8q",
        "colab_type": "text"
      },
      "source": [
        "**TODO: evaluate the trajectories before saving the final datasets**  \n",
        "**TODO: add button to load from data/ or save to drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvtLqqVZwFEW",
        "colab_type": "code",
        "outputId": "9a80f802-11a9-47a9-e16e-499da0ba7c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "time_start = time()\n",
        "print(\"PRINT_EVERY_N_TRAJECTORIES:\", PRINT_EVERY_N_TRAJECTORIES)\n",
        "print(\"N_OF_TRAJECTORIES:\", N_OF_TRAJECTORIES)\n",
        "print(\"N_OF_STEPS:\", N_OF_STEPS)\n",
        "print(\"================\")\n",
        "for algo, env_id in GAMES:\n",
        "    time_start_env = time()\n",
        "\n",
        "    env = make_atari_env(env_id, num_env=1, seed=0)\n",
        "    env = VecFrameStack(env, n_stack=4) # Frame-stacking with 4 frames\n",
        "    agent_path = os.path.join(PATH_TO_AGENTS, algo.lower(), env_id + '.pkl')\n",
        "    \n",
        "    print(f\"('{algo}', '{env_id}')\")\n",
        "    print(f\"Getting pre-trained agent from: '{agent_path}'\\n\")\n",
        "    \n",
        "    model = ALGO_IMPL[algo].load(agent_path, env)\n",
        "    \n",
        "    for trajectory in tqdm(range(N_OF_TRAJECTORIES), position=0, leave=True):\n",
        "        # store the \"obs -> action\" mapping\n",
        "        observed_states, actions_taken = [], []\n",
        "\n",
        "        obs = env.reset() # (84, 84, 4)\n",
        "        for step in range(N_OF_STEPS):\n",
        "            action = model.predict(obs)\n",
        "            observed_states.append(obs)\n",
        "            actions_taken.append(action)\n",
        "            obs, reward, done, infos = env.step(action)\n",
        "            if done:\n",
        "                obs = env.reset()\n",
        "                if PRINT_EARLY_DONE:\n",
        "                    print(f\"done at step {step + 1} (reseting env)\")\n",
        "        \n",
        "        # NOTE action, reward and done are arrays since we're using a vectorized env\n",
        "        observed_states = [obs[0] for obs in observed_states]\n",
        "        actions_taken = [action[0][0] for action in actions_taken]\n",
        "        \n",
        "        np.savez_compressed(file=os.path.join(SAVE_DIR, f\"{env_id}_{algo}_t{trajectory+1}_{N_OF_STEPS}s\"), \n",
        "                            observations=observed_states, actions=actions_taken)\n",
        "        \n",
        "        if (trajectory + 1) % 10 == 0:\n",
        "            print(f\" Saved trajectory {trajectory+1} (of {N_OF_TRAJECTORIES})\")\n",
        "\n",
        "        if PRINT_ACTIONS_TAKEN and trajectory == N_OF_TRAJECTORIES - 1:\n",
        "            print(\"\\nActions taken:\", \", \".join([ACTION_MEANING[action] for action in set(actions_taken)]))\n",
        "\n",
        "    del observed_states\n",
        "    del actions_taken\n",
        "    env.close()\n",
        "    print(f\"Δt = {(time() - time_start_env):.2f}s\")\n",
        "    print(\"================\")\n",
        "\n",
        "print(f\"Total Δt = {(time() - time_start):.2f}s\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PRINT_EVERY_N_TRAJECTORIES: 0\n",
            "N_OF_TRAJECTORIES: 5\n",
            "N_OF_STEPS: 100\n",
            "================\n",
            "('PPO2', 'PongNoFrameskip-v4')\n",
            "Getting pre-trained agent from: 'rl-baselines-zoo/trained_agents/ppo2/PongNoFrameskip-v4.pkl'\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[step 1] infos: [{'ale.lives': 0}]\n",
            "[step 2] infos: [{'ale.lives': 0}]\n",
            "[step 3] infos: [{'ale.lives': 0}]\n",
            "[step 4] infos: [{'ale.lives': 0}]\n",
            "[step 5] infos: [{'ale.lives': 0}]\n",
            "[step 6] infos: [{'ale.lives': 0}]\n",
            "[step 7] infos: [{'ale.lives': 0}]\n",
            "[step 8] infos: [{'ale.lives': 0}]\n",
            "[step 9] infos: [{'ale.lives': 0}]\n",
            "[step 10] infos: [{'ale.lives': 0}]\n",
            "[step 11] infos: [{'ale.lives': 0}]\n",
            "[step 12] infos: [{'ale.lives': 0}]\n",
            "[step 13] infos: [{'ale.lives': 0}]\n",
            "[step 14] infos: [{'ale.lives': 0}]\n",
            "[step 15] infos: [{'ale.lives': 0}]\n",
            "[step 16] infos: [{'ale.lives': 0}]\n",
            "[step 17] infos: [{'ale.lives': 0}]\n",
            "[step 18] infos: [{'ale.lives': 0}]\n",
            "[step 19] infos: [{'ale.lives': 0}]\n",
            "[step 20] infos: [{'ale.lives': 0}]\n",
            "[step 21] infos: [{'ale.lives': 0}]\n",
            "[step 22] infos: [{'ale.lives': 0}]\n",
            "[step 23] infos: [{'ale.lives': 0}]\n",
            "[step 24] infos: [{'ale.lives': 0}]\n",
            "[step 25] infos: [{'ale.lives': 0}]\n",
            "[step 26] infos: [{'ale.lives': 0}]\n",
            "[step 27] infos: [{'ale.lives': 0}]\n",
            "[step 28] infos: [{'ale.lives': 0}]\n",
            "[step 29] infos: [{'ale.lives': 0}]\n",
            "[step 30] infos: [{'ale.lives': 0}]\n",
            "[step 31] infos: [{'ale.lives': 0}]\n",
            "[step 32] infos: [{'ale.lives': 0}]\n",
            "[step 33] infos: [{'ale.lives': 0}]\n",
            "[step 34] infos: [{'ale.lives': 0}]\n",
            "[step 35] infos: [{'ale.lives': 0}]\n",
            "[step 36] infos: [{'ale.lives': 0}]\n",
            "[step 37] infos: [{'ale.lives': 0}]\n",
            "[step 38] infos: [{'ale.lives': 0}]\n",
            "[step 39] infos: [{'ale.lives': 0}]\n",
            "[step 40] infos: [{'ale.lives': 0}]\n",
            "[step 41] infos: [{'ale.lives': 0}]\n",
            "[step 42] infos: [{'ale.lives': 0}]\n",
            "[step 43] infos: [{'ale.lives': 0}]\n",
            "[step 44] infos: [{'ale.lives': 0}]\n",
            "[step 45] infos: [{'ale.lives': 0}]\n",
            "[step 46] infos: [{'ale.lives': 0}]\n",
            "[step 47] infos: [{'ale.lives': 0}]\n",
            "[step 48] infos: [{'ale.lives': 0}]\n",
            "[step 49] infos: [{'ale.lives': 0}]\n",
            "[step 50] infos: [{'ale.lives': 0}]\n",
            "[step 51] infos: [{'ale.lives': 0}]\n",
            "[step 52] infos: [{'ale.lives': 0}]\n",
            "[step 53] infos: [{'ale.lives': 0}]\n",
            "[step 54] infos: [{'ale.lives': 0}]\n",
            "[step 55] infos: [{'ale.lives': 0}]\n",
            "[step 56] infos: [{'ale.lives': 0}]\n",
            "[step 57] infos: [{'ale.lives': 0}]\n",
            "[step 58] infos: [{'ale.lives': 0}]\n",
            "[step 59] infos: [{'ale.lives': 0}]\n",
            "[step 60] infos: [{'ale.lives': 0}]\n",
            "[step 61] infos: [{'ale.lives': 0}]\n",
            "[step 62] infos: [{'ale.lives': 0}]\n",
            "[step 63] infos: [{'ale.lives': 0}]\n",
            "[step 64] infos: [{'ale.lives': 0}]\n",
            "[step 65] infos: [{'ale.lives': 0}]\n",
            "[step 66] infos: [{'ale.lives': 0}]\n",
            "[step 67] infos: [{'ale.lives': 0}]\n",
            "[step 68] infos: [{'ale.lives': 0}]\n",
            "[step 69] infos: [{'ale.lives': 0}]\n",
            "[step 70] infos: [{'ale.lives': 0}]\n",
            "[step 71] infos: [{'ale.lives': 0}]\n",
            "[step 72] infos: [{'ale.lives': 0}]\n",
            "[step 73] infos: [{'ale.lives': 0}]\n",
            "[step 74] infos: [{'ale.lives': 0}]\n",
            "[step 75] infos: [{'ale.lives': 0}]\n",
            "[step 76] infos: [{'ale.lives': 0}]\n",
            "[step 77] infos: [{'ale.lives': 0}]\n",
            "[step 78] infos: [{'ale.lives': 0}]\n",
            "[step 79] infos: [{'ale.lives': 0}]\n",
            "[step 80] infos: [{'ale.lives': 0}]\n",
            "[step 81] infos: [{'ale.lives': 0}]\n",
            "[step 82] infos: [{'ale.lives': 0}]\n",
            "[step 83] infos: [{'ale.lives': 0}]\n",
            "[step 84] infos: [{'ale.lives': 0}]\n",
            "[step 85] infos: [{'ale.lives': 0}]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 1/5 [00:00<00:02,  1.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[step 86] infos: [{'ale.lives': 0}]\n",
            "[step 87] infos: [{'ale.lives': 0}]\n",
            "[step 88] infos: [{'ale.lives': 0}]\n",
            "[step 89] infos: [{'ale.lives': 0}]\n",
            "[step 90] infos: [{'ale.lives': 0}]\n",
            "[step 91] infos: [{'ale.lives': 0}]\n",
            "[step 92] infos: [{'ale.lives': 0}]\n",
            "[step 93] infos: [{'ale.lives': 0}]\n",
            "[step 94] infos: [{'ale.lives': 0}]\n",
            "[step 95] infos: [{'ale.lives': 0}]\n",
            "[step 96] infos: [{'ale.lives': 0}]\n",
            "[step 97] infos: [{'ale.lives': 0}]\n",
            "[step 98] infos: [{'ale.lives': 0}]\n",
            "[step 99] infos: [{'ale.lives': 0}]\n",
            "[step 100] infos: [{'ale.lives': 0}]\n",
            "[step 1] infos: [{'ale.lives': 0}]\n",
            "[step 2] infos: [{'ale.lives': 0}]\n",
            "[step 3] infos: [{'ale.lives': 0}]\n",
            "[step 4] infos: [{'ale.lives': 0}]\n",
            "[step 5] infos: [{'ale.lives': 0}]\n",
            "[step 6] infos: [{'ale.lives': 0}]\n",
            "[step 7] infos: [{'ale.lives': 0}]\n",
            "[step 8] infos: [{'ale.lives': 0}]\n",
            "[step 9] infos: [{'ale.lives': 0}]\n",
            "[step 10] infos: [{'ale.lives': 0}]\n",
            "[step 11] infos: [{'ale.lives': 0}]\n",
            "[step 12] infos: [{'ale.lives': 0}]\n",
            "[step 13] infos: [{'ale.lives': 0}]\n",
            "[step 14] infos: [{'ale.lives': 0}]\n",
            "[step 15] infos: [{'ale.lives': 0}]\n",
            "[step 16] infos: [{'ale.lives': 0}]\n",
            "[step 17] infos: [{'ale.lives': 0}]\n",
            "[step 18] infos: [{'ale.lives': 0}]\n",
            "[step 19] infos: [{'ale.lives': 0}]\n",
            "[step 20] infos: [{'ale.lives': 0}]\n",
            "[step 21] infos: [{'ale.lives': 0}]\n",
            "[step 22] infos: [{'ale.lives': 0}]\n",
            "[step 23] infos: [{'ale.lives': 0}]\n",
            "[step 24] infos: [{'ale.lives': 0}]\n",
            "[step 25] infos: [{'ale.lives': 0}]\n",
            "[step 26] infos: [{'ale.lives': 0}]\n",
            "[step 27] infos: [{'ale.lives': 0}]\n",
            "[step 28] infos: [{'ale.lives': 0}]\n",
            "[step 29] infos: [{'ale.lives': 0}]\n",
            "[step 30] infos: [{'ale.lives': 0}]\n",
            "[step 31] infos: [{'ale.lives': 0}]\n",
            "[step 32] infos: [{'ale.lives': 0}]\n",
            "[step 33] infos: [{'ale.lives': 0}]\n",
            "[step 34] infos: [{'ale.lives': 0}]\n",
            "[step 35] infos: [{'ale.lives': 0}]\n",
            "[step 36] infos: [{'ale.lives': 0}]\n",
            "[step 37] infos: [{'ale.lives': 0}]\n",
            "[step 38] infos: [{'ale.lives': 0}]\n",
            "[step 39] infos: [{'ale.lives': 0}]\n",
            "[step 40] infos: [{'ale.lives': 0}]\n",
            "[step 41] infos: [{'ale.lives': 0}]\n",
            "[step 42] infos: [{'ale.lives': 0}]\n",
            "[step 43] infos: [{'ale.lives': 0}]\n",
            "[step 44] infos: [{'ale.lives': 0}]\n",
            "[step 45] infos: [{'ale.lives': 0}]\n",
            "[step 46] infos: [{'ale.lives': 0}]\n",
            "[step 47] infos: [{'ale.lives': 0}]\n",
            "[step 48] infos: [{'ale.lives': 0}]\n",
            "[step 49] infos: [{'ale.lives': 0}]\n",
            "[step 50] infos: [{'ale.lives': 0}]\n",
            "[step 51] infos: [{'ale.lives': 0}]\n",
            "[step 52] infos: [{'ale.lives': 0}]\n",
            "[step 53] infos: [{'ale.lives': 0}]\n",
            "[step 54] infos: [{'ale.lives': 0}]\n",
            "[step 55] infos: [{'ale.lives': 0}]\n",
            "[step 56] infos: [{'ale.lives': 0}]\n",
            "[step 57] infos: [{'ale.lives': 0}]\n",
            "[step 58] infos: [{'ale.lives': 0}]\n",
            "[step 59] infos: [{'ale.lives': 0}]\n",
            "[step 60] infos: [{'ale.lives': 0}]\n",
            "[step 61] infos: [{'ale.lives': 0}]\n",
            "[step 62] infos: [{'ale.lives': 0}]\n",
            "[step 63] infos: [{'ale.lives': 0}]\n",
            "[step 64] infos: [{'ale.lives': 0}]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 2/5 [00:01<00:01,  1.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[step 65] infos: [{'ale.lives': 0}]\n",
            "[step 66] infos: [{'ale.lives': 0}]\n",
            "[step 67] infos: [{'ale.lives': 0}]\n",
            "[step 68] infos: [{'ale.lives': 0}]\n",
            "[step 69] infos: [{'ale.lives': 0}]\n",
            "[step 70] infos: [{'ale.lives': 0}]\n",
            "[step 71] infos: [{'ale.lives': 0}]\n",
            "[step 72] infos: [{'ale.lives': 0}]\n",
            "[step 73] infos: [{'ale.lives': 0}]\n",
            "[step 74] infos: [{'ale.lives': 0}]\n",
            "[step 75] infos: [{'ale.lives': 0}]\n",
            "[step 76] infos: [{'ale.lives': 0}]\n",
            "[step 77] infos: [{'ale.lives': 0}]\n",
            "[step 78] infos: [{'ale.lives': 0}]\n",
            "[step 79] infos: [{'ale.lives': 0}]\n",
            "[step 80] infos: [{'ale.lives': 0}]\n",
            "[step 81] infos: [{'ale.lives': 0}]\n",
            "[step 82] infos: [{'ale.lives': 0}]\n",
            "[step 83] infos: [{'ale.lives': 0}]\n",
            "[step 84] infos: [{'ale.lives': 0}]\n",
            "[step 85] infos: [{'ale.lives': 0}]\n",
            "[step 86] infos: [{'ale.lives': 0}]\n",
            "[step 87] infos: [{'ale.lives': 0}]\n",
            "[step 88] infos: [{'ale.lives': 0}]\n",
            "[step 89] infos: [{'ale.lives': 0}]\n",
            "[step 90] infos: [{'ale.lives': 0}]\n",
            "[step 91] infos: [{'ale.lives': 0}]\n",
            "[step 92] infos: [{'ale.lives': 0}]\n",
            "[step 93] infos: [{'ale.lives': 0}]\n",
            "[step 94] infos: [{'ale.lives': 0}]\n",
            "[step 95] infos: [{'ale.lives': 0}]\n",
            "[step 96] infos: [{'ale.lives': 0}]\n",
            "[step 97] infos: [{'ale.lives': 0}]\n",
            "[step 98] infos: [{'ale.lives': 0}]\n",
            "[step 99] infos: [{'ale.lives': 0}]\n",
            "[step 100] infos: [{'ale.lives': 0}]\n",
            "[step 1] infos: [{'ale.lives': 0}]\n",
            "[step 2] infos: [{'ale.lives': 0}]\n",
            "[step 3] infos: [{'ale.lives': 0}]\n",
            "[step 4] infos: [{'ale.lives': 0}]\n",
            "[step 5] infos: [{'ale.lives': 0}]\n",
            "[step 6] infos: [{'ale.lives': 0}]\n",
            "[step 7] infos: [{'ale.lives': 0}]\n",
            "[step 8] infos: [{'ale.lives': 0}]\n",
            "[step 9] infos: [{'ale.lives': 0}]\n",
            "[step 10] infos: [{'ale.lives': 0}]\n",
            "[step 11] infos: [{'ale.lives': 0}]\n",
            "[step 12] infos: [{'ale.lives': 0}]\n",
            "[step 13] infos: [{'ale.lives': 0}]\n",
            "[step 14] infos: [{'ale.lives': 0}]\n",
            "[step 15] infos: [{'ale.lives': 0}]\n",
            "[step 16] infos: [{'ale.lives': 0}]\n",
            "[step 17] infos: [{'ale.lives': 0}]\n",
            "[step 18] infos: [{'ale.lives': 0}]\n",
            "[step 19] infos: [{'ale.lives': 0}]\n",
            "[step 20] infos: [{'ale.lives': 0}]\n",
            "[step 21] infos: [{'ale.lives': 0}]\n",
            "[step 22] infos: [{'ale.lives': 0}]\n",
            "[step 23] infos: [{'ale.lives': 0}]\n",
            "[step 24] infos: [{'ale.lives': 0}]\n",
            "[step 25] infos: [{'ale.lives': 0}]\n",
            "[step 26] infos: [{'ale.lives': 0}]\n",
            "[step 27] infos: [{'ale.lives': 0}]\n",
            "[step 28] infos: [{'ale.lives': 0}]\n",
            "[step 29] infos: [{'ale.lives': 0}]\n",
            "[step 30] infos: [{'ale.lives': 0}]\n",
            "[step 31] infos: [{'ale.lives': 0}]\n",
            "[step 32] infos: [{'ale.lives': 0}]\n",
            "[step 33] infos: [{'ale.lives': 0}]\n",
            "[step 34] infos: [{'ale.lives': 0}]\n",
            "[step 35] infos: [{'ale.lives': 0}]\n",
            "[step 36] infos: [{'ale.lives': 0}]\n",
            "[step 37] infos: [{'ale.lives': 0}]\n",
            "[step 38] infos: [{'ale.lives': 0}]\n",
            "[step 39] infos: [{'ale.lives': 0}]\n",
            "[step 40] infos: [{'ale.lives': 0}]\n",
            "[step 41] infos: [{'ale.lives': 0}]\n",
            "[step 42] infos: [{'ale.lives': 0}]\n",
            "[step 43] infos: [{'ale.lives': 0}]\n",
            "[step 44] infos: [{'ale.lives': 0}]\n",
            "[step 45] infos: [{'ale.lives': 0}]\n",
            "[step 46] infos: [{'ale.lives': 0}]\n",
            "[step 47] infos: [{'ale.lives': 0}]\n",
            "[step 48] infos: [{'ale.lives': 0}]\n",
            "[step 49] infos: [{'ale.lives': 0}]\n",
            "[step 50] infos: [{'ale.lives': 0}]\n",
            "[step 51] infos: [{'ale.lives': 0}]\n",
            "[step 52] infos: [{'ale.lives': 0}]\n",
            "[step 53] infos: [{'ale.lives': 0}]\n",
            "[step 54] infos: [{'ale.lives': 0}]\n",
            "[step 55] infos: [{'ale.lives': 0}]\n",
            "[step 56] infos: [{'ale.lives': 0}]\n",
            "[step 57] infos: [{'ale.lives': 0}]\n",
            "[step 58] infos: [{'ale.lives': 0}]\n",
            "[step 59] infos: [{'ale.lives': 0}]\n",
            "[step 60] infos: [{'ale.lives': 0}]\n",
            "[step 61] infos: [{'ale.lives': 0}]\n",
            "[step 62] infos: [{'ale.lives': 0}]\n",
            "[step 63] infos: [{'ale.lives': 0}]\n",
            "[step 64] infos: [{'ale.lives': 0}]\n",
            "[step 65] infos: [{'ale.lives': 0}]\n",
            "[step 66] infos: [{'ale.lives': 0}]\n",
            "[step 67] infos: [{'ale.lives': 0}]\n",
            "[step 68] infos: [{'ale.lives': 0}]\n",
            "[step 69] infos: [{'ale.lives': 0}]\n",
            "[step 70] infos: [{'ale.lives': 0}]\n",
            "[step 71] infos: [{'ale.lives': 0}]\n",
            "[step 72] infos: [{'ale.lives': 0}]\n",
            "[step 73] infos: [{'ale.lives': 0}]\n",
            "[step 74] infos: [{'ale.lives': 0}]\n",
            "[step 75] infos: [{'ale.lives': 0}]\n",
            "[step 76] infos: [{'ale.lives': 0}]\n",
            "[step 77] infos: [{'ale.lives': 0}]\n",
            "[step 78] infos: [{'ale.lives': 0}]\n",
            "[step 79] infos: [{'ale.lives': 0}]\n",
            "[step 80] infos: [{'ale.lives': 0}]\n",
            "[step 81] infos: [{'ale.lives': 0}]\n",
            "[step 82] infos: [{'ale.lives': 0}]\n",
            "[step 83] infos: [{'ale.lives': 0}]\n",
            "[step 84] infos: [{'ale.lives': 0}]\n",
            "[step 85] infos: [{'ale.lives': 0}]\n",
            "[step 86] infos: [{'ale.lives': 0}]\n",
            "[step 87] infos: [{'ale.lives': 0}]\n",
            "[step 88] infos: [{'ale.lives': 0}]\n",
            "[step 89] infos: [{'ale.lives': 0}]\n",
            "[step 90] infos: [{'ale.lives': 0}]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 3/5 [00:01<00:01,  1.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[step 91] infos: [{'ale.lives': 0}]\n",
            "[step 92] infos: [{'ale.lives': 0}]\n",
            "[step 93] infos: [{'ale.lives': 0}]\n",
            "[step 94] infos: [{'ale.lives': 0}]\n",
            "[step 95] infos: [{'ale.lives': 0}]\n",
            "[step 96] infos: [{'ale.lives': 0}]\n",
            "[step 97] infos: [{'ale.lives': 0}]\n",
            "[step 98] infos: [{'ale.lives': 0}]\n",
            "[step 99] infos: [{'ale.lives': 0}]\n",
            "[step 100] infos: [{'ale.lives': 0}]\n",
            "[step 1] infos: [{'ale.lives': 0}]\n",
            "[step 2] infos: [{'ale.lives': 0}]\n",
            "[step 3] infos: [{'ale.lives': 0}]\n",
            "[step 4] infos: [{'ale.lives': 0}]\n",
            "[step 5] infos: [{'ale.lives': 0}]\n",
            "[step 6] infos: [{'ale.lives': 0}]\n",
            "[step 7] infos: [{'ale.lives': 0}]\n",
            "[step 8] infos: [{'ale.lives': 0}]\n",
            "[step 9] infos: [{'ale.lives': 0}]\n",
            "[step 10] infos: [{'ale.lives': 0}]\n",
            "[step 11] infos: [{'ale.lives': 0}]\n",
            "[step 12] infos: [{'ale.lives': 0}]\n",
            "[step 13] infos: [{'ale.lives': 0}]\n",
            "[step 14] infos: [{'ale.lives': 0}]\n",
            "[step 15] infos: [{'ale.lives': 0}]\n",
            "[step 16] infos: [{'ale.lives': 0}]\n",
            "[step 17] infos: [{'ale.lives': 0}]\n",
            "[step 18] infos: [{'ale.lives': 0}]\n",
            "[step 19] infos: [{'ale.lives': 0}]\n",
            "[step 20] infos: [{'ale.lives': 0}]\n",
            "[step 21] infos: [{'ale.lives': 0}]\n",
            "[step 22] infos: [{'ale.lives': 0}]\n",
            "[step 23] infos: [{'ale.lives': 0}]\n",
            "[step 24] infos: [{'ale.lives': 0}]\n",
            "[step 25] infos: [{'ale.lives': 0}]\n",
            "[step 26] infos: [{'ale.lives': 0}]\n",
            "[step 27] infos: [{'ale.lives': 0}]\n",
            "[step 28] infos: [{'ale.lives': 0}]\n",
            "[step 29] infos: [{'ale.lives': 0}]\n",
            "[step 30] infos: [{'ale.lives': 0}]\n",
            "[step 31] infos: [{'ale.lives': 0}]\n",
            "[step 32] infos: [{'ale.lives': 0}]\n",
            "[step 33] infos: [{'ale.lives': 0}]\n",
            "[step 34] infos: [{'ale.lives': 0}]\n",
            "[step 35] infos: [{'ale.lives': 0}]\n",
            "[step 36] infos: [{'ale.lives': 0}]\n",
            "[step 37] infos: [{'ale.lives': 0}]\n",
            "[step 38] infos: [{'ale.lives': 0}]\n",
            "[step 39] infos: [{'ale.lives': 0}]\n",
            "[step 40] infos: [{'ale.lives': 0}]\n",
            "[step 41] infos: [{'ale.lives': 0}]\n",
            "[step 42] infos: [{'ale.lives': 0}]\n",
            "[step 43] infos: [{'ale.lives': 0}]\n",
            "[step 44] infos: [{'ale.lives': 0}]\n",
            "[step 45] infos: [{'ale.lives': 0}]\n",
            "[step 46] infos: [{'ale.lives': 0}]\n",
            "[step 47] infos: [{'ale.lives': 0}]\n",
            "[step 48] infos: [{'ale.lives': 0}]\n",
            "[step 49] infos: [{'ale.lives': 0}]\n",
            "[step 50] infos: [{'ale.lives': 0}]\n",
            "[step 51] infos: [{'ale.lives': 0}]\n",
            "[step 52] infos: [{'ale.lives': 0}]\n",
            "[step 53] infos: [{'ale.lives': 0}]\n",
            "[step 54] infos: [{'ale.lives': 0}]\n",
            "[step 55] infos: [{'ale.lives': 0}]\n",
            "[step 56] infos: [{'ale.lives': 0}]\n",
            "[step 57] infos: [{'ale.lives': 0}]\n",
            "[step 58] infos: [{'ale.lives': 0}]\n",
            "[step 59] infos: [{'ale.lives': 0}]\n",
            "[step 60] infos: [{'ale.lives': 0}]\n",
            "[step 61] infos: [{'ale.lives': 0}]\n",
            "[step 62] infos: [{'ale.lives': 0}]\n",
            "[step 63] infos: [{'ale.lives': 0}]\n",
            "[step 64] infos: [{'ale.lives': 0}]\n",
            "[step 65] infos: [{'ale.lives': 0}]\n",
            "[step 66] infos: [{'ale.lives': 0}]\n",
            "[step 67] infos: [{'ale.lives': 0}]\n",
            "[step 68] infos: [{'ale.lives': 0}]\n",
            "[step 69] infos: [{'ale.lives': 0}]\n",
            "[step 70] infos: [{'ale.lives': 0}]\n",
            "[step 71] infos: [{'ale.lives': 0}]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 4/5 [00:02<00:00,  1.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[step 72] infos: [{'ale.lives': 0}]\n",
            "[step 73] infos: [{'ale.lives': 0}]\n",
            "[step 74] infos: [{'ale.lives': 0}]\n",
            "[step 75] infos: [{'ale.lives': 0}]\n",
            "[step 76] infos: [{'ale.lives': 0}]\n",
            "[step 77] infos: [{'ale.lives': 0}]\n",
            "[step 78] infos: [{'ale.lives': 0}]\n",
            "[step 79] infos: [{'ale.lives': 0}]\n",
            "[step 80] infos: [{'ale.lives': 0}]\n",
            "[step 81] infos: [{'ale.lives': 0}]\n",
            "[step 82] infos: [{'ale.lives': 0}]\n",
            "[step 83] infos: [{'ale.lives': 0}]\n",
            "[step 84] infos: [{'ale.lives': 0}]\n",
            "[step 85] infos: [{'ale.lives': 0}]\n",
            "[step 86] infos: [{'ale.lives': 0}]\n",
            "[step 87] infos: [{'ale.lives': 0}]\n",
            "[step 88] infos: [{'ale.lives': 0}]\n",
            "[step 89] infos: [{'ale.lives': 0}]\n",
            "[step 90] infos: [{'ale.lives': 0}]\n",
            "[step 91] infos: [{'ale.lives': 0}]\n",
            "[step 92] infos: [{'ale.lives': 0}]\n",
            "[step 93] infos: [{'ale.lives': 0}]\n",
            "[step 94] infos: [{'ale.lives': 0}]\n",
            "[step 95] infos: [{'ale.lives': 0}]\n",
            "[step 96] infos: [{'ale.lives': 0}]\n",
            "[step 97] infos: [{'ale.lives': 0}]\n",
            "[step 98] infos: [{'ale.lives': 0}]\n",
            "[step 99] infos: [{'ale.lives': 0}]\n",
            "[step 100] infos: [{'ale.lives': 0}]\n",
            "[step 1] infos: [{'ale.lives': 0}]\n",
            "[step 2] infos: [{'ale.lives': 0}]\n",
            "[step 3] infos: [{'ale.lives': 0}]\n",
            "[step 4] infos: [{'ale.lives': 0}]\n",
            "[step 5] infos: [{'ale.lives': 0}]\n",
            "[step 6] infos: [{'ale.lives': 0}]\n",
            "[step 7] infos: [{'ale.lives': 0}]\n",
            "[step 8] infos: [{'ale.lives': 0}]\n",
            "[step 9] infos: [{'ale.lives': 0}]\n",
            "[step 10] infos: [{'ale.lives': 0}]\n",
            "[step 11] infos: [{'ale.lives': 0}]\n",
            "[step 12] infos: [{'ale.lives': 0}]\n",
            "[step 13] infos: [{'ale.lives': 0}]\n",
            "[step 14] infos: [{'ale.lives': 0}]\n",
            "[step 15] infos: [{'ale.lives': 0}]\n",
            "[step 16] infos: [{'ale.lives': 0}]\n",
            "[step 17] infos: [{'ale.lives': 0}]\n",
            "[step 18] infos: [{'ale.lives': 0}]\n",
            "[step 19] infos: [{'ale.lives': 0}]\n",
            "[step 20] infos: [{'ale.lives': 0}]\n",
            "[step 21] infos: [{'ale.lives': 0}]\n",
            "[step 22] infos: [{'ale.lives': 0}]\n",
            "[step 23] infos: [{'ale.lives': 0}]\n",
            "[step 24] infos: [{'ale.lives': 0}]\n",
            "[step 25] infos: [{'ale.lives': 0}]\n",
            "[step 26] infos: [{'ale.lives': 0}]\n",
            "[step 27] infos: [{'ale.lives': 0}]\n",
            "[step 28] infos: [{'ale.lives': 0}]\n",
            "[step 29] infos: [{'ale.lives': 0}]\n",
            "[step 30] infos: [{'ale.lives': 0}]\n",
            "[step 31] infos: [{'ale.lives': 0}]\n",
            "[step 32] infos: [{'ale.lives': 0}]\n",
            "[step 33] infos: [{'ale.lives': 0}]\n",
            "[step 34] infos: [{'ale.lives': 0}]\n",
            "[step 35] infos: [{'ale.lives': 0}]\n",
            "[step 36] infos: [{'ale.lives': 0}]\n",
            "[step 37] infos: [{'ale.lives': 0}]\n",
            "[step 38] infos: [{'ale.lives': 0}]\n",
            "[step 39] infos: [{'ale.lives': 0}]\n",
            "[step 40] infos: [{'ale.lives': 0}]\n",
            "[step 41] infos: [{'ale.lives': 0}]\n",
            "[step 42] infos: [{'ale.lives': 0}]\n",
            "[step 43] infos: [{'ale.lives': 0}]\n",
            "[step 44] infos: [{'ale.lives': 0}]\n",
            "[step 45] infos: [{'ale.lives': 0}]\n",
            "[step 46] infos: [{'ale.lives': 0}]\n",
            "[step 47] infos: [{'ale.lives': 0}]\n",
            "[step 48] infos: [{'ale.lives': 0}]\n",
            "[step 49] infos: [{'ale.lives': 0}]\n",
            "[step 50] infos: [{'ale.lives': 0}]\n",
            "[step 51] infos: [{'ale.lives': 0}]\n",
            "[step 52] infos: [{'ale.lives': 0}]\n",
            "[step 53] infos: [{'ale.lives': 0}]\n",
            "[step 54] infos: [{'ale.lives': 0}]\n",
            "[step 55] infos: [{'ale.lives': 0}]\n",
            "[step 56] infos: [{'ale.lives': 0}]\n",
            "[step 57] infos: [{'ale.lives': 0}]\n",
            "[step 58] infos: [{'ale.lives': 0}]\n",
            "[step 59] infos: [{'ale.lives': 0}]\n",
            "[step 60] infos: [{'ale.lives': 0}]\n",
            "[step 61] infos: [{'ale.lives': 0}]\n",
            "[step 62] infos: [{'ale.lives': 0}]\n",
            "[step 63] infos: [{'ale.lives': 0}]\n",
            "[step 64] infos: [{'ale.lives': 0}]\n",
            "[step 65] infos: [{'ale.lives': 0}]\n",
            "[step 66] infos: [{'ale.lives': 0}]\n",
            "[step 67] infos: [{'ale.lives': 0}]\n",
            "[step 68] infos: [{'ale.lives': 0}]\n",
            "[step 69] infos: [{'ale.lives': 0}]\n",
            "[step 70] infos: [{'ale.lives': 0}]\n",
            "[step 71] infos: [{'ale.lives': 0}]\n",
            "[step 72] infos: [{'ale.lives': 0}]\n",
            "[step 73] infos: [{'ale.lives': 0}]\n",
            "[step 74] infos: [{'ale.lives': 0}]\n",
            "[step 75] infos: [{'ale.lives': 0}]\n",
            "[step 76] infos: [{'ale.lives': 0}]\n",
            "[step 77] infos: [{'ale.lives': 0}]\n",
            "[step 78] infos: [{'ale.lives': 0}]\n",
            "[step 79] infos: [{'ale.lives': 0}]\n",
            "[step 80] infos: [{'ale.lives': 0}]\n",
            "[step 81] infos: [{'ale.lives': 0}]\n",
            "[step 82] infos: [{'ale.lives': 0}]\n",
            "[step 83] infos: [{'ale.lives': 0}]\n",
            "[step 84] infos: [{'ale.lives': 0}]\n",
            "[step 85] infos: [{'ale.lives': 0}]\n",
            "[step 86] infos: [{'ale.lives': 0}]\n",
            "[step 87] infos: [{'ale.lives': 0}]\n",
            "[step 88] infos: [{'ale.lives': 0}]\n",
            "[step 89] infos: [{'ale.lives': 0}]\n",
            "[step 90] infos: [{'ale.lives': 0}]\n",
            "[step 91] infos: [{'ale.lives': 0}]\n",
            "[step 92] infos: [{'ale.lives': 0}]\n",
            "[step 93] infos: [{'ale.lives': 0}]\n",
            "[step 94] infos: [{'ale.lives': 0}]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 5/5 [00:02<00:00,  1.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[step 95] infos: [{'ale.lives': 0}]\n",
            "[step 96] infos: [{'ale.lives': 0}]\n",
            "[step 97] infos: [{'ale.lives': 0}]\n",
            "[step 98] infos: [{'ale.lives': 0}]\n",
            "[step 99] infos: [{'ale.lives': 0}]\n",
            "[step 100] infos: [{'ale.lives': 0}]\n",
            "Δt = 4.61s\n",
            "================\n",
            "Total Δt = 4.62s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40zclw3dAGcv",
        "colab_type": "code",
        "outputId": "6ca78ead-b76b-40e9-e5d8-931aada3cafe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trajectory_filenames = []\n",
        "for r, ds, fs in os.walk(SAVE_DIR): # r=root, d=directories, f=files\n",
        "    print(r + '/')\n",
        "    for f in fs:\n",
        "        print(\"|___\", f)\n",
        "        trajectory_filenames.append(f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/\n",
            "|___ PongNoFrameskip-v4_PPO2_t54_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t72_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t40_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t40_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t35_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t62_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t52_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t38_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t89_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t48_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t3_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t29_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t11_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t48_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t16_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t18_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t21_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t17_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t53_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t82_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t89_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t47_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t59_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t41_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t65_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t72_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t55_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t77_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t1_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t49_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t94_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t83_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t17_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t35_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t70_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t22_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t34_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t9_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t83_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t15_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t99_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t30_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t16_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t97_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t24_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t64_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t22_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t39_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t84_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t27_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t94_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t19_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t87_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t75_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t47_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t63_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t67_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t50_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t37_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t73_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t55_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t23_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t7_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t54_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t41_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t66_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t37_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t26_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t69_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t25_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t18_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t71_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t98_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t68_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t33_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t73_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t75_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t96_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t79_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t65_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t95_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t36_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t84_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t97_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t26_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t56_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t15_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t45_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t44_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t56_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t79_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t85_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t80_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t2_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t74_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t42_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t27_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t13_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t92_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t23_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t63_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t39_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t5_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t88_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t82_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t20_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t98_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t33_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t4_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t14_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t67_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t31_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t12_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t29_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t12_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t76_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t100_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t85_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t8_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t7_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t77_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t10_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t14_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t60_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t93_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t86_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t57_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t38_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t87_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t70_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t92_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t51_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t60_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t44_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t46_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t81_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t69_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t20_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t46_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t80_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t88_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t13_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t28_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t90_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t100_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t64_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t6_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t61_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t91_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t32_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t11_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t45_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t10_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t99_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t81_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t32_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t93_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t8_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t2_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t76_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t25_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t34_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t24_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t58_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t9_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t30_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t49_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t52_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t57_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t51_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t95_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t62_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t91_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t53_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t78_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t43_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t58_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t74_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t71_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t4_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t50_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t86_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t78_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t31_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t43_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t61_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t19_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t36_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t42_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t59_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t6_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t90_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t3_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t5_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t1_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t68_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t21_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t66_1000s.npz\n",
            "|___ BreakoutNoFrameskip-v4_PPO2_t28_1000s.npz\n",
            "|___ PongNoFrameskip-v4_PPO2_t96_1000s.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td2MzGZK_7ht",
        "colab_type": "code",
        "outputId": "1c8e588d-9e24-446e-d97e-8ae7c9114ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "test_trajectory_filename = trajectory_filenames[0]\n",
        "print(f\"Loading from '{test_trajectory_filename}'\\n\")\n",
        "\n",
        "test_trajectory_load = np.load(os.path.join(SAVE_DIR, test_trajectory_filename), \n",
        "                               allow_pickle=True)\n",
        "\n",
        "print(\"observations shape:\", test_trajectory_load['observations'].shape)\n",
        "print(\"actions shape:\", test_trajectory_load['actions'].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading from 'PongNoFrameskip-v4_PPO2_t54_1000s.npz'\n",
            "\n",
            "observations shape: (1000, 84, 84, 4)\n",
            "actions shape: (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6vHSNX5YFng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/araffin/rl-baselines-zoo/blob/master/utils/record_video.py\n",
        "# https://github.com/araffin/rl-baselines-zoo/blob/master/enjoy.py\n",
        "# https://github.com/hill-a/stable-baselines#try-it-online-with-colab-notebooks-"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-bxg62b_5N7",
        "colab_type": "text"
      },
      "source": [
        "## Old"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ump8v2czCIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def save_as_image(observation, save_dir, img_name, prefix=\"img_\", downscale=False):\n",
        "#     # downscaling the image\n",
        "#     if downscale:\n",
        "#         im_array = cv2.resize(observation, INP_IMAGE_SHAPE) # TODO test tf.image.resize\n",
        "#         im_array = np.array(im_array, dtype='float32')\n",
        "#         im_array = (im_array/127.5) - 1\n",
        "#         im = PIL.Image.fromarray(im_array, 'RGB')\n",
        "#     else:\n",
        "#         try:\n",
        "#             im = PIL.Image.fromarray(observation, 'RGB')\n",
        "#         except:\n",
        "#             print(type(observation))\n",
        "#     imname = \"{}{}.png\".format(prefix, img_name)\n",
        "#     im.save(os.path.join(save_dir, imname))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n74gjFzbzkJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # you can change the default values here\n",
        "# save_dir = SAVE_DIR\n",
        "# num_images = IMAGES_TO_GENERATE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wd6qHz4zyp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os.makedirs(save_dir, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHKIU3Vn0AcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# envs = [gym.make(env_id) for env_id in ENV_IDS]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z4YJ4XV0HF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for env_id, env in zip(ENV_IDS, envs):\n",
        "#     print(env_id)\n",
        "#     env_dir = os.path.join(save_dir, f\"{env_id}_{IMAGES_TO_GENERATE}\")\n",
        "#     os.makedirs(env_dir, exist_ok=True)\n",
        "    \n",
        "#     env.reset()\n",
        "#     i, current_env_images = 0, 0\n",
        "    \n",
        "#     actions_taken = []\n",
        "#     while i < num_images:\n",
        "#         # take a random action (sampled from the action space)\n",
        "#         action = env.action_space.sample()\n",
        "#         actions_taken.append(action)\n",
        "#         assert 0 <= action < 18, f\"action = {action}\"\n",
        "#         obs, _, done, _ = env.step(action)\n",
        "#         if np.mean(obs) > 0.01:\n",
        "#             save_as_image(obs, env_dir, str(i))\n",
        "#             i += 1\n",
        "#         else:\n",
        "#             print(\"should I have been reached?\")\n",
        "#             continue\n",
        "#         if done:\n",
        "#             print(f\"reseting {env_id} at i={i}\")\n",
        "#             env.reset()\n",
        "    \n",
        "#     actions_taken = np.asarray(actions_taken, dtype='int8')\n",
        "#     print(actions_taken.shape, actions_taken.size, actions_taken.dtype)\n",
        "#     np.save(os.path.join(save_dir, f\"{env_id}_{IMAGES_TO_GENERATE}_actions\"), actions_taken)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NZCKFvS4J3sd",
        "colab": {}
      },
      "source": [
        "# IMG_SIZE = 160 # All images will be resized to 160x160\n",
        "\n",
        "# def load_image(image_path):\n",
        "#     image = tf.io.read_file(image_path)\n",
        "#     image = tf.image.decode_png(image, channels=3)\n",
        "#     image = tf.cast(image, tf.float32)\n",
        "#     image = (image/127.5) - 1\n",
        "#     image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "#     return image, image_path\n",
        "\n",
        "# IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# # Create the base model from the pre-trained model MobileNet V2\n",
        "# base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "#                                                include_top=False,\n",
        "#                                                weights='imagenet')\n",
        "\n",
        "# s = time()\n",
        "# # Get unique images\n",
        "# encode_train = img_name_vector\n",
        "\n",
        "# # Feel free to change batch_size according to your system configuration\n",
        "# image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\n",
        "# image_dataset = image_dataset.map(\n",
        "#   load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)\n",
        "\n",
        "# print((time()-s)/1000)\n",
        "\n",
        "# for img, path in image_dataset:\n",
        "#   batch_features = image_features_extract_model(img)\n",
        "#   batch_features = tf.reshape(batch_features,\n",
        "#                               (batch_features.shape[0], -1, batch_features.shape[3]))\n",
        "\n",
        "#   for bf, p in zip(batch_features, path):\n",
        "#     path_of_feature = p.numpy().decode(\"utf-8\")\n",
        "#     np.save(path_of_feature, bf.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}