{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trajectories.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurelkeys/machine-learning/blob/master/assignment-4/Trajectories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z29bPFt3BKSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "# PATH_TO_DATA = os.path.join(\"drive\", \"My Drive\", \"unicamp\", \"MC886\", \"atari\")\n",
        "\n",
        "PATH_TO_DATA = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yg8oJkJBPW1",
        "colab_type": "code",
        "outputId": "85a16bde-d4a8-4e1d-e8ae-fc648a507225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "SAVE_DIR = os.path.join(PATH_TO_DATA, \"data\")\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "SAVE_DIR # where the trajectories for each game will be saved to"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-pfFDVVBTX6",
        "colab_type": "code",
        "outputId": "28903740-9b52-4e38-9969-682835c8f674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "LOG_DIR = os.path.join(PATH_TO_DATA, \"data\", \"results\")\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "LOG_DIR # where the stats for each game will be saved to"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data/results'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxiF53dtcx5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of trajectories to generate\n",
        "N_OF_TRAJECTORIES = 5\n",
        "\n",
        "# number of steps per trajectory\n",
        "N_OF_STEPS = 1000\n",
        "\n",
        "# list of string tuples in the format (RL Algorithm, Game Environment)\n",
        "GAMES = [\n",
        "    (\"PPO2\", \"BreakoutNoFrameskip-v4\"),\n",
        "    (\"PPO2\", \"PongNoFrameskip-v4\"),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0nFoCbqBlhv",
        "colab_type": "text"
      },
      "source": [
        "## Install dependencies\n",
        "Note that we're not installing [MPI](https://mpi4py.readthedocs.io/en/stable/), so these algorithms will probably not work: `DDPG`, `GAIL`, `PPO1`, `TRPO`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHfq9U0pBpEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get update                                                  > /dev/null 2>&1\n",
        "!apt-get install swig cmake zlib1g-dev ffmpeg freeglut3-dev xvfb > /dev/null 2>&1\n",
        "!pip install pytablewriter                                       > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kObMTO5_BzKK",
        "colab_type": "code",
        "outputId": "69b8e7e0-052d-4ff9-ab30-29038c487059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#### Stable Baselines only supports TF 1.x for now ####\n",
        "try:\n",
        "    # Colab only\n",
        "    %tensorflow_version 1.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrzGDVIYB4TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from time import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# NOTE use tqdm.write() instead of print() inside of tqdm wrapped loops\n",
        "from tqdm import tqdm\n",
        "\n",
        "import gym\n",
        "from gym.envs.atari.atari_env import ACTION_MEANING"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtHWjpwKCAqF",
        "colab_type": "text"
      },
      "source": [
        "### Update [Stable Baselines](https://github.com/hill-a/stable-baselines) and clone [RL Zoo Baselines](https://github.com/araffin/rl-baselines-zoo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGg59yj4CCWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!yes | pip uninstall stable-baselines                           > /dev/null 2>&1\n",
        "!pip install git+https://github.com/hill-a/stable-baselines.git > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uoafLRoCEM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from stable_baselines.common.cmd_util import make_atari_env\n",
        "from stable_baselines.common.vec_env import VecFrameStack\n",
        "\n",
        "# HACK to save logs\n",
        "from stable_baselines import logger\n",
        "os.environ[\"OPENAI_LOG_FORMAT\"] = 'stdout,log,csv,tensorboard'\n",
        "os.environ[\"OPENAI_LOGDIR\"] = os.path.abspath(LOG_DIR)\n",
        "logger.configure(folder=os.path.abspath(LOG_DIR), format_strs=['stdout', 'log', 'csv', 'tensorboard'])\n",
        "\n",
        "# NOTE add more algorithms here if you want to use them\n",
        "from stable_baselines import PPO2, ACER, ACKTR\n",
        "ALGO_IMPL = {\n",
        "    'PPO2': PPO2,\n",
        "    'ACER': ACER,\n",
        "    'ACKTR': ACKTR,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMaHETmpCKms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/araffin/rl-baselines-zoo.git > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjB4SzAnCPlT",
        "colab_type": "text"
      },
      "source": [
        "## Load pre-trained agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ9jc42VCVNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_AGENTS = os.path.join(\"rl-baselines-zoo\", \"trained_agents\")\n",
        "!ls rl-baselines-zoo/trained_agents/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKIUEECQCXtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ext = \"NoFrameskip-v4.pkl\"\n",
        "# check the available pre-trained models\n",
        "algorithms = [\"PPO2\"]\n",
        "for algo in algorithms:\n",
        "    algo_path = os.path.join(PATH_TO_AGENTS, algo.lower())\n",
        "    print(algo_path + '/')\n",
        "    for f in sorted(os.listdir(algo_path), key=lambda x: x[::-1]):\n",
        "        # sort by the reversed filename, so env types get grouped together\n",
        "        if f.endswith(ext):\n",
        "            print(\"├──\", f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6CwssmOCb9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(2):\n",
        "    clear_output() # HACK to remove TensorFlow warnings\n",
        "    for algo, env_id in GAMES:\n",
        "        print(f\"('{algo}', '{env_id}')\")\n",
        "        agent_path = os.path.join(PATH_TO_AGENTS, algo.lower(), env_id + '.pkl')\n",
        "        model = ALGO_IMPL[algo].load(agent_path, verbose=0)\n",
        "        print(\"observation_space:\", model.observation_space)\n",
        "        print(\"action_space:\", model.action_space)\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stlirTJ_RkZJ",
        "colab_type": "text"
      },
      "source": [
        "## Monitor vectorized environments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZHrv2IERnN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import json\n",
        "from collections import deque\n",
        "\n",
        "from stable_baselines.common.vec_env import VecEnvWrapper\n",
        "\n",
        "class VecMonitor(VecEnvWrapper):\n",
        "    EXT = \"monitor.csv\"\n",
        "    \n",
        "    def __init__(self, venv, filename=None, keep_buf=0, info_keywords=()):\n",
        "        VecEnvWrapper.__init__(self, venv)\n",
        "        self.eprets = None\n",
        "        self.eplens = None\n",
        "        self.epcount = 0\n",
        "        self.tstart = time()\n",
        "        if filename:\n",
        "            if logger.get_dir() is not None and os.path.isdir(logger.get_dir()):\n",
        "                filename = os.path.join(logger.get_dir(), filename)\n",
        "            self.results_writer = ResultsWriter(filename, \n",
        "                                                header={'t_start': self.tstart},\n",
        "                                                extra_keys=info_keywords)\n",
        "        else:\n",
        "            self.results_writer = None\n",
        "        self.info_keywords = info_keywords\n",
        "        self.keep_buf = keep_buf\n",
        "        if self.keep_buf:\n",
        "            self.epret_buf = deque([], maxlen=keep_buf)\n",
        "            self.eplen_buf = deque([], maxlen=keep_buf)\n",
        "\n",
        "    def reset(self):\n",
        "        obs = self.venv.reset()\n",
        "        self.eprets = np.zeros(self.num_envs, 'f')\n",
        "        self.eplens = np.zeros(self.num_envs, 'i')\n",
        "        return obs\n",
        "\n",
        "    def step_wait(self):\n",
        "        obs, rews, dones, infos = self.venv.step_wait()\n",
        "        self.eprets += rews\n",
        "        self.eplens += 1\n",
        "\n",
        "        newinfos = list(infos[:])\n",
        "        for i in range(len(dones)):\n",
        "            if dones[i]:\n",
        "                info = infos[i].copy()\n",
        "                ret = self.eprets[i]\n",
        "                eplen = self.eplens[i]\n",
        "                epinfo = {'r': ret, 'l': eplen, 't': round(time() - self.tstart, 6)}\n",
        "                for k in self.info_keywords:\n",
        "                    try:\n",
        "                        epinfo[k] = info[k]\n",
        "                    except:\n",
        "                        pass # HACK to log 'episode' info for Atari envs\n",
        "                info['episode'] = epinfo\n",
        "                if self.keep_buf:\n",
        "                    self.epret_buf.append(ret)\n",
        "                    self.eplen_buf.append(eplen)\n",
        "                self.epcount += 1\n",
        "                self.eprets[i] = 0\n",
        "                self.eplens[i] = 0\n",
        "                if self.results_writer:\n",
        "                    self.results_writer.write_row(epinfo)\n",
        "                newinfos[i] = info\n",
        "        return obs, rews, dones, newinfos\n",
        "        \n",
        "class ResultsWriter(object):\n",
        "    def __init__(self, filename, header='', extra_keys=()):\n",
        "        self.extra_keys = extra_keys\n",
        "        assert filename is not None\n",
        "        if not filename.endswith(VecMonitor.EXT):\n",
        "            os.makedirs(filename, exist_ok=True)\n",
        "            filename = os.path.join(filename, VecMonitor.EXT)\n",
        "            # if os.path.isdir(filename):\n",
        "            #     filename = os.path.join(filename, VecMonitor.EXT)\n",
        "            # else:\n",
        "            #     filename = f\"{filename}.{VecMonitor.EXT}\"\n",
        "        self.f = open(filename, \"wt\")\n",
        "        if isinstance(header, dict):\n",
        "            header = '# {} \\n'.format(json.dumps(header))\n",
        "        self.f.write(header)\n",
        "        self.logger = csv.DictWriter(self.f, fieldnames=('r', 'l', 't')+tuple(extra_keys))\n",
        "        self.logger.writeheader()\n",
        "        self.f.flush()\n",
        "\n",
        "    def write_row(self, epinfo):\n",
        "        if self.logger:\n",
        "            self.logger.writerow(epinfo)\n",
        "            self.f.flush()        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaxY9IxFCyaZ",
        "colab_type": "text"
      },
      "source": [
        "## Generate trajectories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS3Jr8O5C-A-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VERBOSE = 2 # 0, 1 or 2\n",
        "\n",
        "print(\"N_OF_STEPS:\", N_OF_STEPS)\n",
        "print(\"N_OF_TRAJECTORIES:\", N_OF_TRAJECTORIES)\n",
        "print(N_OF_STEPS, \"*\", N_OF_TRAJECTORIES, \"=\", N_OF_STEPS * N_OF_TRAJECTORIES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls6Uw4PnDAsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set to False to save observations as PNG and store their location path, \n",
        "# instead of saving them as numpy arrays (which end up taking more space)\n",
        "SAVE_IMAGES_AS_NUMPY_ARRAYS = False\n",
        "\n",
        "PRINT_EARLY_DONE = False # print env resets in a trajectory\n",
        "PRINT_ACTIONS_TAKEN = True # print the meanings of actions\n",
        "PRINT_ATARI_EPISODE = False # print 'episode' if available\n",
        "\n",
        "# set to N_OF_TRAJECTORIES + 1 not to print\n",
        "PRINT_EVERY_N_TRAJECTORIES = N_OF_TRAJECTORIES // 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HSnlYyfEDrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"N_OF_STEPS:\", N_OF_STEPS)\n",
        "print(\"N_OF_TRAJECTORIES:\", N_OF_TRAJECTORIES)\n",
        "print(\"PRINT_EVERY_N_TRAJECTORIES:\", PRINT_EVERY_N_TRAJECTORIES)\n",
        "\n",
        "time_start = time()\n",
        "print(\"\\n================\")\n",
        "\n",
        "for algo, env_id in GAMES:\n",
        "    time_start_env = time()\n",
        "    \n",
        "    # setup paths where data will be saved to\n",
        "    dataset_folder = f\"{env_id}_{algo}_{N_OF_STEPS}steps\"\n",
        "    if not SAVE_IMAGES_AS_NUMPY_ARRAYS:\n",
        "        images_folder = os.path.join(SAVE_DIR, dataset_folder, \"images\")\n",
        "        os.makedirs(images_folder, exist_ok=True)\n",
        "        if VERBOSE > 0:\n",
        "            print(f\"Images will be recorded to '{images_folder}/'\\n\")\n",
        "\n",
        "    env = make_atari_env(env_id, num_env=1, seed=0)\n",
        "    env = VecFrameStack(env, n_stack=4) # Frame-stacking with 4 frames\n",
        "    env = VecMonitor(env, f\"{algo}-{env_id}\", info_keywords=('episode',))\n",
        "    agent_path = os.path.join(PATH_TO_AGENTS, algo.lower(), env_id + '.pkl')\n",
        "\n",
        "    print(f\"('{algo}', '{env_id}')\")\n",
        "    print(f\"Getting pre-trained agent from: '{agent_path}'\\n\")\n",
        "\n",
        "    model = ALGO_IMPL[algo].load(agent_path, env)\n",
        "    \n",
        "    for trajectory in tqdm(range(N_OF_TRAJECTORIES), position=0, leave=True):\n",
        "        # store the \"obs -> action\" mapping\n",
        "        observed_states, actions_taken = [], []\n",
        "        \n",
        "        # episode stats\n",
        "        ep_rewards, ep_starts = np.zeros((N_OF_STEPS,)), [True]\n",
        "        \n",
        "        # NOTE action, obs, reward, done and info are \n",
        "        #      arrays as we're using a vectorized env\n",
        "        \n",
        "        obs = env.reset() # (84, 84, 4)\n",
        "        for step in range(N_OF_STEPS):\n",
        "            observed_states.append(obs[0])\n",
        "            action, _ = model.predict(obs)\n",
        "            actions_taken.append(action[0])\n",
        "            obs, reward, done, info = env.step(action)\n",
        "            ep_starts.append(done[0])\n",
        "            ep_rewards[step] = reward[0]\n",
        "            if info is not None and PRINT_ATARI_EPISODE:\n",
        "                ep_info = info[0].get('episode')\n",
        "                if ep_info is not None:\n",
        "                    tqdm.write(\"\\n ****************\")\n",
        "                    tqdm.write(f\" Atari Episode Score: {ep_info['r']:.2f}\")\n",
        "                    tqdm.write(f\" Atari Episode Length: {ep_info['l']}\")\n",
        "                    tqdm.write(\" ****************\")\n",
        "            if done[0]:\n",
        "                obs = env.reset()\n",
        "                if PRINT_EARLY_DONE:\n",
        "                    tqdm.write(f\" Done at step {step} (reseting env)\")\n",
        "        \n",
        "        # left pad the trajectory number with 0's\n",
        "        trajectory_number = str(trajectory).zfill(len(str(N_OF_TRAJECTORIES - 1)))\n",
        "\n",
        "        if not SAVE_IMAGES_AS_NUMPY_ARRAYS:\n",
        "            _observed_states = [] # store image paths\n",
        "            for step, obs in enumerate(observed_states):\n",
        "                image_folder = os.path.join(images_folder, trajectory_number)\n",
        "                os.makedirs(image_folder, exist_ok=True)\n",
        "                image_path = os.path.join(image_folder, f\"{str(step).zfill(len(str(N_OF_STEPS - 1)))}.png\")\n",
        "                if obs.shape[-1] == 3:\n",
        "                    obs = cv2.cvtColor(obs, cv2.COLOR_RGB2BGR)\n",
        "                cv2.imwrite(image_path, obs) #, [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
        "                _observed_states.append(image_path)\n",
        "            observed_states = np.array(_observed_states)\n",
        "        else:\n",
        "            observed_states = np.concatenate(observed_states).reshape((-1,) + env.observation_space.shape)\n",
        "\n",
        "        actions_taken = np.array(actions_taken)\n",
        "        ep_starts = np.array(ep_starts[:-1])\n",
        "\n",
        "        data = {\n",
        "            'actions': actions_taken,\n",
        "            'observations': observed_states,\n",
        "            'rewards': ep_rewards,\n",
        "            'episode_starts': ep_starts\n",
        "        } # type: Dict[str, np.ndarray]\n",
        "\n",
        "        save_folder = os.path.join(SAVE_DIR, dataset_folder, trajectory_number)\n",
        "        os.makedirs(save_folder, exist_ok=True)\n",
        "        np.savez_compressed(file=os.path.join(save_folder, \"trajectory\"), **data)\n",
        "        \n",
        "        if (trajectory + 1) % 10 == 0:\n",
        "            tqdm.write(f\" Saved trajectory {trajectory + 1} (of {N_OF_TRAJECTORIES})\")\n",
        "            if VERBOSE > 1:\n",
        "                tqdm.write(f\" Mean reward: {np.mean(ep_rewards):.2f}, ep_rewards.shape == {ep_rewards.shape}\")\n",
        "\n",
        "        if PRINT_ACTIONS_TAKEN and trajectory == N_OF_TRAJECTORIES - 1:\n",
        "            tqdm.write(f\"\\n Actions taken: {', '.join([ACTION_MEANING[action] for action in set(actions_taken)])}\")\n",
        "    \n",
        "    env.close()\n",
        "    print(f\" Δt = {(time() - time_start_env):.2f}s\")\n",
        "    print(\"================\\n\")\n",
        "\n",
        "print(f\"Total Δt = {(time() - time_start):.2f}s\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnxuOeekJgqw",
        "colab_type": "text"
      },
      "source": [
        "## Load results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzjczWiNSjce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from stable_baselines.bench.monitor import get_monitor_files\n",
        "from stable_baselines.results_plotter import load_results, ts2xy\n",
        "\n",
        "!ls /content/data/results/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YsNV7X6g5pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def monitor_info(monitor_file_path, print_info=True):\n",
        "    results = load_results(monitor_file_path)\n",
        "    x, y = ts2xy(results, 'timesteps')\n",
        "    if print_info:\n",
        "        # print(\"x:\", x) # x == results['l']\n",
        "        # print(\"y:\", y) # y == results['r']\n",
        "        print(f\"Mean reward: {np.mean(y):.2f} +- {np.std(y):.2f}\")\n",
        "        print(f\"Number of timesteps: {x[-1]}\")\n",
        "        print(f\"Number of episodes: {len(y)}\") # trajectories\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRtQry0_hzg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "monitor_info(LOG_DIR) # data/results/0.monitor.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxuTC_zFdzmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for algo, env_id in GAMES:\n",
        "    monitor_folder_path = os.path.join(LOG_DIR, f\"{algo}-{env_id}\")\n",
        "    print(get_monitor_files(monitor_folder_path))\n",
        "    monitor_info(monitor_folder_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQmOI5ozJe6Z",
        "colab_type": "text"
      },
      "source": [
        "## Zip data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n6nR9pJjmg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF4usP_fhpg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/data.zip /content/data > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q26xcGsWkME6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -la | grep .zip\n",
        "!ls -lh | grep .zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phjtQowPGHqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWqkjFZ0k8a5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# files.download(\"/content/data.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txkWJnDElQbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# larger files may not work, try looking at:\n",
        "# https://stackoverflow.com/questions/49428332/how-to-download-large-files-like-weights-of-a-model-from-colaboratory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoGekcDrieGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded_data = False\n",
        "\n",
        "try:\n",
        "    files.download(\"/content/data.zip\")\n",
        "    downloaded_data = True\n",
        "except:\n",
        "    from google.colab import auth\n",
        "    from googleapiclient.http import MediaFileUpload\n",
        "    from googleapiclient.discovery import build\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pmyfpILi2Bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not downloaded_data:\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}