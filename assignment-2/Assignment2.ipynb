{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libs and loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [2, 2]\n",
    "sns.set() # apply the seaborn defaults to plotted figures (e.g. theme, scaling, color palette), instead of matplotlib's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Computational Graph definition and implementation\n",
    "\n",
    "We will define a Computational Graph [[ref]](https://colah.github.io/posts/2015-08-Backprop/) where each node either represents a value (i.e. what will later be a **layer** in a neural network) or a computation (i.e. an operation like the **activation** or **cost** functions in a neural network).\n",
    "\n",
    "With it we can then represent both an artificial neural network, aswell as a softmax regressor (which performs Multinomial Logistic Regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from time import time\n",
    "\n",
    "RANDOM_SEED = 886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction:\n",
    "    ''' An ActivationFunction is applied to Z to get the output A, \n",
    "        but its derivative expects the value A, not Z (!):\n",
    "\n",
    "        A == __call__(Z) and derivative(A) == derivative(__call__(Z)), \n",
    "        calling derivative(Z) will often yield WRONG results\n",
    "    '''\n",
    "    def __call__(self, Z):\n",
    "        ''' Z.shape=(n_examples, layer_output_size) '''\n",
    "        raise NotImplementedError    \n",
    "    def derivative(self, A):\n",
    "        ''' A.shape=(n_examples, layer_output_size) '''\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Sigmoid(ActivationFunction):\n",
    "    def __call__(self, Z, clip=500):\n",
    "        Z = np.clip(Z, -clip, clip) # numerical stability\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    def derivative(self, A):\n",
    "        return A * (1 - A) # Sigmoid(Z) * (1 - Sigmoid(Z))\n",
    "\n",
    "class ReLU(ActivationFunction):\n",
    "    def __call__(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "    def derivative(self, A):\n",
    "        return np.where(A > 0, 1, 0)\n",
    "\n",
    "class SoftMax(ActivationFunction):\n",
    "    def __call__(self, Z):\n",
    "        exp = np.exp(Z - Z.max(axis=1, keepdims=True))\n",
    "        return exp / np.sum(exp, axis=1, keepdims=True)\n",
    "    def derivative(self, A, eps=1e-9):\n",
    "        Ypred = A+eps\n",
    "        return Ypred * (1 - Ypred) # SoftMax(Z) * (1 - SoftMax(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostFunction:\n",
    "    ''' A CostFunction is applied to Y (the target values) and Ypred (the predicted values) to get a scalar output\n",
    "        Its derivative w.r.t. Ypred also expects Y and Ypred, but returns a tensor of shape (n_examples, last_layer_output_size)\n",
    "        \n",
    "        obs.: Ypred is the last layer's activation values: last_layer.A == last_layer.g(last.layer.Z), \n",
    "              i.e. last_layer is the output layer of the network\n",
    "    '''\n",
    "    def __call__(self, Y, Ypred):\n",
    "        ''' Y.shape == Ypred.shape == (n_examples, last_layer_output_size) '''\n",
    "        raise NotImplementedError # [J(Y, Ypred) == J(Y, A^L)]\n",
    "    def derivative(self, Y, Ypred):\n",
    "        ''' Y.shape == Ypred.shape == (n_examples, last_layer_output_size) '''\n",
    "        raise NotImplementedError # [dJ/dYpred == dJ/dA^L]\n",
    "    def deltaL(self, Y, Ypred, activation_function, Z):\n",
    "        ''' Y.shape == Ypred.shape == (n_examples, last_layer_output_size) \n",
    "\n",
    "            activation_function should be the last layer's g function, thus Ypred == activation_function(Z)\n",
    "            and the value returned is the delta for the output layer of the network (delta^L == dJ/dZ^L)\n",
    "        '''\n",
    "        return self.derivative(Y, Ypred) * activation_function.derivative(Z) # [dJ/dZ^L == dJ/dYpred . dYpred/dZ^L]\n",
    "        # obs.: Ypred == A^L == g(Z^L), thus dYpred/dZ^L == dA^L/dZ^L == g'(Z^L)\n",
    "        #       [dJ/dZ^L == dJ/dYpred . dYpred/dZ^L == dJ/dA^L . dA^L/dZ^L]\n",
    "\n",
    "class CrossEntropy(CostFunction):\n",
    "    def __call__(self, Y, Ypred, eps=1e-9):\n",
    "        return np.mean( -(Y * np.log(Ypred+eps)).sum(axis=1) )\n",
    "    def derivative(self, Y, Ypred, eps=1e-9):\n",
    "        m = Ypred.shape[0]\n",
    "        return - (Y / (Ypred+eps)) / m\n",
    "    def deltaL(self, Y, Ypred, activation_function, Z):\n",
    "        if isinstance(activation_function, SoftMax):\n",
    "            m = Ypred.shape[0]\n",
    "            # numerically stable\n",
    "            return (Ypred - Y) / m # (SoftMax(Z) - Y) / m\n",
    "        else:\n",
    "            return super().deltaL(Y, Ypred, activation_function, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME test if eps are really necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    ''' The optimizer's optimization policy should be implemented on its update(layers) function '''\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "    def update(self, layers):\n",
    "        ''' Updates the parameters (i.e. weights and biases) for each layer in the layers list '''\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GradientDescent(Optimizer):\n",
    "    def __init__(self, learning_rate):\n",
    "        super().__init__(learning_rate)\n",
    "    def update(self, layers):\n",
    "        for layer in layers[1:]:\n",
    "            layer.W -= self.learning_rate * layer.dW\n",
    "            layer.b -= self.learning_rate * layer.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    ''' A.shape == (n_examples, output_size)\n",
    "        Z.shape == (n_examples, output_size)\n",
    "        W.shape == (input_size, output_size)\n",
    "        b.shape == (output_size, )\n",
    "        X.shape == (n_examples, input_size)\n",
    "        obs.:\n",
    "            input_size == prev_layer.output_size\n",
    "            output_size == next_layer.input_size\n",
    "    '''\n",
    "    def __init__(self, output_size, activation_function):\n",
    "        if activation_function != None:\n",
    "            # obs.: the activation_function should only be None for the network's input layer\n",
    "            assert(isinstance(activation_function, ActivationFunction)), \"Invalid object type for activation_function\"\n",
    "        \n",
    "        self.input_size = None\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # activation function\n",
    "        self.g = activation_function # g_prime == activation_function.derivative\n",
    "        \n",
    "        # activation values\n",
    "        self.A = None # self.A == self.g(self.Z)\n",
    "        self.Z = None # prev_layer.A @ self.W + self.b\n",
    "        \n",
    "        # output value of the previous layer\n",
    "        self.X = None # == prev_layer.A\n",
    "        self.dX = None\n",
    "        \n",
    "        # parameters (weights and biases)\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "    \n",
    "    def init(self, input_size, weight_initialization):\n",
    "        ''' Sets the layer's input_size and initializes its weights and biases '''\n",
    "        self.input_size = input_size\n",
    "        if weight_initialization == 'xavier':\n",
    "            stddev = np.sqrt(1 / self.input_size)\n",
    "            self.W = stddev * np.random.randn(self.input_size, self.output_size)\n",
    "            self.b = np.random.randn(self.output_size, )\n",
    "        elif weight_initialization == 'xavier_avg':\n",
    "            stddev = np.sqrt(2 / (self.input_size + self.output_size))\n",
    "            self.W = stddev * np.random.randn(self.input_size, self.output_size)\n",
    "            self.b = np.random.randn(self.output_size, )\n",
    "        elif weight_initialization == 'rand_-1_to_1':\n",
    "            self.W = 2 * np.random.randn(self.input_size, self.output_size) - 1\n",
    "            self.b = 2 * np.random.randn(self.output_size, ) - 1\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid weight_initialization value: '{weight_initialization}'\")\n",
    "    \n",
    "    @property\n",
    "    def params_count(self):\n",
    "        return self.W.size + self.b.size\n",
    "    \n",
    "    # receives the activation values of the previous layer (i.e. this layer's input)\n",
    "    # returns the activation values of the current layer (i.e. next layer's input)\n",
    "    def feedforward(self, X):\n",
    "        ''' X.shape == (n_examples, self.input_size) '''\n",
    "        assert(X.shape[1] == self.input_size)\n",
    "        self.X = X\n",
    "        # (n_examples, output_size) = (n_examples, input_size) @ (input_size, output_size) + (output_size, )\n",
    "        self.Z = self.X @ self.W + self.b\n",
    "        self.A = self.g(self.Z)\n",
    "        return self.A\n",
    "    \n",
    "    # receives the derivative of the cost function w.r.t. the Z value of the current layer [dJ/dZ = dJ/dA . dA/dZ]\n",
    "    # returns the derivative of the cost function w.r.t. the A value of the previous layer [dJ/dX = dJ/dZ . dZ/dX]\n",
    "    # obs.: the A value of the previous layer is this layer's input value X\n",
    "    def backprop(self, dZ):\n",
    "        ''' dZ.shape == (n_examples, self.output_size)\n",
    "        \n",
    "            Note that only calling backprop doesn't actually update the layer parameters\n",
    "        '''\n",
    "        assert(dZ.shape[1] == self.output_size)\n",
    "        # (input_size, output_size) = (input_size, n_examples)  @ (n_examples, output_size)\n",
    "        # (output_size, )           = (n_examples, output_size).sum(axis=0)\n",
    "        # (n_examples, input_size)  = (n_examples, output_size) @ (output_size, input_size), input_size==prev_layer.output_size\n",
    "        self.dW = (self.X).T @ dZ              # [dJ/dW = dJ/dZ . dZ/dX]\n",
    "        self.db = dZ.sum(axis=0)               # [dJ/db = dJ/dZ . dZ/db]\n",
    "        self.dX = dZ @ (self.W).T              # [dJ/dX = dJ/dZ . dZ/dX]\n",
    "        return self.dX\n",
    "        # note that dJ/dX is dJ/dA for the previous layer (since this layer's input X is the previous layer's A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputationalGraph:\n",
    "    def __init__(self, layers, cost_function, optimizer, weight_initialization='xavier'):\n",
    "        assert(isinstance(cost_function, CostFunction)), \"Invalid object type for cost_function\"\n",
    "        \n",
    "        self.J = cost_function # cost_function(Y, Ypred)\n",
    "        # obs.: cost_function.derivative is the derivative of J w.r.t. the last layer's activation values [dJ/dYpred]\n",
    "        #       Ypred == self.layers[-1].A, thus [dJ/dYpred == dJ/dA^L]\n",
    "        #\n",
    "        #       cost_function.deltaL is the derivative of J w.r.t. the last layer's Z values [dJ/dZ^L]\n",
    "        #       Z^L == self.layers[-1].Z, thus [dJ/dZ^L == dJ/dA^L . dA^L/dZ^L == dJ/dYpred . dYpred/dZ^L]\n",
    "        \n",
    "        self.optimizer = optimizer # obs.: the learning rate is set on the optimizer object\n",
    "        \n",
    "        self.layers = []\n",
    "        # obs.: we don't call init for the input layer since we set it's activation values manually\n",
    "        layers[0].input_size = layers[0].output_size\n",
    "        self.layers.append(layers[0]) # input layer\n",
    "        for l in range(1, len(layers)):            \n",
    "            # sets the layer's input_size as the last layer's output_size and initializes its weights and biases\n",
    "            layers[l].init(input_size=layers[l-1].output_size, weight_initialization=weight_initialization)            \n",
    "            self.layers.append(layers[l]) # adds the initialized layer to the network\n",
    "        \n",
    "        self.history = { \"loss\": [], \"loss_val\": [], \"acc\": [], \"acc_val\": [] }\n",
    "    \n",
    "    # note that we use zero-based indexing here, so\n",
    "    # the 1st layer is self.layers[0] and the last is self.layers[len(self.layers) - 1]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ''' X.shape == (n_examples, self.layers[0].input_size) '''\n",
    "        assert(X.shape[1] == self.layers[0].output_size) # self.layers[0].input_size == self.layers[0].output_size\n",
    "        activation = X # network's input\n",
    "        for l in range(1, len(self.layers)):\n",
    "            Z = activation @ self.layers[l].W + self.layers[l].b\n",
    "            activation = self.layers[l].g(Z)\n",
    "        return activation # network's output (Ypred)\n",
    "    \n",
    "    def feedforward(self, X):\n",
    "        ''' X.shape     == (n_examples, self.layers[0].input_size) '''\n",
    "        assert(X.shape[1] == self.layers[0].output_size) # self.layers[0].input_size == self.layers[0].output_size\n",
    "        self.layers[0].A = X # input\n",
    "        for l in range(1, len(self.layers)):\n",
    "            self.layers[l].feedforward(self.layers[l-1].A)\n",
    "        Ypred = self.layers[-1].A # output\n",
    "        return Ypred\n",
    "    \n",
    "    def backprop(self, X, Y, Ypred):\n",
    "        ''' X.shape     == (n_examples, self.layers[0].input_size)\n",
    "            Y.shape     == (n_examples, self.layers[-1].output_size)\n",
    "            Ypred.shape == (n_examples, self.layers[-1].output_size)\n",
    "            where Ypred is the result of feedforward(X)\n",
    "            \n",
    "            Note that only calling backprop doesn't actually update the network parameters\n",
    "        '''\n",
    "        assert(X.shape[0] == Y.shape[0])\n",
    "        assert(X.shape[1] == self.layers[0].output_size) # self.layers[0].input_size == self.layers[0].output_size\n",
    "        assert(Y.shape[1] == self.layers[-1].output_size)\n",
    "        assert(Ypred.shape == Y.shape)\n",
    "        \n",
    "        delta = self.J.deltaL(Y, Ypred, self.layers[-1].g, self.layers[-1].A) # delta^L == [dJ/dZ^L]\n",
    "        self.layers[-1].backprop(dZ=delta)\n",
    "        for l in reversed(range(1, len(self.layers) - 1)):\n",
    "            # [dJ/dZ^l == dJ/dA^l . dA^l/dZ^l], note that dJ/dA^l is dJ/dX^{l+1}\n",
    "            delta = self.layers[l+1].dX * self.layers[l].g.derivative(self.layers[l].Z) # delta^l == [dJ/dZ^l]\n",
    "            self.layers[l].backprop(dZ=delta)\n",
    "        \n",
    "        # obs.: we don't backpropagate the input layer since we \n",
    "        #       manually set it's activation values A to the network's input X\n",
    "    \n",
    "    def __shuffle_X_Y(self, X, Y):\n",
    "        m = X.shape[0] # == Y.shape[0]\n",
    "        p = np.random.permutation(m)\n",
    "        return X[p], Y[p]\n",
    "    \n",
    "    def __get_batches(self, X, Y, batch_size, shuffled):\n",
    "        m = X.shape[0] # == Y.shape[0]\n",
    "        n_batches = m // batch_size\n",
    "        if shuffled:\n",
    "            X, Y = self.__shuffle_X_Y(X, Y)\n",
    "        return zip(np.array_split(X, n_batches), np.array_split(Y, n_batches))\n",
    "    \n",
    "    # test data\n",
    "    def evaluate(self, X_test, Y_test):\n",
    "        ''' X_test.shape == (n_test_samples, self.layers[0].input_size)\n",
    "            Y_test.shape == (n_test_samples, self.layers[-1].output_size)\n",
    "        '''\n",
    "        assert(X_test.shape[0] == Y_test.shape[0])\n",
    "        assert(X_test.shape[1] == self.layers[0].output_size) # self.layers[0].input_size == self.layers[0].output_size\n",
    "        assert(Y_test.shape[1] == self.layers[-1].output_size)\n",
    "        \n",
    "        # loss/cost value for the training set\n",
    "        Ypred = self.predict(X_test) # same as self.feedforward(X_test) but doesn't change the 'cached' values\n",
    "        cost = self.J(Y_test, Ypred)\n",
    "        \n",
    "        # calculates the values not as one-hot encoded row vectors\n",
    "        target = np.argmax(Y_test, axis=1)\n",
    "        prediction = np.argmax(Ypred, axis=1)\n",
    "        accuracy = (prediction == target).mean()\n",
    "\n",
    "        return cost, accuracy\n",
    "    \n",
    "    # training and validation data\n",
    "    def train(self, X, Y, X_val, Y_val, n_epochs, batch_size, verbose=True):\n",
    "        ''' X.shape == (n_training_samples, self.layers[0].input_size)\n",
    "            Y.shape == (n_training_samples, self.layers[-1].output_size)\n",
    "            \n",
    "            X_val.shape == (n_validation_samples, self.layers[0].input_size)\n",
    "            Y_val.shape == (n_validation_samples, self.layers[-1].output_size)\n",
    "            \n",
    "            For each iteration we'll have:\n",
    "              n_examples = batch_size\n",
    "              batch_X.shape == (n_examples, self.layers[0].input_size)\n",
    "              batch_Y.shape == (n_examples, self.layers[-1].output_size)\n",
    "            Thus, each epoch has ceil(n_training_samples / batch_size) iterations\n",
    "            obs.: batch_X and batch_Y are rows of X and Y, and after each iteration (i.e. after going through\n",
    "                  each batch) we update our network parameters (weights and biases)\n",
    "            \n",
    "            If n_training_samples is not divisible by batch_size the last training batch will be smaller\n",
    "        '''\n",
    "        assert(X.shape[0] == Y.shape[0])\n",
    "        assert(X.shape[1] == self.layers[0].output_size) # self.layers[0].input_size == self.layers[0].output_size\n",
    "        assert(Y.shape[1] == self.layers[-1].output_size)\n",
    "        assert(X_val.shape[0] == Y_val.shape[0])\n",
    "        assert(X_val.shape[1] == self.layers[0].output_size) # self.layers[0].input_size == self.layers[0].output_size\n",
    "        assert(Y_val.shape[1] == self.layers[-1].output_size)\n",
    "        \n",
    "        n_training_samples = X.shape[0]\n",
    "        batches_per_epoch = int(np.ceil(n_training_samples / batch_size)) # equal to the number of iterations per epoch\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            if verbose:\n",
    "                start_time = time()\n",
    "                batch_number = 1\n",
    "                \n",
    "            for batch_X, batch_Y in self.__get_batches(X, Y, batch_size, shuffled=True):\n",
    "                # calculates the predicted target values for this batch (with the current network parameters)\n",
    "                batch_Ypred = self.feedforward(batch_X)\n",
    "                \n",
    "                # sets the values of dW and db, used to then update the network parameters\n",
    "                self.backprop(batch_X, batch_Y, batch_Ypred)\n",
    "                \n",
    "                # updates each layer's parameters (i.e. weights and biases) with some flavor of gradient descent\n",
    "                self.optimizer.update(self.layers)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"batch ({batch_number}/{batches_per_epoch})\", end='\\r')\n",
    "                    batch_number += 1\n",
    "            \n",
    "            # calculate the loss/cost value for this epoch\n",
    "            epoch_cost, epoch_accuracy = self.evaluate(X, Y) # training set\n",
    "            epoch_cost_val, epoch_accuracy_val = self.evaluate(X_val, Y_val) # validation set\n",
    "            self.history[\"loss\"].append(epoch_cost)\n",
    "            self.history[\"loss_val\"].append(epoch_cost_val)\n",
    "            self.history[\"acc\"].append(epoch_accuracy)\n",
    "            self.history[\"acc_val\"].append(epoch_accuracy_val)\n",
    "            if verbose:\n",
    "                print(f\"epoch ({epoch+1}/{n_epochs}) \"\n",
    "                      f\"loss: {epoch_cost:.4f}, loss_val: {epoch_cost_val:.4f} | \"\n",
    "                      f\"acc: {epoch_accuracy:.4f}, acc_val: {epoch_accuracy_val:.4f} | \"\n",
    "                      f\"Δt: {(time() - start_time):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** you should have the .npz files in the directory listed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes_and_names.csv\n",
      "images\n",
      "README.txt\n",
      "test.npz\n",
      "train.npz\n",
      "val.npz\n"
     ]
    }
   ],
   "source": [
    "# confirm that you have test.npz, train.npz and val.npz\n",
    "!ls mini_cinic10/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = os.path.join(\"mini_cinic10\")\n",
    "\n",
    "train_data = np.load(os.path.join(PATH_TO_DATA, \"train.npz\"))\n",
    "val_data   = np.load(os.path.join(PATH_TO_DATA, \"val.npz\"))\n",
    "# test_data  = np.load(os.path.join(PATH_TO_DATA, \"test.npz\")) # assume this doesn't exist (we'll come back to it at the end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 3072) uint8\n",
      "(80000,) uint8\n"
     ]
    }
   ],
   "source": [
    "xs, ys = train_data['xs'], train_data['ys']\n",
    "print(xs.shape, xs.dtype) # 3072 = 3 * 1024 = 3 * (32 * 32)\n",
    "print(ys.shape, ys.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072) uint8\n",
      "(10000,) uint8\n"
     ]
    }
   ],
   "source": [
    "xs_val, ys_val = val_data['xs'], val_data['ys']\n",
    "print(xs_val.shape, xs_val.dtype) # 3072 = 3 * 1024 = 3 * (32 * 32)\n",
    "print(ys_val.shape, ys_val.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = IMG_HEIGHT = 32\n",
    "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3) # RGB images\n",
    "IMG_FLAT_SHAPE = (IMG_HEIGHT*IMG_WIDTH*3, )\n",
    "\n",
    "# classes_and_names.csv\n",
    "CLASS_NAME = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\",\n",
    "}\n",
    "CLASS_COUNT = len(CLASS_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unflatten(flat_img, img_shape=IMG_SHAPE):\n",
    "    ''' Converts a flattened image back into a 3-layer RGB matrix representation '''\n",
    "    return flat_img.reshape(img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img_index, xs, ys, figsize=None):\n",
    "    ''' Shows the image represented by the img_index-th row of xs '''\n",
    "    if figsize != None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "    plt.imshow(unflatten(xs[img_index]))\n",
    "    plt.title(f'idx #{img_index} ({CLASS_NAME[ys[img_index]]})')\n",
    "    plt.axis(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(0, xs, ys, [1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Normalize xs and one-hot encode ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs: mean=117.3316, stddev=63.1088\n",
      "X:  mean=  0.0000, stddev= 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"xs: mean={xs.mean():>8.4f}, stddev={xs.std():>7.4f}\")\n",
    "\n",
    "# NOTE that we must use stats from train data to normalize the val and test sets aswell\n",
    "mean, std = xs.mean(), xs.std()\n",
    "X = (xs - mean) / std\n",
    "\n",
    "print(f\"X:  mean={X.mean():>8.4f}, stddev={X.std():>7.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs_val: mean=118.1221, stddev=63.2348\n",
      "X_val:  mean=  0.0125, stddev= 1.0020\n"
     ]
    }
   ],
   "source": [
    "X_val = (xs_val - mean) / std\n",
    "print(f\"xs_val: mean={xs_val.mean():>8.4f}, stddev={xs_val.std():>7.4f}\")\n",
    "print(f\"X_val:  mean={X_val.mean():>8.4f}, stddev={X_val.std():>7.4f}\") # mean should be close to 0 and stddev close to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(ys):\n",
    "    n_examples, *_ = ys.shape\n",
    "    onehot = np.zeros(shape=(n_examples, CLASS_COUNT))\n",
    "    onehot[np.arange(n_examples), ys] = 1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000,) (80000, 10)\n"
     ]
    }
   ],
   "source": [
    "Y = onehot_encode(ys)\n",
    "print(ys.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "Y_val = onehot_encode(ys_val)\n",
    "print(ys_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Add helper functions for running Computational Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_computational_graph(computational_graph, X, Y, X_val, Y_val, n_epochs, batch_size, verbose=True):\n",
    "    start = time()\n",
    "    print(\"Starting to train...\")\n",
    "    computational_graph.train(\n",
    "        X, Y,\n",
    "        X_val, Y_val,\n",
    "        n_epochs,\n",
    "        batch_size,\n",
    "        verbose\n",
    "    )\n",
    "    end = time()\n",
    "    print(f\"\\nDone.\\nTraining took {(end - start):.2f}s\")\n",
    "    return computational_graph.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 48\n",
    "batch_size = 80\n",
    "learning_rate = 5e-5\n",
    "\n",
    "hidden_layer_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perform Multinomial Logistic Regression (i.e. softmax regression)\n",
    "It is a generalization of Logistic Regression to the case where we want to handle multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_regressor = ComputationalGraph(\n",
    "    cost_function=CrossEntropy(),\n",
    "    optimizer=GradientDescent(learning_rate),\n",
    "    weight_initialization='xavier',\n",
    "    layers=[\n",
    "        Layer(IMG_FLAT_SHAPE[0], None), Layer(CLASS_COUNT, SoftMax())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n",
      "epoch (1/48) loss: 2.3742, loss_val: 2.3773 | acc: 0.19, acc_val: 0.18 | Δt: 3.94s\n",
      "epoch (2/48) loss: 2.2823, loss_val: 2.2849 | acc: 0.21, acc_val: 0.21 | Δt: 3.88s\n",
      "epoch (3/48) loss: 2.2320, loss_val: 2.2352 | acc: 0.22, acc_val: 0.22 | Δt: 3.76s\n",
      "epoch (4/48) loss: 2.1978, loss_val: 2.2017 | acc: 0.23, acc_val: 0.23 | Δt: 3.75s\n",
      "epoch (5/48) loss: 2.1725, loss_val: 2.1770 | acc: 0.24, acc_val: 0.24 | Δt: 3.62s\n",
      "epoch (6/48) loss: 2.1527, loss_val: 2.1579 | acc: 0.24, acc_val: 0.24 | Δt: 3.84s\n",
      "epoch (7/48) loss: 2.1367, loss_val: 2.1425 | acc: 0.25, acc_val: 0.25 | Δt: 3.69s\n",
      "epoch (8/48) loss: 2.1234, loss_val: 2.1298 | acc: 0.26, acc_val: 0.25 | Δt: 3.66s\n",
      "epoch (9/48) loss: 2.1121, loss_val: 2.1190 | acc: 0.26, acc_val: 0.26 | Δt: 3.87s\n",
      "epoch (10/48) loss: 2.1024, loss_val: 2.1097 | acc: 0.26, acc_val: 0.26 | Δt: 3.94s\n",
      "epoch (11/48) loss: 2.0939, loss_val: 2.1012 | acc: 0.27, acc_val: 0.26 | Δt: 3.78s\n",
      "epoch (12/48) loss: 2.0863, loss_val: 2.0941 | acc: 0.27, acc_val: 0.27 | Δt: 4.16s\n",
      "epoch (13/48) loss: 2.0794, loss_val: 2.0875 | acc: 0.27, acc_val: 0.27 | Δt: 4.81s\n",
      "epoch (14/48) loss: 2.0732, loss_val: 2.0817 | acc: 0.27, acc_val: 0.27 | Δt: 4.42s\n",
      "epoch (15/48) loss: 2.0675, loss_val: 2.0762 | acc: 0.27, acc_val: 0.27 | Δt: 3.97s\n",
      "epoch (16/48) loss: 2.0623, loss_val: 2.0714 | acc: 0.28, acc_val: 0.28 | Δt: 3.98s\n",
      "epoch (17/48) loss: 2.0574, loss_val: 2.0667 | acc: 0.28, acc_val: 0.28 | Δt: 3.99s\n",
      "epoch (18/48) loss: 2.0529, loss_val: 2.0627 | acc: 0.28, acc_val: 0.28 | Δt: 4.08s\n",
      "epoch (19/48) loss: 2.0487, loss_val: 2.0586 | acc: 0.28, acc_val: 0.28 | Δt: 3.95s\n",
      "epoch (20/48) loss: 2.0447, loss_val: 2.0547 | acc: 0.28, acc_val: 0.28 | Δt: 3.70s\n",
      "epoch (21/48) loss: 2.0410, loss_val: 2.0513 | acc: 0.28, acc_val: 0.28 | Δt: 3.79s\n",
      "epoch (22/48) loss: 2.0374, loss_val: 2.0480 | acc: 0.28, acc_val: 0.28 | Δt: 3.90s\n",
      "epoch (23/48) loss: 2.0341, loss_val: 2.0449 | acc: 0.28, acc_val: 0.29 | Δt: 3.73s\n",
      "epoch (24/48) loss: 2.0309, loss_val: 2.0419 | acc: 0.29, acc_val: 0.29 | Δt: 3.85s\n",
      "epoch (25/48) loss: 2.0278, loss_val: 2.0391 | acc: 0.29, acc_val: 0.29 | Δt: 3.68s\n",
      "epoch (26/48) loss: 2.0249, loss_val: 2.0365 | acc: 0.29, acc_val: 0.29 | Δt: 3.95s\n",
      "epoch (27/48) loss: 2.0222, loss_val: 2.0341 | acc: 0.29, acc_val: 0.29 | Δt: 3.77s\n",
      "epoch (28/48) loss: 2.0195, loss_val: 2.0315 | acc: 0.29, acc_val: 0.29 | Δt: 3.63s\n",
      "epoch (29/48) loss: 2.0169, loss_val: 2.0291 | acc: 0.29, acc_val: 0.29 | Δt: 3.67s\n",
      "epoch (30/48) loss: 2.0145, loss_val: 2.0271 | acc: 0.29, acc_val: 0.29 | Δt: 3.81s\n",
      "epoch (31/48) loss: 2.0121, loss_val: 2.0249 | acc: 0.29, acc_val: 0.29 | Δt: 4.01s\n",
      "epoch (32/48) loss: 2.0098, loss_val: 2.0227 | acc: 0.29, acc_val: 0.29 | Δt: 3.89s\n",
      "epoch (33/48) loss: 2.0075, loss_val: 2.0206 | acc: 0.29, acc_val: 0.29 | Δt: 3.79s\n",
      "epoch (34/48) loss: 2.0054, loss_val: 2.0186 | acc: 0.29, acc_val: 0.29 | Δt: 3.84s\n",
      "epoch (35/48) loss: 2.0034, loss_val: 2.0169 | acc: 0.30, acc_val: 0.29 | Δt: 3.89s\n",
      "epoch (36/48) loss: 2.0014, loss_val: 2.0150 | acc: 0.30, acc_val: 0.30 | Δt: 4.35s\n",
      "epoch (37/48) loss: 1.9994, loss_val: 2.0132 | acc: 0.30, acc_val: 0.30 | Δt: 4.13s\n",
      "epoch (38/48) loss: 1.9975, loss_val: 2.0115 | acc: 0.30, acc_val: 0.30 | Δt: 4.05s\n",
      "epoch (39/48) loss: 1.9957, loss_val: 2.0099 | acc: 0.30, acc_val: 0.30 | Δt: 4.26s\n",
      "epoch (40/48) loss: 1.9939, loss_val: 2.0084 | acc: 0.30, acc_val: 0.30 | Δt: 3.93s\n",
      "epoch (41/48) loss: 1.9922, loss_val: 2.0068 | acc: 0.30, acc_val: 0.30 | Δt: 3.84s\n",
      "epoch (42/48) loss: 1.9905, loss_val: 2.0055 | acc: 0.30, acc_val: 0.30 | Δt: 4.14s\n",
      "epoch (43/48) loss: 1.9888, loss_val: 2.0038 | acc: 0.30, acc_val: 0.30 | Δt: 4.56s\n",
      "epoch (44/48) loss: 1.9872, loss_val: 2.0026 | acc: 0.30, acc_val: 0.30 | Δt: 3.82s\n",
      "epoch (45/48) loss: 1.9856, loss_val: 2.0009 | acc: 0.30, acc_val: 0.30 | Δt: 3.55s\n",
      "epoch (46/48) loss: 1.9841, loss_val: 1.9997 | acc: 0.30, acc_val: 0.30 | Δt: 3.96s\n",
      "epoch (47/48) loss: 1.9826, loss_val: 1.9985 | acc: 0.30, acc_val: 0.30 | Δt: 4.15s\n",
      "epoch (48/48) loss: 1.9811, loss_val: 1.9972 | acc: 0.30, acc_val: 0.30 | Δt: 4.08s\n",
      "\n",
      "Done.\n",
      "Training took 188.84s\n"
     ]
    }
   ],
   "source": [
    "softmax_regressor_history = train_computational_graph(\n",
    "    softmax_regressor,\n",
    "    X=X, X_val=X_val,\n",
    "    Y=Y, Y_val=Y_val,\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO plot history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPsGc8lu5uj7"
   },
   "source": [
    "## 3. Neural Network\n",
    "\n",
    "Being $m$ the number of samples in a batch, from a layer $k-1$ to a layer $k$ we have:\n",
    "- Weights $\\mathbb{W}^{(k)} \\in \\mathbb{R}^{n_{k-1} \\times n_k}$\n",
    "- Biases $\\mathbf{b}^{(k)} \\in \\mathbb{R}^{n_k}$\n",
    "- Activations $\\mathbb{A}^{(k)} = g_k(\\mathbb{Z}^{(k)}) \\in \\mathbb{R}^{m \\times n_k}$, where $g_k(\\mathbb{Z}^{(k)})$ is the activation function of the $k^{\\text{th}}$ layer and $\\mathbb{Z}^{(k)} = \\mathbb{A}^{(k-1)} \\mathbb{W}^{(k)} + \\mathbf{b}^{(k)}$\n",
    "\n",
    "(Xavier initialization: [[1]](https://prateekvjoshi.com/2016/03/29/understanding-xavier-initialization-in-deep-neural-networks/))\n",
    "\n",
    "For the first layer, the activation is the input itself: $\\mathbb{A}^{(1)} = \\mathbb{X} \\in \\mathbb{R}^{m \\times n_1}$, where $n_1$ is the input size (3072)  \n",
    "For the middle layers ($2 \\leq k < L$), the activation function is the sigmoid: $\\mathbb{A}^{(k)} = g_k(\\mathbb{Z}^{(k)}) = sigmoid(\\mathbb{Z}^{(k)})$  \n",
    "For the last layer, we have the predicted value with softmax activation: $\\mathbb{A}^{(L)} = g_k(\\mathbb{Z}^{(L)}) = softmax(\\mathbb{Z}^{(L)}) \\in \\mathbb{R}^{m \\times n_L}$, where $n_L$ is the output size (10)  \n",
    "(i.e. the hypothesis function $a^{(L)} = h_{W, b}(x) = y_{\\text{pred}} \\approx y$)\n",
    "\n",
    "obs.: the number of layers $L$ comes from: $1$ input layer + $1$ output layer + $L-2$ hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ComputationalGraph(\n",
    "    cost_function=CrossEntropy(),\n",
    "    optimizer=GradientDescent(learning_rate),\n",
    "    weight_initialization='xavier',\n",
    "    layers=[\n",
    "        Layer(IMG_FLAT_SHAPE[0], None), Layer(hidden_layer_size, Sigmoid()), Layer(CLASS_COUNT, SoftMax())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n",
      "batch (179/1000)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\documents\\github\\unicamp\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: overflow encountered in exp\n",
      "d:\\documents\\github\\unicamp\\lib\\site-packages\\ipykernel_launcher.py:82: RuntimeWarning: overflow encountered in matmul\n",
      "d:\\documents\\github\\unicamp\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in multiply\n",
      "d:\\documents\\github\\unicamp\\lib\\site-packages\\numpy\\core\\_methods.py:38: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (1/48) loss: nan, loss_val: nan | acc: 0.1010, acc_val: 0.1024 | Δt: 16.71s\n",
      "batch (530/1000)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-5645c0351f76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-47-0f983497d138>\u001b[0m in \u001b[0;36mtrain_computational_graph\u001b[1;34m(computational_graph, X, Y, X_val, Y_val, n_epochs, batch_size, verbose)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     11\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-6eafa3505cd4>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, Y, X_val, Y_val, n_epochs, batch_size, verbose)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[1;31m# updates each layer's parameters (i.e. weights and biases) with some flavor of gradient descent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-5427b58935a8>\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, layers)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn_history = train_computational_graph(\n",
    "    nn,\n",
    "    X=X, X_val=X_val,\n",
    "    Y=Y, Y_val=Y_val,\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO plot history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare results with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "#callbacks to be used during training\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Compare softmax regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "__input  = Input(shape=IMG_FLAT_SHAPE)\n",
    "__output = Dense(CLASS_COUNT, activation='softmax')(__input)\n",
    "\n",
    "keras_softmax_regressor = Model(inputs=__input, outputs=__output)\n",
    "keras_softmax_regressor.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=SGD(learning_rate=learning_rate, momentum=0.0),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3072)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                30730     \n",
      "=================================================================\n",
      "Total params: 30,730\n",
      "Trainable params: 30,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_softmax_regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 10000 samples\n",
      "Epoch 1/48\n",
      "80000/80000 [==============================] - 4s 48us/sample - loss: 2.6243 - accuracy: 0.1373 - val_loss: 2.4322 - val_accuracy: 0.1654\n",
      "Epoch 2/48\n",
      "80000/80000 [==============================] - 3s 42us/sample - loss: 2.3478 - accuracy: 0.1838 - val_loss: 2.3043 - val_accuracy: 0.1928\n",
      "Epoch 3/48\n",
      "80000/80000 [==============================] - 4s 44us/sample - loss: 2.2605 - accuracy: 0.2055 - val_loss: 2.2432 - val_accuracy: 0.2074\n",
      "Epoch 4/48\n",
      "80000/80000 [==============================] - 3s 41us/sample - loss: 2.2132 - accuracy: 0.2183 - val_loss: 2.2056 - val_accuracy: 0.2196\n",
      "Epoch 5/48\n",
      "80000/80000 [==============================] - 3s 41us/sample - loss: 2.1819 - accuracy: 0.2270 - val_loss: 2.1786 - val_accuracy: 0.2273\n",
      "Epoch 6/48\n",
      "80000/80000 [==============================] - 3s 41us/sample - loss: 2.1586 - accuracy: 0.2343 - val_loss: 2.1579 - val_accuracy: 0.2318\n",
      "Epoch 7/48\n",
      "80000/80000 [==============================] - 4s 46us/sample - loss: 2.1403 - accuracy: 0.2404 - val_loss: 2.1409 - val_accuracy: 0.2373\n",
      "Epoch 8/48\n",
      "80000/80000 [==============================] - 3s 43us/sample - loss: 2.1250 - accuracy: 0.2454 - val_loss: 2.1267 - val_accuracy: 0.2409\n",
      "Epoch 9/48\n",
      "80000/80000 [==============================] - 3s 43us/sample - loss: 2.1120 - accuracy: 0.2494 - val_loss: 2.1147 - val_accuracy: 0.2447\n",
      "Epoch 10/48\n",
      "80000/80000 [==============================] - 4s 44us/sample - loss: 2.1007 - accuracy: 0.2535 - val_loss: 2.1040 - val_accuracy: 0.2479\n",
      "Epoch 11/48\n",
      "80000/80000 [==============================] - 4s 44us/sample - loss: 2.0907 - accuracy: 0.2564 - val_loss: 2.0945 - val_accuracy: 0.2510\n",
      "Epoch 12/48\n",
      "80000/80000 [==============================] - 3s 41us/sample - loss: 2.0818 - accuracy: 0.2591 - val_loss: 2.0861 - val_accuracy: 0.2540\n",
      "Epoch 13/48\n",
      "80000/80000 [==============================] - 3s 40us/sample - loss: 2.0738 - accuracy: 0.2620 - val_loss: 2.0785 - val_accuracy: 0.2565\n",
      "Epoch 14/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 2.0664 - accuracy: 0.2647 - val_loss: 2.0717 - val_accuracy: 0.2591\n",
      "Epoch 15/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 2.0597 - accuracy: 0.2669 - val_loss: 2.0653 - val_accuracy: 0.2623\n",
      "Epoch 16/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 2.0535 - accuracy: 0.2680 - val_loss: 2.0595 - val_accuracy: 0.2630\n",
      "Epoch 17/48\n",
      "80000/80000 [==============================] - 3s 39us/sample - loss: 2.0478 - accuracy: 0.2700 - val_loss: 2.0543 - val_accuracy: 0.2658\n",
      "Epoch 18/48\n",
      "80000/80000 [==============================] - 4s 45us/sample - loss: 2.0424 - accuracy: 0.2720 - val_loss: 2.0491 - val_accuracy: 0.2669\n",
      "Epoch 19/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 2.0374 - accuracy: 0.2739 - val_loss: 2.0446 - val_accuracy: 0.2685\n",
      "Epoch 20/48\n",
      "80000/80000 [==============================] - 3s 39us/sample - loss: 2.0328 - accuracy: 0.2756 - val_loss: 2.0401 - val_accuracy: 0.2720\n",
      "Epoch 21/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 2.0284 - accuracy: 0.2773 - val_loss: 2.0359 - val_accuracy: 0.2729\n",
      "Epoch 22/48\n",
      "80000/80000 [==============================] - 3s 39us/sample - loss: 2.0242 - accuracy: 0.2793 - val_loss: 2.0323 - val_accuracy: 0.2737\n",
      "Epoch 23/48\n",
      "80000/80000 [==============================] - 3s 41us/sample - loss: 2.0203 - accuracy: 0.2806 - val_loss: 2.0285 - val_accuracy: 0.2756\n",
      "Epoch 24/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 2.0165 - accuracy: 0.2812 - val_loss: 2.0251 - val_accuracy: 0.2763\n",
      "Epoch 25/48\n",
      "80000/80000 [==============================] - 3s 41us/sample - loss: 2.0130 - accuracy: 0.2826 - val_loss: 2.0217 - val_accuracy: 0.2774\n",
      "Epoch 26/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 2.0096 - accuracy: 0.2833 - val_loss: 2.0186 - val_accuracy: 0.2790\n",
      "Epoch 27/48\n",
      "80000/80000 [==============================] - 3s 41us/sample - loss: 2.0064 - accuracy: 0.2848 - val_loss: 2.0158 - val_accuracy: 0.2799\n",
      "Epoch 28/48\n",
      "80000/80000 [==============================] - 3s 40us/sample - loss: 2.0032 - accuracy: 0.2866 - val_loss: 2.0128 - val_accuracy: 0.2805\n",
      "Epoch 29/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 2.0004 - accuracy: 0.2867 - val_loss: 2.0102 - val_accuracy: 0.2818\n",
      "Epoch 30/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 1.9975 - accuracy: 0.2884 - val_loss: 2.0075 - val_accuracy: 0.2826\n",
      "Epoch 31/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 1.9948 - accuracy: 0.2899 - val_loss: 2.0051 - val_accuracy: 0.2839\n",
      "Epoch 32/48\n",
      "80000/80000 [==============================] - 3s 40us/sample - loss: 1.9922 - accuracy: 0.2907 - val_loss: 2.0027 - val_accuracy: 0.2844\n",
      "Epoch 33/48\n",
      "80000/80000 [==============================] - 3s 41us/sample - loss: 1.9897 - accuracy: 0.2924 - val_loss: 2.0005 - val_accuracy: 0.2852\n",
      "Epoch 34/48\n",
      "80000/80000 [==============================] - 3s 42us/sample - loss: 1.9872 - accuracy: 0.2923 - val_loss: 1.9983 - val_accuracy: 0.2867\n",
      "Epoch 35/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 1.9849 - accuracy: 0.2936 - val_loss: 1.9962 - val_accuracy: 0.2868\n",
      "Epoch 36/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 1.9826 - accuracy: 0.2951 - val_loss: 1.9942 - val_accuracy: 0.2879\n",
      "Epoch 37/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 1.9804 - accuracy: 0.2956 - val_loss: 1.9924 - val_accuracy: 0.2881\n",
      "Epoch 38/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 1.9783 - accuracy: 0.2962 - val_loss: 1.9905 - val_accuracy: 0.2896\n",
      "Epoch 39/48\n",
      "80000/80000 [==============================] - 3s 38us/sample - loss: 1.9762 - accuracy: 0.2970 - val_loss: 1.9884 - val_accuracy: 0.2900\n",
      "Epoch 40/48\n",
      "80000/80000 [==============================] - 4s 51us/sample - loss: 1.9742 - accuracy: 0.2974 - val_loss: 1.9868 - val_accuracy: 0.2907\n",
      "Epoch 41/48\n",
      "80000/80000 [==============================] - 4s 46us/sample - loss: 1.9723 - accuracy: 0.2977 - val_loss: 1.9852 - val_accuracy: 0.2907\n",
      "Epoch 42/48\n",
      "80000/80000 [==============================] - 3s 42us/sample - loss: 1.9705 - accuracy: 0.2987 - val_loss: 1.9833 - val_accuracy: 0.2927\n",
      "Epoch 43/48\n",
      "80000/80000 [==============================] - 4s 44us/sample - loss: 1.9686 - accuracy: 0.2993 - val_loss: 1.9816 - val_accuracy: 0.2919\n",
      "Epoch 44/48\n",
      "80000/80000 [==============================] - 3s 42us/sample - loss: 1.9669 - accuracy: 0.2995 - val_loss: 1.9803 - val_accuracy: 0.2929\n",
      "Epoch 45/48\n",
      "80000/80000 [==============================] - 4s 45us/sample - loss: 1.9651 - accuracy: 0.3003 - val_loss: 1.9787 - val_accuracy: 0.2926\n",
      "Epoch 46/48\n",
      "80000/80000 [==============================] - 3s 41us/sample - loss: 1.9634 - accuracy: 0.3011 - val_loss: 1.9773 - val_accuracy: 0.2930\n",
      "Epoch 47/48\n",
      "80000/80000 [==============================] - 3s 41us/sample - loss: 1.9618 - accuracy: 0.3015 - val_loss: 1.9758 - val_accuracy: 0.2939\n",
      "Epoch 48/48\n",
      "80000/80000 [==============================] - 3s 43us/sample - loss: 1.9602 - accuracy: 0.3025 - val_loss: 1.9745 - val_accuracy: 0.2951\n"
     ]
    }
   ],
   "source": [
    "keras_softmax_regressor_history = keras_softmax_regressor.fit(\n",
    "            x=X, y=Y,\n",
    "            validation_data=(X_val, Y_val),\n",
    "            epochs=n_epochs,\n",
    "            batch_size=batch_size\n",
    "          ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Compare neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "__input  = Input(shape=IMG_FLAT_SHAPE) # 3072\n",
    "__hidden = Dense(hidden_layer_size, activation='sigmoid')(__input)\n",
    "__output = Dense(CLASS_COUNT, activation='softmax')(__hidden) # 10\n",
    "\n",
    "keras_nn = Model(inputs=__input, outputs=__output)\n",
    "keras_nn.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=SGD(learning_rate=learning_rate, momentum=0.0),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 3072)]            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               614600    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 616,610\n",
      "Trainable params: 616,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 10000 samples\n",
      "Epoch 1/48\n",
      "80000/80000 [==============================] - 6s 81us/sample - loss: 2.4325 - accuracy: 0.0984 - val_loss: 2.3772 - val_accuracy: 0.0991\n",
      "Epoch 2/48\n",
      "80000/80000 [==============================] - 6s 73us/sample - loss: 2.3362 - accuracy: 0.1066 - val_loss: 2.3051 - val_accuracy: 0.1191\n",
      "Epoch 3/48\n",
      "80000/80000 [==============================] - 6s 71us/sample - loss: 2.2793 - accuracy: 0.1315 - val_loss: 2.2601 - val_accuracy: 0.1420\n",
      "Epoch 4/48\n",
      "80000/80000 [==============================] - 6s 72us/sample - loss: 2.2423 - accuracy: 0.1549 - val_loss: 2.2296 - val_accuracy: 0.1605\n",
      "Epoch 5/48\n",
      "80000/80000 [==============================] - 6s 72us/sample - loss: 2.2162 - accuracy: 0.1720 - val_loss: 2.2074 - val_accuracy: 0.1783\n",
      "Epoch 6/48\n",
      "80000/80000 [==============================] - 6s 72us/sample - loss: 2.1966 - accuracy: 0.1849 - val_loss: 2.1902 - val_accuracy: 0.1905\n",
      "Epoch 7/48\n",
      "80000/80000 [==============================] - 6s 71us/sample - loss: 2.1811 - accuracy: 0.1933 - val_loss: 2.1762 - val_accuracy: 0.1998\n",
      "Epoch 8/48\n",
      "80000/80000 [==============================] - 6s 76us/sample - loss: 2.1681 - accuracy: 0.2011 - val_loss: 2.1643 - val_accuracy: 0.2082\n",
      "Epoch 9/48\n",
      "80000/80000 [==============================] - 6s 76us/sample - loss: 2.1569 - accuracy: 0.2074 - val_loss: 2.1539 - val_accuracy: 0.2104\n",
      "Epoch 10/48\n",
      "80000/80000 [==============================] - 6s 72us/sample - loss: 2.1470 - accuracy: 0.2129 - val_loss: 2.1446 - val_accuracy: 0.2141\n",
      "Epoch 11/48\n",
      "80000/80000 [==============================] - 6s 73us/sample - loss: 2.1381 - accuracy: 0.2181 - val_loss: 2.1362 - val_accuracy: 0.2191\n",
      "Epoch 12/48\n",
      "80000/80000 [==============================] - 6s 72us/sample - loss: 2.1299 - accuracy: 0.2225 - val_loss: 2.1285 - val_accuracy: 0.2224\n",
      "Epoch 13/48\n",
      "80000/80000 [==============================] - 6s 72us/sample - loss: 2.1224 - accuracy: 0.2262 - val_loss: 2.1213 - val_accuracy: 0.2275\n",
      "Epoch 14/48\n",
      "80000/80000 [==============================] - 6s 76us/sample - loss: 2.1154 - accuracy: 0.2294 - val_loss: 2.1146 - val_accuracy: 0.2303\n",
      "Epoch 15/48\n",
      "80000/80000 [==============================] - 7s 81us/sample - loss: 2.1089 - accuracy: 0.2324 - val_loss: 2.1084 - val_accuracy: 0.2331\n",
      "Epoch 16/48\n",
      "80000/80000 [==============================] - 6s 73us/sample - loss: 2.1027 - accuracy: 0.2356 - val_loss: 2.1025 - val_accuracy: 0.2354\n",
      "Epoch 17/48\n",
      "80000/80000 [==============================] - 6s 75us/sample - loss: 2.0970 - accuracy: 0.2380 - val_loss: 2.0970 - val_accuracy: 0.2390\n",
      "Epoch 18/48\n",
      "80000/80000 [==============================] - 6s 74us/sample - loss: 2.0915 - accuracy: 0.2402 - val_loss: 2.0918 - val_accuracy: 0.2408\n",
      "Epoch 19/48\n",
      "80000/80000 [==============================] - 6s 73us/sample - loss: 2.0863 - accuracy: 0.2423 - val_loss: 2.0868 - val_accuracy: 0.2429\n",
      "Epoch 20/48\n",
      "80000/80000 [==============================] - 7s 82us/sample - loss: 2.0814 - accuracy: 0.2442 - val_loss: 2.0821 - val_accuracy: 0.2453\n",
      "Epoch 21/48\n",
      "80000/80000 [==============================] - 7s 85us/sample - loss: 2.0767 - accuracy: 0.2467 - val_loss: 2.0776 - val_accuracy: 0.2483\n",
      "Epoch 22/48\n",
      "80000/80000 [==============================] - 6s 77us/sample - loss: 2.0723 - accuracy: 0.2485 - val_loss: 2.0733 - val_accuracy: 0.2521\n",
      "Epoch 23/48\n",
      "80000/80000 [==============================] - 6s 78us/sample - loss: 2.0680 - accuracy: 0.2503 - val_loss: 2.0692 - val_accuracy: 0.2532\n",
      "Epoch 24/48\n",
      "80000/80000 [==============================] - 6s 72us/sample - loss: 2.0640 - accuracy: 0.2523 - val_loss: 2.0653 - val_accuracy: 0.2561\n",
      "Epoch 25/48\n",
      "80000/80000 [==============================] - 6s 75us/sample - loss: 2.0601 - accuracy: 0.2540 - val_loss: 2.0615 - val_accuracy: 0.2586\n",
      "Epoch 26/48\n",
      "80000/80000 [==============================] - 7s 83us/sample - loss: 2.0563 - accuracy: 0.2560 - val_loss: 2.0579 - val_accuracy: 0.2601\n",
      "Epoch 27/48\n",
      "80000/80000 [==============================] - 7s 86us/sample - loss: 2.0528 - accuracy: 0.2578 - val_loss: 2.0545 - val_accuracy: 0.2623\n",
      "Epoch 28/48\n",
      "80000/80000 [==============================] - 6s 76us/sample - loss: 2.0493 - accuracy: 0.2597 - val_loss: 2.0512 - val_accuracy: 0.2632\n",
      "Epoch 29/48\n",
      "80000/80000 [==============================] - 6s 81us/sample - loss: 2.0460 - accuracy: 0.2614 - val_loss: 2.0480 - val_accuracy: 0.2645\n",
      "Epoch 30/48\n",
      "80000/80000 [==============================] - 7s 85us/sample - loss: 2.0428 - accuracy: 0.2627 - val_loss: 2.0449 - val_accuracy: 0.2646\n",
      "Epoch 31/48\n",
      "80000/80000 [==============================] - 6s 73us/sample - loss: 2.0397 - accuracy: 0.2637 - val_loss: 2.0420 - val_accuracy: 0.2660\n",
      "Epoch 32/48\n",
      "80000/80000 [==============================] - 6s 74us/sample - loss: 2.0368 - accuracy: 0.2653 - val_loss: 2.0391 - val_accuracy: 0.2672\n",
      "Epoch 33/48\n",
      "80000/80000 [==============================] - 6s 81us/sample - loss: 2.0339 - accuracy: 0.2669 - val_loss: 2.0363 - val_accuracy: 0.2693\n",
      "Epoch 34/48\n",
      "80000/80000 [==============================] - 7s 84us/sample - loss: 2.0312 - accuracy: 0.2680 - val_loss: 2.0337 - val_accuracy: 0.2709\n",
      "Epoch 35/48\n",
      "80000/80000 [==============================] - 8s 96us/sample - loss: 2.0285 - accuracy: 0.2691 - val_loss: 2.0311 - val_accuracy: 0.2714\n",
      "Epoch 36/48\n",
      "80000/80000 [==============================] - 7s 92us/sample - loss: 2.0259 - accuracy: 0.2706 - val_loss: 2.0286 - val_accuracy: 0.2727\n",
      "Epoch 37/48\n",
      "80000/80000 [==============================] - 7s 84us/sample - loss: 2.0234 - accuracy: 0.2716 - val_loss: 2.0262 - val_accuracy: 0.2738\n",
      "Epoch 38/48\n",
      "80000/80000 [==============================] - 6s 74us/sample - loss: 2.0210 - accuracy: 0.2726 - val_loss: 2.0239 - val_accuracy: 0.2752\n",
      "Epoch 39/48\n",
      "80000/80000 [==============================] - 6s 74us/sample - loss: 2.0186 - accuracy: 0.2735 - val_loss: 2.0216 - val_accuracy: 0.2764\n",
      "Epoch 40/48\n",
      "80000/80000 [==============================] - 6s 73us/sample - loss: 2.0163 - accuracy: 0.2744 - val_loss: 2.0194 - val_accuracy: 0.2768\n",
      "Epoch 41/48\n",
      "80000/80000 [==============================] - 6s 72us/sample - loss: 2.0141 - accuracy: 0.2758 - val_loss: 2.0173 - val_accuracy: 0.2783\n",
      "Epoch 42/48\n",
      "80000/80000 [==============================] - 7s 82us/sample - loss: 2.0120 - accuracy: 0.2765 - val_loss: 2.0152 - val_accuracy: 0.2787\n",
      "Epoch 43/48\n",
      "80000/80000 [==============================] - 7s 87us/sample - loss: 2.0099 - accuracy: 0.2773 - val_loss: 2.0132 - val_accuracy: 0.2796\n",
      "Epoch 44/48\n",
      "80000/80000 [==============================] - 7s 86us/sample - loss: 2.0079 - accuracy: 0.2781 - val_loss: 2.0112 - val_accuracy: 0.2808\n",
      "Epoch 45/48\n",
      "80000/80000 [==============================] - 6s 78us/sample - loss: 2.0059 - accuracy: 0.2789 - val_loss: 2.0093 - val_accuracy: 0.2807\n",
      "Epoch 46/48\n",
      "80000/80000 [==============================] - 6s 79us/sample - loss: 2.0040 - accuracy: 0.2798 - val_loss: 2.0074 - val_accuracy: 0.2812\n",
      "Epoch 47/48\n",
      "80000/80000 [==============================] - 6s 72us/sample - loss: 2.0021 - accuracy: 0.2806 - val_loss: 2.0056 - val_accuracy: 0.2820\n",
      "Epoch 48/48\n",
      "80000/80000 [==============================] - 7s 81us/sample - loss: 2.0003 - accuracy: 0.2812 - val_loss: 2.0039 - val_accuracy: 0.2829\n"
     ]
    }
   ],
   "source": [
    "keras_nn_history = keras_nn.fit(\n",
    "            x=X, y=Y,\n",
    "            validation_data=(X_val, Y_val),\n",
    "            epochs=n_epochs,\n",
    "            batch_size=batch_size\n",
    "          ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
