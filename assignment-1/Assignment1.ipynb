{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libs and loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set() # apply the seaborn defaults to plotted figures (e.g. theme, scaling, color palette), instead of matplotlib's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48204, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_csv_path = \"Metro_Interstate_Traffic_Volume.csv\" # 8 attributes of 48,204 examples (plus the target column)\n",
    "\n",
    "# loading the dataset with pandas (instead of numpy or csv) since there are different datatypes\n",
    "dataset_csv = pd.read_csv(dataset_csv_path, delimiter=',')\n",
    "dataset_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset attributes\n",
    "- 1: **holiday**: US National holidays plus regional holiday, Minnesota State Fair\n",
    "- 2: **temp**: average temp in kelvin\n",
    "- 3: **rain 1h**: amount in mm of rain that occurred in the hour\n",
    "- 4: **snow 1h**: amount in mm of snow that occurred in the hour\n",
    "- 5: **clouds all**: percentage of cloud cover\n",
    "- 6: **weather main**: short textual description of the current weather\n",
    "- 7: **weather description**: longer textual description of the current weather\n",
    "- 8: **date time**: hour of the data collected in local CST time\n",
    "- target: **traffic volume**: traffic volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "holiday                 object\n",
       "temp                   float64\n",
       "rain_1h                float64\n",
       "snow_1h                float64\n",
       "clouds_all               int64\n",
       "weather_main            object\n",
       "weather_description     object\n",
       "date_time               object\n",
       "traffic_volume           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_csv.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Clear</td>\n",
       "      <td>SQUALLS</td>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>Washingtons Birthday</td>\n",
       "      <td>310.070000</td>\n",
       "      <td>9831.300000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>Thunderstorm</td>\n",
       "      <td>very heavy rain</td>\n",
       "      <td>2018-09-30 23:00:00</td>\n",
       "      <td>7280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>NaN</td>\n",
       "      <td>282.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>281.205870</td>\n",
       "      <td>0.334264</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>49.362231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3259.818355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13.338232</td>\n",
       "      <td>44.789133</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>39.015750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1986.860670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     holiday        temp      rain_1h   snow_1h  clouds_all  \\\n",
       "min            Christmas Day    0.000000     0.000000  0.000000    0.000000   \n",
       "max     Washingtons Birthday  310.070000  9831.300000  0.510000  100.000000   \n",
       "median                   NaN  282.450000     0.000000  0.000000   64.000000   \n",
       "mean                     NaN  281.205870     0.334264  0.000222   49.362231   \n",
       "std                      NaN   13.338232    44.789133  0.008168   39.015750   \n",
       "\n",
       "        weather_main weather_description            date_time  traffic_volume  \n",
       "min            Clear             SQUALLS  2012-10-02 09:00:00        0.000000  \n",
       "max     Thunderstorm     very heavy rain  2018-09-30 23:00:00     7280.000000  \n",
       "median           NaN                 NaN                  NaN     3380.000000  \n",
       "mean             NaN                 NaN                  NaN     3259.818355  \n",
       "std              NaN                 NaN                  NaN     1986.860670  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_csv.agg([\"min\", \"max\", \"median\", \"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>temp_celsius</th>\n",
       "      <th>temp</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_main</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clouds</th>\n",
       "      <td>15164</td>\n",
       "      <td>8.316101</td>\n",
       "      <td>281.466101</td>\n",
       "      <td>3618.449749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haze</th>\n",
       "      <td>1360</td>\n",
       "      <td>2.668581</td>\n",
       "      <td>275.818581</td>\n",
       "      <td>3502.101471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rain</th>\n",
       "      <td>5672</td>\n",
       "      <td>13.829586</td>\n",
       "      <td>286.979586</td>\n",
       "      <td>3317.905501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drizzle</th>\n",
       "      <td>1821</td>\n",
       "      <td>10.645431</td>\n",
       "      <td>283.795431</td>\n",
       "      <td>3290.727073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoke</th>\n",
       "      <td>20</td>\n",
       "      <td>17.777500</td>\n",
       "      <td>290.927500</td>\n",
       "      <td>3237.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clear</th>\n",
       "      <td>13391</td>\n",
       "      <td>8.339971</td>\n",
       "      <td>281.489971</td>\n",
       "      <td>3055.908819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow</th>\n",
       "      <td>2876</td>\n",
       "      <td>-5.194812</td>\n",
       "      <td>267.955188</td>\n",
       "      <td>3016.844228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thunderstorm</th>\n",
       "      <td>1034</td>\n",
       "      <td>19.566431</td>\n",
       "      <td>292.716431</td>\n",
       "      <td>3001.620890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mist</th>\n",
       "      <td>5950</td>\n",
       "      <td>6.326892</td>\n",
       "      <td>279.476892</td>\n",
       "      <td>2932.956639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fog</th>\n",
       "      <td>912</td>\n",
       "      <td>6.265713</td>\n",
       "      <td>279.415713</td>\n",
       "      <td>2703.720395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Squall</th>\n",
       "      <td>4</td>\n",
       "      <td>19.237500</td>\n",
       "      <td>292.387500</td>\n",
       "      <td>2061.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               size  temp_celsius        temp  traffic_volume\n",
       "weather_main                                                 \n",
       "Clouds        15164      8.316101  281.466101     3618.449749\n",
       "Haze           1360      2.668581  275.818581     3502.101471\n",
       "Rain           5672     13.829586  286.979586     3317.905501\n",
       "Drizzle        1821     10.645431  283.795431     3290.727073\n",
       "Smoke            20     17.777500  290.927500     3237.650000\n",
       "Clear         13391      8.339971  281.489971     3055.908819\n",
       "Snow           2876     -5.194812  267.955188     3016.844228\n",
       "Thunderstorm   1034     19.566431  292.716431     3001.620890\n",
       "Mist           5950      6.326892  279.476892     2932.956639\n",
       "Fog             912      6.265713  279.415713     2703.720395\n",
       "Squall            4     19.237500  292.387500     2061.750000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_values = dataset_csv.groupby(\"weather_main\")[[\"temp\", \"traffic_volume\"]].mean()\n",
    "mean_values[\"temp_celsius\"] = mean_values[\"temp\"].apply(lambda temp_K: temp_K - 273.15)\n",
    "mean_values[\"size\"] = dataset_csv.groupby(\"weather_main\").size() # amount of entries in each group\n",
    "\n",
    "# order by the weather conditions which have the largest mean traffic volume\n",
    "mean_values[[\"size\", \"temp_celsius\", \"temp\", \"traffic_volume\"]].sort_values(by=\"traffic_volume\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rain_1h\n",
       "0.00       44737\n",
       "0.25         948\n",
       "0.26           2\n",
       "0.27           5\n",
       "0.28          23\n",
       "           ...  \n",
       "28.70          2\n",
       "31.75          1\n",
       "44.45          1\n",
       "55.63          1\n",
       "9831.30        1\n",
       "Length: 372, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 44737 / 48204 ~= 93.81% of entries have no rain (3467 have)\n",
    "dataset_csv.groupby(\"rain_1h\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snow_1h\n",
       "0.00    48141\n",
       "0.05       14\n",
       "0.06       12\n",
       "0.08        2\n",
       "0.10        6\n",
       "0.13        6\n",
       "0.17        3\n",
       "0.21        1\n",
       "0.25        6\n",
       "0.32        5\n",
       "0.44        2\n",
       "0.51        6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 48141 / 48204 ~= 99.87% of entries have no snow (only 63 have)\n",
    "dataset_csv.groupby(\"snow_1h\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll copy our dataset to the DataFrame object 'data' to clean it and\n",
    "# save it as a new .csv file later (splitting it into trainning/validation and test)\n",
    "data = dataset_csv.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Removing invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48204, 9) - (10, 9) => (48194, 9)\n"
     ]
    }
   ],
   "source": [
    "# removing entries with 0 Kelvin temperature\n",
    "print(f\"{data.shape} - {data.query('temp == 0.0').shape} => \", end='')\n",
    "\n",
    "data = data.query(\"temp > 0.0\")\n",
    "print(data.shape) # removes 10 invalid samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24872</th>\n",
       "      <td>None</td>\n",
       "      <td>302.11</td>\n",
       "      <td>9831.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Rain</td>\n",
       "      <td>very heavy rain</td>\n",
       "      <td>2016-07-11 17:00:00</td>\n",
       "      <td>5535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
       "24872    None  302.11   9831.3      0.0          75         Rain   \n",
       "\n",
       "      weather_description            date_time  traffic_volume  \n",
       "24872     very heavy rain  2016-07-11 17:00:00            5535  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the max value of rain_1h is invalid (>1000mm), so we'll drop it\n",
    "data.query(\"rain_1h > 0.0\").sort_values(by=\"rain_1h\", ascending=False).head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(index=24872, inplace=True) # removes the row where rain_1h == 9831.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48193, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Saving the clean dataset\n",
    "\n",
    "Note that we removed values from the whole dataset, and only then we'll split it into test, train and validation.\n",
    "\n",
    "However, the values we removed (0 Kelvin temperature and over 1000mm of rain in an hour) are clearly invalid, so even if we're dealing with test (never seen) data, we could confidently remove entries like these (besides that, only 11 rows were actually removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"date_time\"] = pd.to_datetime(data[\"date_time\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "data.set_index(\"date_time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the dataset into train/validation and test\n",
    "\n",
    "- test: 10%\n",
    "- train & validation: 90%\n",
    "    - train: 80%\n",
    "    - validation: 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed for splitting the data deterministically\n",
    "RANDOM_SEED = 886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: (48193, 8)\n",
      "\n",
      "train: (38554, 8)\n",
      "validation: (4819, 8)\n",
      "test: (4820, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"total: {data.shape}\\n\")\n",
    "\n",
    "train_data, test_validation_data = train_test_split(data, train_size=0.8, shuffle=True, random_state=RANDOM_SEED)\n",
    "print(f\"train: {train_data.shape}\") # 80%\n",
    "\n",
    "validation_data, test_data = train_test_split(test_validation_data, test_size=0.5, shuffle=True, random_state=RANDOM_SEED)\n",
    "print(f\"validation: {validation_data.shape}\") # 10% of total\n",
    "print(f\"test: {test_data.shape}\") # 10% of total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: \n",
      "                      traffic_volume\n",
      "date_time                          \n",
      "2012-10-02 09:00:00            5545\n",
      "2012-10-02 10:00:00            4516\n",
      "2012-10-02 11:00:00            4767\n",
      "2012-10-02 12:00:00            5026\n",
      "\n",
      "Validation: \n",
      "                      traffic_volume\n",
      "date_time                          \n",
      "2012-10-02 16:00:00            6015\n",
      "2012-10-03 20:00:00            2898\n",
      "2012-10-04 09:00:00            5309\n",
      "2012-10-04 10:00:00            4603\n",
      "\n",
      "Test: \n",
      "                      traffic_volume\n",
      "date_time                          \n",
      "2012-10-03 15:00:00            5692\n",
      "2012-10-03 23:00:00            1015\n",
      "2012-10-04 03:00:00             367\n",
      "2012-10-04 07:00:00            6990\n"
     ]
    }
   ],
   "source": [
    "# visualize the first values of each set\n",
    "print(\"Train: \\n\", train_data[[\"traffic_volume\"]].sort_values(\"date_time\").head(n=4))\n",
    "print(\"\\nValidation: \\n\", validation_data[[\"traffic_volume\"]].sort_values(\"date_time\").head(n=4))\n",
    "print(\"\\nTest: \\n\", test_data[[\"traffic_volume\"]].sort_values(\"date_time\").head(n=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transform features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Turn 'date_time' into 'hour', 'weekday' and 'weekofyear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformed_date_time(df):\n",
    "    transformed_df = df.copy()\n",
    "    transformed_df.insert(0, \"hour\", pd.DatetimeIndex(transformed_df.index).hour)\n",
    "    transformed_df.insert(1, \"weekday\", pd.DatetimeIndex(transformed_df.index).weekday)\n",
    "    transformed_df.insert(2, \"weekofyear\", pd.DatetimeIndex(transformed_df.index).weekofyear)\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Dropping 'snow_1h' and 'weather_description' columns\n",
    "They both seem redundant if we consider the 'weather_main' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropped_snow_1h_weather_description(df):\n",
    "    return df.drop(columns=[\"snow_1h\", \"weather_description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Adding holiday value to the whole day (not just at 00:00:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformed_holiday(df):\n",
    "    transformed_df = df.copy()\n",
    "    transformed_df[\"date_time\"] = transformed_df.index\n",
    "    \n",
    "    holidays = transformed_df[transformed_df.holiday != \"None\"]\n",
    "    holiday_names = [row[\"holiday\"] for index, row in holidays.iterrows()]\n",
    "    holiday_dates = holidays[\"date_time\"].dt.normalize()\n",
    "    \n",
    "    # add holiday name to holiday days on hours other than 00:00:00\n",
    "    for holiday_name, holiday_date in zip(holiday_names, holiday_dates):\n",
    "        transformed_df.loc[(transformed_df[\"date_time\"].dt.normalize() == holiday_date), \"holiday\"] = holiday_name\n",
    "    \n",
    "    return transformed_df.drop(columns=[\"date_time\"])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Apply changes to the split sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformed(dataset, transformations=[transformed_date_time, dropped_snow_1h_weather_description, transformed_holiday]):\n",
    "    for transform in transformations:\n",
    "        dataset = transform(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = transformed(train_data)\n",
    "validation_data = transformed(validation_data)\n",
    "\n",
    "test_data = transformed(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Transform categorical features\n",
    "\n",
    "Instead of turning a categorical feature with $n$ possible values into an $n$-D vector, with entries having only one non-zero — _hot_ — element, we'll drop one dimension (i.e. not use one of the values), creating an $(n-1)$-D vector to avoid the [Dummy Variable Trap](https://www.algosome.com/articles/dummy-variable-trap-regression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['None' 'Columbus Day' 'Veterans Day' 'Thanksgiving Day' 'Christmas Day'\n",
      " 'New Years Day' 'Washingtons Birthday' 'Memorial Day' 'Independence Day'\n",
      " 'State Fair' 'Labor Day' 'Martin Luther King Jr Day'] \n",
      "\n",
      "['Clouds' 'Clear' 'Rain' 'Drizzle' 'Mist' 'Haze' 'Fog' 'Thunderstorm'\n",
      " 'Snow' 'Squall' 'Smoke']\n"
     ]
    }
   ],
   "source": [
    "# categorical attributes: \"holiday\", \"weather_main\"\n",
    "print(data[\"holiday\"].unique(), '\\n')\n",
    "print(data[\"weather_main\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encoding, n-D: \n",
    "#   pd.get_dummies(df, prefix=\"weather\", columns=[\"weather_main\"])\n",
    "\n",
    "# one-hot encoding, (n-1)-D:\n",
    "#   pd.get_dummies(df, prefix=\"weather\", columns=[\"weather_main\"], drop_first=True)\n",
    "\n",
    "def encoded_weather_main(df):\n",
    "    encoded_df = df.copy()\n",
    "    weather_encoding = pd.get_dummies(encoded_df[\"weather_main\"], drop_first=True) # drops Clear weather\n",
    "    encoded_df = pd.concat([encoded_df, weather_encoding], axis=1)\n",
    "    encoded_df.drop(columns=[\"weather_main\"], inplace=True)\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll make 'holiday' a binary value\n",
    "def encoded_holiday(df):\n",
    "    encoded_df = df.copy()\n",
    "    # obs.: comparing the value to 0 prevents accidents when running this twice\n",
    "    encoded_df[\"holiday\"] = encoded_df[\"holiday\"].apply(lambda h: 0 if (h == \"None\" or h == 0) else 1)\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trasformed categorical features\n",
    "def encoded(dataset, encodings=[encoded_weather_main, encoded_holiday]):\n",
    "    for encode in encodings:\n",
    "        dataset = encode(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = encoded(train_data)\n",
    "validation_data = encoded(validation_data)\n",
    "\n",
    "test_data = encoded(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = set(train_data.columns).union(set(validation_data.columns).union(set(test_data.columns)))\n",
    "for col in columns:\n",
    "    if col not in train_data:\n",
    "        train_data[col] = 0\n",
    "    if col not in validation_data:\n",
    "        validation_data[col] = 0\n",
    "    if col not in test_data:\n",
    "        test_data[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 'traffic_volume' the last column\n",
    "columns_order = [col for col in columns if col != \"traffic_volume\"] + [\"traffic_volume\"]\n",
    "\n",
    "train_data = train_data[columns_order]\n",
    "validation_data = validation_data[columns_order]\n",
    "\n",
    "test_data = test_data[columns_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Normalize values\n",
    "\n",
    "It's important we **normalize our trainning data** and save the mapping we made to it so we can use the same values once we deal with the validation and test sets (i.e. we don't want to be normalizing the test and validation sets based on their own values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we have to change this list if new columns are added\n",
    "attrs_to_normalize = [\"traffic_volume\", \"hour\", \"weekday\", \"weekofyear\", \"temp\", \"rain_1h\", \"clouds_all\"]\n",
    "def get_stats(df, columns, operations=['min', 'max', 'median', 'mean', 'std']):\n",
    "    return df[columns].agg(operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-score normalization: $ x \\leftarrow \\dfrac{x - \\mu}{\\sigma}$ (makes the mean 0 and the standard deviation 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu = mean, sigma = stddev\n",
    "def z_score(x, mu, sigma):\n",
    "    return (x - mu) / sigma\n",
    "\n",
    "def normalized(dataset, stats):\n",
    "    normalized_dataset = dataset.copy()\n",
    "    for col in stats:\n",
    "        col_mean = stats.loc[\"mean\", col]\n",
    "        col_stddev = stats.loc[\"std\", col]\n",
    "        normalized_dataset.loc[:, col] = dataset.loc[:, col].apply(lambda x: z_score(x, mu=col_mean, sigma=col_stddev))\n",
    "    return normalized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we must use 'train_stats' when normalizing 'validation_data' and 'test_data' aswell\n",
    "train_stats = get_stats(train_data, columns=attrs_to_normalize).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>243.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7280.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>310.070000</td>\n",
       "      <td>55.630000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>3370.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>282.465000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3252.085594</td>\n",
       "      <td>11.372750</td>\n",
       "      <td>2.993230</td>\n",
       "      <td>26.467863</td>\n",
       "      <td>281.246050</td>\n",
       "      <td>0.131921</td>\n",
       "      <td>49.442289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1987.407287</td>\n",
       "      <td>6.944758</td>\n",
       "      <td>2.004335</td>\n",
       "      <td>14.850605</td>\n",
       "      <td>12.728783</td>\n",
       "      <td>1.025035</td>\n",
       "      <td>38.990004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        traffic_volume       hour   weekday  weekofyear        temp  \\\n",
       "min           0.000000   0.000000  0.000000    1.000000  243.390000   \n",
       "max        7280.000000  23.000000  6.000000   53.000000  310.070000   \n",
       "median     3370.000000  11.000000  3.000000   27.000000  282.465000   \n",
       "mean       3252.085594  11.372750  2.993230   26.467863  281.246050   \n",
       "std        1987.407287   6.944758  2.004335   14.850605   12.728783   \n",
       "\n",
       "          rain_1h  clouds_all  \n",
       "min      0.000000    0.000000  \n",
       "max     55.630000  100.000000  \n",
       "median   0.000000   64.000000  \n",
       "mean     0.131921   49.442289  \n",
       "std      1.025035   38.990004  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = normalized(train_data, stats=train_stats)\n",
    "validation_data = normalized(validation_data, stats=train_stats)\n",
    "test_data = normalized(test_data, stats=train_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.636346e+00</td>\n",
       "      <td>-1.637602e+00</td>\n",
       "      <td>-1.493378e+00</td>\n",
       "      <td>-1.714938e+00</td>\n",
       "      <td>-2.974051e+00</td>\n",
       "      <td>-1.286994e-01</td>\n",
       "      <td>-1.268076e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.026718e+00</td>\n",
       "      <td>1.674248e+00</td>\n",
       "      <td>1.500133e+00</td>\n",
       "      <td>1.786603e+00</td>\n",
       "      <td>2.264470e+00</td>\n",
       "      <td>5.414260e+01</td>\n",
       "      <td>1.296684e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>5.933077e-02</td>\n",
       "      <td>-5.367356e-02</td>\n",
       "      <td>3.377542e-03</td>\n",
       "      <td>3.583266e-02</td>\n",
       "      <td>9.576331e-02</td>\n",
       "      <td>-1.286994e-01</td>\n",
       "      <td>3.733704e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.667165e-17</td>\n",
       "      <td>2.543313e-17</td>\n",
       "      <td>-3.953193e-17</td>\n",
       "      <td>-5.897538e-18</td>\n",
       "      <td>9.187258e-17</td>\n",
       "      <td>4.791750e-18</td>\n",
       "      <td>3.133067e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        traffic_volume          hour       weekday    weekofyear  \\\n",
       "min      -1.636346e+00 -1.637602e+00 -1.493378e+00 -1.714938e+00   \n",
       "max       2.026718e+00  1.674248e+00  1.500133e+00  1.786603e+00   \n",
       "median    5.933077e-02 -5.367356e-02  3.377542e-03  3.583266e-02   \n",
       "mean      5.667165e-17  2.543313e-17 -3.953193e-17 -5.897538e-18   \n",
       "std       1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                temp       rain_1h    clouds_all  \n",
       "min    -2.974051e+00 -1.286994e-01 -1.268076e+00  \n",
       "max     2.264470e+00  5.414260e+01  1.296684e+00  \n",
       "median  9.576331e-02 -1.286994e-01  3.733704e-01  \n",
       "mean    9.187258e-17  4.791750e-18  3.133067e-18  \n",
       "std     1.000000e+00  1.000000e+00  1.000000e+00  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we should now see mean~=0 and std~=1 for all attributes\n",
    "get_stats(train_data, columns=attrs_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.634836</td>\n",
       "      <td>-1.637602</td>\n",
       "      <td>-1.493378</td>\n",
       "      <td>-1.714938</td>\n",
       "      <td>-2.908845</td>\n",
       "      <td>-0.128699</td>\n",
       "      <td>-1.268076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.906964</td>\n",
       "      <td>1.674248</td>\n",
       "      <td>1.500133</td>\n",
       "      <td>1.786603</td>\n",
       "      <td>2.170196</td>\n",
       "      <td>24.572889</td>\n",
       "      <td>1.296684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.129271</td>\n",
       "      <td>0.090320</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.035833</td>\n",
       "      <td>0.115797</td>\n",
       "      <td>-0.128699</td>\n",
       "      <td>0.373370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.031358</td>\n",
       "      <td>0.021147</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.024347</td>\n",
       "      <td>0.013055</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>-0.008086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.994448</td>\n",
       "      <td>0.985955</td>\n",
       "      <td>1.007676</td>\n",
       "      <td>0.997670</td>\n",
       "      <td>0.995840</td>\n",
       "      <td>0.901125</td>\n",
       "      <td>1.003678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        traffic_volume      hour   weekday  weekofyear      temp    rain_1h  \\\n",
       "min          -1.634836 -1.637602 -1.493378   -1.714938 -2.908845  -0.128699   \n",
       "max           1.906964  1.674248  1.500133    1.786603  2.170196  24.572889   \n",
       "median        0.129271  0.090320  0.003378    0.035833  0.115797  -0.128699   \n",
       "mean          0.031358  0.021147  0.001514    0.024347  0.013055   0.003504   \n",
       "std           0.994448  0.985955  1.007676    0.997670  0.995840   0.901125   \n",
       "\n",
       "        clouds_all  \n",
       "min      -1.268076  \n",
       "max       1.296684  \n",
       "median    0.373370  \n",
       "mean     -0.008086  \n",
       "std       1.003678  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we should now see mean close to 0 and std close to 1\n",
    "get_stats(validation_data, columns=attrs_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.635843</td>\n",
       "      <td>-1.637602</td>\n",
       "      <td>-1.493378</td>\n",
       "      <td>-1.714938</td>\n",
       "      <td>-2.861707</td>\n",
       "      <td>-0.128699</td>\n",
       "      <td>-1.268076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.016655</td>\n",
       "      <td>1.674248</td>\n",
       "      <td>1.500133</td>\n",
       "      <td>1.786603</td>\n",
       "      <td>2.004430</td>\n",
       "      <td>24.709470</td>\n",
       "      <td>1.296684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.043984</td>\n",
       "      <td>-0.053674</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.035833</td>\n",
       "      <td>0.068620</td>\n",
       "      <td>-0.128699</td>\n",
       "      <td>0.373370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.009341</td>\n",
       "      <td>0.017158</td>\n",
       "      <td>-0.044651</td>\n",
       "      <td>-0.008174</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>-0.018913</td>\n",
       "      <td>-0.009955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.002002</td>\n",
       "      <td>1.007484</td>\n",
       "      <td>0.999010</td>\n",
       "      <td>0.995686</td>\n",
       "      <td>0.988977</td>\n",
       "      <td>0.878543</td>\n",
       "      <td>1.002495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        traffic_volume      hour   weekday  weekofyear      temp    rain_1h  \\\n",
       "min          -1.635843 -1.637602 -1.493378   -1.714938 -2.861707  -0.128699   \n",
       "max           2.016655  1.674248  1.500133    1.786603  2.004430  24.709470   \n",
       "median        0.043984 -0.053674  0.003378    0.035833  0.068620  -0.128699   \n",
       "mean          0.009341  0.017158 -0.044651   -0.008174  0.000880  -0.018913   \n",
       "std           1.002002  1.007484  0.999010    0.995686  0.988977   0.878543   \n",
       "\n",
       "        clouds_all  \n",
       "min      -1.268076  \n",
       "max       1.296684  \n",
       "median    0.373370  \n",
       "mean     -0.009955  \n",
       "std       1.002495  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we should now see mean close to 0 and std close to 1\n",
    "get_stats(test_data, columns=attrs_to_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save the split data, normalized with values from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_80.csv\")\n",
    "validation_data.to_csv(\"validation_10.csv\")\n",
    "\n",
    "test_data.to_csv(\"test_10.csv\") # and now.. don't touch it anymore!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perform Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis: \n",
    "$h_{\\theta}(x) = \\theta^T x = \\theta_0 + \\theta_1 x_1 + ... + \\theta_n x_n$, where:\n",
    "\n",
    "- $x = (x_0, x_1, ..., x_n)$, with $x_0 = 1$ and the values from $1$ to $n$ are taken from rows of our dataset.\n",
    "- $\\theta = (\\theta_0, \\theta_1, ..., \\theta_n)$ are the parameters.\n",
    "\n",
    "### Cost function: \n",
    "$J(\\theta) = \\dfrac{1}{2m} \\sum\\limits_{i=1}^m (h_{\\theta}(x^{(i)}) - y^{(i)})^2 \\; \\Longrightarrow \\; \n",
    "\\dfrac{\\partial J(\\theta)}{\\partial \\theta_j} = \\dfrac{1}{m} \\sum\\limits_{i=1}^m (\\,(h_{\\theta}(x^{(i)}) - y^{(i)}) \\, x_j^{(i)}\\,)$, where:\n",
    "\n",
    "- $m$ is the number of examples.\n",
    "- $n$ is the number of features.\n",
    "- $x^{(i)} = (1, x_1^{(i)}, ..., x_n^{(i)})$ are the features of the $i^{th}$ training example ($\\forall{i},\\,x_0^{(i)} = 1$).\n",
    "- $x_j^{(i)}$ is the value of feature $j$ of the $i^{th}$ training example.\n",
    "- $y = (y^{(1)}, ..., y^{(m)})$ are the target values.\n",
    "- $y^{(i)}$ is the target value for the $i^{th}$ training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta is an array of 'params' of shape=(n_features, 1)\n",
    "# -> (n+1) x 1\n",
    "\n",
    "# X is a matrix of 'data', with each line being an 'example', of shape=(n_examples, n_features)\n",
    "# -> m x (n+1)\n",
    "\n",
    "# y is an array of 'target' values for each example of shape=(n_examples, 1)\n",
    "# -> m x 1\n",
    "\n",
    "''' Returns a scalar, corresponding to the value of J(theta). '''\n",
    "def loss_function(theta, X, y):\n",
    "    assert(X.shape[0] == y.shape[0]), f\"X.shape[0] != y.shape[0] for shapes: {X.shape} of X, and {y.shape} of y\"\n",
    "    assert(X.shape[1] == theta.shape[0]), f\"X.shape[1] != theta.shape[0] for shapes: {X.shape} of X, and {theta.shape} of theta\"\n",
    "    \n",
    "    m = X.shape[0] # number of examples\n",
    "    \n",
    "    #loss = X.dot(theta) # estimate of y (h_theta(X))\n",
    "    #loss = loss - y     # error between estimate and real y values (h_theta(X) - y)\n",
    "    #loss = loss**2      # squared error of each element (h_theta(X) - y)**2\n",
    "    #loss = 0.5 * (1 / m) * loss.sum()\n",
    "\n",
    "    return 0.5 * (1 / m) * np.sum((X.dot(theta) - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Returns a (n+1) x 1 array with the gradient values for each theta_j. '''\n",
    "def eval_gradient(theta, X, y):\n",
    "    assert(X.shape[0] == y.shape[0]), f\"X.shape[0] != y.shape[0] for shapes: {X.shape} of X, and {y.shape} of y\"\n",
    "    assert(X.shape[1] == theta.shape[0]), f\"X.shape[1] != theta.shape[0] for shapes: {X.shape} of X, and {theta.shape} of theta\"\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    #loss_partial_theta = X.dot(theta) # h_theta(X) = X • theta\n",
    "    #loss_partial_theta = loss_partial_theta - y # h_theta(X) - y\n",
    "    #loss_partial_theta = X.T.dot(loss_partial_theta) # X_transposed • (h_theta(X) - y)\n",
    "    #loss_partial_theta = (1 / m) * loss_partial_theta\n",
    "    \n",
    "    # gradient for every theta (an array with each j-th element being the partial derivative of J with respect to theta_j)\n",
    "    return (1 / m) * np.dot(X.T, X.dot(theta) - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent: \n",
    "Given the learning rate $\\alpha$:\n",
    "\n",
    "**repeat {** $\\theta_j := \\theta_j - \\alpha \\dfrac{\\partial J(\\theta)}{\\partial \\theta_j}$ \n",
    "**}** (simultaneously update for $j = 0, 1, ..., n$)\n",
    "\n",
    "If we consider a matrix $\\mathbb{X}$, with each row $i$ equal to $x^{(i)}$ transposed ($1 \\leq i \\leq m$), we have:\n",
    "$\\theta := \\theta - \\alpha (\\,\\frac{1}{m} \\mathbb{X}^T (\\mathbb{X} \\theta - y)\\,)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED) # use for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Perform one epoch of gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Returns a (n+1) x 1 array with the updated values for each parameter theta_j. \n",
    "\n",
    "    Assumes that 'X' is a matrix with shape=(n_examples, n_features), with a first column of 1's, and that\n",
    "    'y' is an array of shape=(n_examples, 1) with the corresponding target values for each row of 'X'.\n",
    "    \n",
    "    n_examples = m\n",
    "    n_features = n+1 (x_0 = 1 for every row i in [1, m], i.e. X[i, 0] = 1)\n",
    "'''\n",
    "def stochastic_GD_step(theta, X, y, learning_rate):\n",
    "    X, y = shuffled_X_y(X, y, seed=RANDOM_SEED)\n",
    "    for sample_X, sample_y in zip(X, y):\n",
    "        theta_grad = eval_gradient(theta, sample_X.reshape(1, -1), sample_y)\n",
    "        theta = theta - learning_rate * theta_grad\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffled_X_y(X, y, seed):\n",
    "    assert(X.shape[0] == y.shape[0]), f\"X.shape[0] != y.shape[0] for shapes: {X.shape} of X, and {y.shape} of y\"\n",
    "    m = y.shape[0]\n",
    "    p = np.random.permutation(m)\n",
    "    return X[p], y[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Returns a (n+1) x 1 array with the updated values for each parameter theta_j. \n",
    "\n",
    "    If batch_size is specified, acts as a Mini Batch GD, otherwise, it works like Vanilla GD.\n",
    "\n",
    "    Assumes that 'X' is a matrix with shape=(n_examples, n_features), with a first column of 1's, and that\n",
    "    'y' is an array of shape=(n_examples, 1) with the corresponding target values for each row of 'X'.\n",
    "    \n",
    "    n_examples = m\n",
    "    n_features = n+1 (x_0 = 1 for every row i in [1, m], i.e. X[i, 0] = 1)\n",
    "'''\n",
    "def batch_GD_step(theta, X, y, learning_rate, batch_size=None):\n",
    "    if not batch_size:\n",
    "        # vanilla\n",
    "        theta_grad = eval_gradient(theta, X, y)\n",
    "        theta = theta - learning_rate * theta_grad\n",
    "    else:\n",
    "        # mini batch\n",
    "        X, y = shuffled_X_y(X, y, seed=RANDOM_SEED)\n",
    "        for batch_X, batch_y in get_batches(X, y, batch_size):\n",
    "            theta_grad = eval_gradient(theta, batch_X, batch_y)\n",
    "            theta = theta - learning_rate * theta_grad\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(X, y, batch_size):\n",
    "    assert(X.shape[0] == y.shape[0]), f\"X.shape[0] != y.shape[0] for shapes: {X.shape} of X, and {y.shape} of y\"\n",
    "    m = y.shape[0]\n",
    "    n_of_batches = m // batch_size\n",
    "    try:\n",
    "        return zip(np.split(X, n_of_batches), np.split(y, n_of_batches))\n",
    "    except:\n",
    "        warnings.warn(f\"batch_size={batch_size} does not result in an equal division for shapes: \" +\n",
    "                      f\"{X.shape} of X, and {y.shape} of y. The last batch will have size {m % batch_size}\")\n",
    "        return zip(np.array_split(X, n_of_batches), np.array_split(y, n_of_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Run gradient descent for a specified number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __gradient_descent(theta, train_X_y, validation_X_y, learning_rate, n_epochs, \n",
    "                       GD_step_func, batch_size_kwarg_if_mini_batch=None):\n",
    "    if batch_size_kwarg_if_mini_batch == None:\n",
    "        batch_size_kwarg_if_mini_batch = {}\n",
    "        \n",
    "    X, y = train_X_y\n",
    "    val_X, val_y = validation_X_y\n",
    "    \n",
    "    loss = loss_function(theta, X, y)\n",
    "    val_loss = loss_function(theta, val_X, val_y)\n",
    "    \n",
    "    # stores the best values for minimizing J(theta) on the validation set\n",
    "    best_params = theta.copy()\n",
    "    best_val_loss = val_loss\n",
    "    \n",
    "    # save the loss values for plotting\n",
    "    plot_dict = { \n",
    "        \"best_val_loss\": best_val_loss, \n",
    "        \"best_val_loss_epoch\": 0, \n",
    "        \"loss\": [loss], # training set\n",
    "        \"val_loss\": [val_loss] # validation set\n",
    "    }\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        theta = GD_step_func(theta, X, y, learning_rate, **batch_size_kwarg_if_mini_batch)\n",
    "    \n",
    "        loss = loss_function(theta, X, y)\n",
    "        plot_dict[\"loss\"].append(loss) # training set\n",
    "        \n",
    "        val_loss = loss_function(theta, val_X, val_y)\n",
    "        plot_dict[\"val_loss\"].append(val_loss) # validation set\n",
    "        \n",
    "        # update the best loss and store the current parameters if val_loss < best_val_loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_params = theta.copy()\n",
    "            plot_dict[\"best_val_loss_epoch\"] = epoch + 1\n",
    "        \n",
    "        print(f\"({epoch + 1} / {n_epochs}) training: {loss:.4f} | validation: {val_loss:.4f}\", end='\\r')\n",
    "        \n",
    "    plot_dict[\"best_val_loss\"] = best_val_loss\n",
    "    return best_params, plot_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Compute $\\mathbb{X}$ and $y$\n",
    "\n",
    "Let's add our datasets' features to $\\mathbb{X}$ (plus $x_0 = 1$) and it's target values to $y$, so we can train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: assumes target values are in the last column of 'dataset'\n",
    "def split_X_y(dataset):\n",
    "    dataset = dataset.to_numpy(copy=True)\n",
    "    m = dataset.shape[0] # number of examples\n",
    "    X = np.c_[np.ones(shape=(m, 1)), dataset[:, :-1]] # add a column of x_0's equal to 1\n",
    "    y = dataset[:, -1:]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_y = split_X_y(train_data)\n",
    "validation_X_y = split_X_y(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if the values are correct\n",
    "# X, y = train_X_y\n",
    "# for i in range(4):\n",
    "#     print(f\"dataset: {train_data.iloc[i].values}\\n\") # should be equal to np.append(X[i, 1:], y[i])\n",
    "#     print(f\"check:   {np.append(X[i, 1:], y[i])}\\n\")\n",
    "#     #print(f\"X: {X[i]}\\n\")\n",
    "#     #print(f\"y: {y[i]}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. Run our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Returns the initial theta (n+1) x 1 array. '''\n",
    "def init_params(n_features, zeros=False):\n",
    "    if zeros:\n",
    "        return np.zeros(shape=(n_features, 1))\n",
    "    else:\n",
    "        # Xavier initialization\n",
    "        return np.sqrt(2 / n_features) * np.random.randn(n_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params, train_X_y, validation_X_y, learning_rate, n_epochs, batch_size=None, GD_flavor=\"vanilla\"):\n",
    "    if GD_flavor == \"vanilla\":        \n",
    "        best_params, plot_dict = __gradient_descent(params, train_X_y, validation_X_y, learning_rate, n_epochs, \n",
    "                                                    GD_step_func=batch_GD_step)\n",
    "\n",
    "    elif GD_flavor == \"mini batch\":\n",
    "        if batch_size == None:\n",
    "            warnings.warn(\"You should specify batch_size when using GD_flavor='mini batch'.\")\n",
    "        best_params, plot_dict = __gradient_descent(params, train_X_y, validation_X_y, learning_rate, n_epochs, \n",
    "                                                    GD_step_func=batch_GD_step, \n",
    "                                                    batch_size_kwarg_if_mini_batch={ \"batch_size\": batch_size })\n",
    "        plot_dict[\"batch_size\"] = batch_size\n",
    "\n",
    "    elif GD_flavor == \"stochastic\":\n",
    "        best_params, plot_dict = __gradient_descent(params, train_X_y, validation_X_y, learning_rate, n_epochs, \n",
    "                                                    GD_step_func=stochastic_GD_step)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"GD_flavor must be one of the following values: 'vanilla', 'stochastic', or 'mini batch'.\")\n",
    "        \n",
    "    plot_dict[\"learning_rate\"] = learning_rate\n",
    "    plot_dict[\"n_epochs\"]      = n_epochs\n",
    "    plot_dict[\"flavor\"]        = GD_flavor\n",
    "    \n",
    "    return best_params, plot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "n_features: 18\n",
      "n_examples: 38554\n",
      "\n",
      "Validation set:\n",
      "val_n_features: 18\n",
      "val_n_examples: 4819\n"
     ]
    }
   ],
   "source": [
    "X, y = train_X_y\n",
    "n_examples, n_features = X.shape # m x (n+1)\n",
    "print(\"Training set:\")\n",
    "print(f\"n_features: {n_features}\")\n",
    "print(f\"n_examples: {n_examples}\")\n",
    "\n",
    "val_X, val_y = validation_X_y\n",
    "val_n_examples, val_n_features = val_X.shape # m x (n+1)\n",
    "print(\"\\nValidation set:\")\n",
    "print(f\"val_n_features: {val_n_features}\")\n",
    "print(f\"val_n_examples: {val_n_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_GD(learning_rate, n_epochs, GD_flavor, batch_size=None):\n",
    "    best_params, plot_dict = train(init_params(n_features, zeros=True), \n",
    "                                   train_X_y, validation_X_y, \n",
    "                                   learning_rate, n_epochs,  \n",
    "                                   batch_size, GD_flavor)\n",
    "    print(\"\\n\\nBest validation loss: {best_val_loss:.6f} (at epoch {best_val_loss_epoch})\".format(\n",
    "        best_val_loss=plot_dict['best_val_loss'], \n",
    "        best_val_loss_epoch=plot_dict['best_val_loss_epoch']))\n",
    "    return best_params, plot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_GD_run(params, plot_dict):\n",
    "    plot_title = \"{flavor} GD\\n({n_epochs} epochs with α = {learning_rate}\".format(\n",
    "        flavor=plot_dict['flavor'], \n",
    "        n_epochs=plot_dict['n_epochs'], \n",
    "        learning_rate=plot_dict['learning_rate'])\n",
    "    plot_title += \")\" if 'batch_size' not in plot_dict else \" and {batch_size} batch size)\".format(\n",
    "        batch_size=plot_dict['batch_size'])\n",
    "\n",
    "    # leave only \"loss\" and \"val_loss\" for plotting\n",
    "    loss_data = pd.DataFrame({k: v for k, v in plot_dict.items() if (k == \"loss\" or k == \"val_loss\")})\n",
    "\n",
    "    sns.lineplot(data=loss_data).set_title(plot_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 Learning rate of 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1 / 10000) training: 0.4999 | validation: 0.4948\r",
      "(2 / 10000) training: 0.4998 | validation: 0.4947\r",
      "(3 / 10000) training: 0.4997 | validation: 0.4946\r",
      "(4 / 10000) training: 0.4996 | validation: 0.4945\r",
      "(5 / 10000) training: 0.4995 | validation: 0.4944\r",
      "(6 / 10000) training: 0.4995 | validation: 0.4943\r",
      "(7 / 10000) training: 0.4994 | validation: 0.4942\r",
      "(8 / 10000) training: 0.4993 | validation: 0.4942\r",
      "(9 / 10000) training: 0.4992 | validation: 0.4941\r",
      "(10 / 10000) training: 0.4991 | validation: 0.4940\r",
      "(11 / 10000) training: 0.4990 | validation: 0.4939\r",
      "(12 / 10000) training: 0.4989 | validation: 0.4938\r",
      "(13 / 10000) training: 0.4989 | validation: 0.4937\r",
      "(14 / 10000) training: 0.4988 | validation: 0.4936\r",
      "(15 / 10000) training: 0.4987 | validation: 0.4936\r",
      "(16 / 10000) training: 0.4986 | validation: 0.4935\r",
      "(17 / 10000) training: 0.4985 | validation: 0.4934\r",
      "(18 / 10000) training: 0.4984 | validation: 0.4933\r",
      "(19 / 10000) training: 0.4983 | validation: 0.4932\r",
      "(20 / 10000) training: 0.4983 | validation: 0.4931\r",
      "(21 / 10000) training: 0.4982 | validation: 0.4930\r",
      "(22 / 10000) training: 0.4981 | validation: 0.4930\r",
      "(23 / 10000) training: 0.4980 | validation: 0.4929\r",
      "(24 / 10000) training: 0.4979 | validation: 0.4928\r",
      "(25 / 10000) training: 0.4978 | validation: 0.4927\r",
      "(26 / 10000) training: 0.4977 | validation: 0.4926\r",
      "(27 / 10000) training: 0.4977 | validation: 0.4925\r",
      "(28 / 10000) training: 0.4976 | validation: 0.4924\r",
      "(29 / 10000) training: 0.4975 | validation: 0.4924\r",
      "(30 / 10000) training: 0.4974 | validation: 0.4923\r",
      "(31 / 10000) training: 0.4973 | validation: 0.4922\r",
      "(32 / 10000) training: 0.4972 | validation: 0.4921\r",
      "(33 / 10000) training: 0.4971 | validation: 0.4920\r",
      "(34 / 10000) training: 0.4971 | validation: 0.4919\r",
      "(35 / 10000) training: 0.4970 | validation: 0.4919\r",
      "(36 / 10000) training: 0.4969 | validation: 0.4918\r",
      "(37 / 10000) training: 0.4968 | validation: 0.4917\r",
      "(38 / 10000) training: 0.4967 | validation: 0.4916\r",
      "(39 / 10000) training: 0.4966 | validation: 0.4915\r",
      "(40 / 10000) training: 0.4966 | validation: 0.4914\r",
      "(41 / 10000) training: 0.4965 | validation: 0.4913\r",
      "(42 / 10000) training: 0.4964 | validation: 0.4913\r",
      "(43 / 10000) training: 0.4963 | validation: 0.4912\r",
      "(44 / 10000) training: 0.4962 | validation: 0.4911\r",
      "(45 / 10000) training: 0.4961 | validation: 0.4910\r",
      "(46 / 10000) training: 0.4960 | validation: 0.4909\r",
      "(47 / 10000) training: 0.4960 | validation: 0.4908\r",
      "(48 / 10000) training: 0.4959 | validation: 0.4908\r",
      "(49 / 10000) training: 0.4958 | validation: 0.4907\r",
      "(50 / 10000) training: 0.4957 | validation: 0.4906\r",
      "(51 / 10000) training: 0.4956 | validation: 0.4905\r",
      "(52 / 10000) training: 0.4955 | validation: 0.4904\r",
      "(53 / 10000) training: 0.4955 | validation: 0.4903\r",
      "(54 / 10000) training: 0.4954 | validation: 0.4903\r",
      "(55 / 10000) training: 0.4953 | validation: 0.4902\r",
      "(56 / 10000) training: 0.4952 | validation: 0.4901\r",
      "(57 / 10000) training: 0.4951 | validation: 0.4900\r",
      "(58 / 10000) training: 0.4951 | validation: 0.4899\r",
      "(59 / 10000) training: 0.4950 | validation: 0.4899\r",
      "(60 / 10000) training: 0.4949 | validation: 0.4898\r",
      "(61 / 10000) training: 0.4948 | validation: 0.4897\r",
      "(62 / 10000) training: 0.4947 | validation: 0.4896\r",
      "(63 / 10000) training: 0.4946 | validation: 0.4895\r",
      "(64 / 10000) training: 0.4946 | validation: 0.4894\r",
      "(65 / 10000) training: 0.4945 | validation: 0.4894\r",
      "(66 / 10000) training: 0.4944 | validation: 0.4893\r",
      "(67 / 10000) training: 0.4943 | validation: 0.4892\r",
      "(68 / 10000) training: 0.4942 | validation: 0.4891\r",
      "(69 / 10000) training: 0.4942 | validation: 0.4890\r",
      "(70 / 10000) training: 0.4941 | validation: 0.4890\r",
      "(71 / 10000) training: 0.4940 | validation: 0.4889\r",
      "(72 / 10000) training: 0.4939 | validation: 0.4888\r",
      "(73 / 10000) training: 0.4938 | validation: 0.4887\r",
      "(74 / 10000) training: 0.4937 | validation: 0.4886\r",
      "(75 / 10000) training: 0.4937 | validation: 0.4886\r",
      "(76 / 10000) training: 0.4936 | validation: 0.4885\r",
      "(77 / 10000) training: 0.4935 | validation: 0.4884\r",
      "(78 / 10000) training: 0.4934 | validation: 0.4883\r",
      "(79 / 10000) training: 0.4933 | validation: 0.4882\r",
      "(80 / 10000) training: 0.4933 | validation: 0.4882\r",
      "(81 / 10000) training: 0.4932 | validation: 0.4881\r",
      "(82 / 10000) training: 0.4931 | validation: 0.4880\r",
      "(83 / 10000) training: 0.4930 | validation: 0.4879\r",
      "(84 / 10000) training: 0.4929 | validation: 0.4878\r",
      "(85 / 10000) training: 0.4929 | validation: 0.4878\r",
      "(86 / 10000) training: 0.4928 | validation: 0.4877\r",
      "(87 / 10000) training: 0.4927 | validation: 0.4876\r",
      "(88 / 10000) training: 0.4926 | validation: 0.4875\r",
      "(89 / 10000) training: 0.4925 | validation: 0.4874\r",
      "(90 / 10000) training: 0.4925 | validation: 0.4874\r",
      "(91 / 10000) training: 0.4924 | validation: 0.4873\r",
      "(92 / 10000) training: 0.4923 | validation: 0.4872\r",
      "(93 / 10000) training: 0.4922 | validation: 0.4871\r",
      "(94 / 10000) training: 0.4921 | validation: 0.4870\r",
      "(95 / 10000) training: 0.4921 | validation: 0.4870\r",
      "(96 / 10000) training: 0.4920 | validation: 0.4869\r",
      "(97 / 10000) training: 0.4919 | validation: 0.4868\r",
      "(98 / 10000) training: 0.4918 | validation: 0.4867\r",
      "(99 / 10000) training: 0.4917 | validation: 0.4866\r",
      "(100 / 10000) training: 0.4917 | validation: 0.4866\r",
      "(101 / 10000) training: 0.4916 | validation: 0.4865\r",
      "(102 / 10000) training: 0.4915 | validation: 0.4864\r",
      "(103 / 10000) training: 0.4914 | validation: 0.4863\r",
      "(104 / 10000) training: 0.4914 | validation: 0.4862\r",
      "(105 / 10000) training: 0.4913 | validation: 0.4862\r",
      "(106 / 10000) training: 0.4912 | validation: 0.4861\r",
      "(107 / 10000) training: 0.4911 | validation: 0.4860\r",
      "(108 / 10000) training: 0.4910 | validation: 0.4859\r",
      "(109 / 10000) training: 0.4910 | validation: 0.4859\r",
      "(110 / 10000) training: 0.4909 | validation: 0.4858\r",
      "(111 / 10000) training: 0.4908 | validation: 0.4857\r",
      "(112 / 10000) training: 0.4907 | validation: 0.4856\r",
      "(113 / 10000) training: 0.4906 | validation: 0.4855\r",
      "(114 / 10000) training: 0.4906 | validation: 0.4855\r",
      "(115 / 10000) training: 0.4905 | validation: 0.4854\r",
      "(116 / 10000) training: 0.4904 | validation: 0.4853\r",
      "(117 / 10000) training: 0.4903 | validation: 0.4852\r",
      "(118 / 10000) training: 0.4903 | validation: 0.4852\r",
      "(119 / 10000) training: 0.4902 | validation: 0.4851\r",
      "(120 / 10000) training: 0.4901 | validation: 0.4850\r",
      "(121 / 10000) training: 0.4900 | validation: 0.4849\r",
      "(122 / 10000) training: 0.4900 | validation: 0.4849\r",
      "(123 / 10000) training: 0.4899 | validation: 0.4848\r",
      "(124 / 10000) training: 0.4898 | validation: 0.4847\r",
      "(125 / 10000) training: 0.4897 | validation: 0.4846\r",
      "(126 / 10000) training: 0.4896 | validation: 0.4845\r",
      "(127 / 10000) training: 0.4896 | validation: 0.4845\r",
      "(128 / 10000) training: 0.4895 | validation: 0.4844\r",
      "(129 / 10000) training: 0.4894 | validation: 0.4843\r",
      "(130 / 10000) training: 0.4893 | validation: 0.4842\r",
      "(131 / 10000) training: 0.4893 | validation: 0.4842\r",
      "(132 / 10000) training: 0.4892 | validation: 0.4841\r",
      "(133 / 10000) training: 0.4891 | validation: 0.4840\r",
      "(134 / 10000) training: 0.4890 | validation: 0.4839\r",
      "(135 / 10000) training: 0.4890 | validation: 0.4839\r",
      "(136 / 10000) training: 0.4889 | validation: 0.4838\r",
      "(137 / 10000) training: 0.4888 | validation: 0.4837\r",
      "(138 / 10000) training: 0.4887 | validation: 0.4836\r",
      "(139 / 10000) training: 0.4887 | validation: 0.4836\r",
      "(140 / 10000) training: 0.4886 | validation: 0.4835\r",
      "(141 / 10000) training: 0.4885 | validation: 0.4834\r",
      "(142 / 10000) training: 0.4884 | validation: 0.4833\r",
      "(143 / 10000) training: 0.4884 | validation: 0.4833\r",
      "(144 / 10000) training: 0.4883 | validation: 0.4832\r",
      "(145 / 10000) training: 0.4882 | validation: 0.4831\r",
      "(146 / 10000) training: 0.4881 | validation: 0.4830\r",
      "(147 / 10000) training: 0.4881 | validation: 0.4830\r",
      "(148 / 10000) training: 0.4880 | validation: 0.4829\r",
      "(149 / 10000) training: 0.4879 | validation: 0.4828\r",
      "(150 / 10000) training: 0.4878 | validation: 0.4827\r",
      "(151 / 10000) training: 0.4878 | validation: 0.4827\r",
      "(152 / 10000) training: 0.4877 | validation: 0.4826\r",
      "(153 / 10000) training: 0.4876 | validation: 0.4825\r",
      "(154 / 10000) training: 0.4875 | validation: 0.4824\r",
      "(155 / 10000) training: 0.4875 | validation: 0.4824\r",
      "(156 / 10000) training: 0.4874 | validation: 0.4823\r",
      "(157 / 10000) training: 0.4873 | validation: 0.4822\r",
      "(158 / 10000) training: 0.4872 | validation: 0.4821\r",
      "(159 / 10000) training: 0.4872 | validation: 0.4821\r",
      "(160 / 10000) training: 0.4871 | validation: 0.4820\r",
      "(161 / 10000) training: 0.4870 | validation: 0.4819\r",
      "(162 / 10000) training: 0.4869 | validation: 0.4818\r",
      "(163 / 10000) training: 0.4869 | validation: 0.4818\r",
      "(164 / 10000) training: 0.4868 | validation: 0.4817\r",
      "(165 / 10000) training: 0.4867 | validation: 0.4816\r",
      "(166 / 10000) training: 0.4866 | validation: 0.4816\r",
      "(167 / 10000) training: 0.4866 | validation: 0.4815\r",
      "(168 / 10000) training: 0.4865 | validation: 0.4814\r",
      "(169 / 10000) training: 0.4864 | validation: 0.4813\r",
      "(170 / 10000) training: 0.4864 | validation: 0.4813\r",
      "(171 / 10000) training: 0.4863 | validation: 0.4812\r",
      "(172 / 10000) training: 0.4862 | validation: 0.4811"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "(173 / 10000) training: 0.4861 | validation: 0.4810\r",
      "(174 / 10000) training: 0.4861 | validation: 0.4810\r",
      "(175 / 10000) training: 0.4860 | validation: 0.4809\r",
      "(176 / 10000) training: 0.4859 | validation: 0.4808\r",
      "(177 / 10000) training: 0.4858 | validation: 0.4808\r",
      "(178 / 10000) training: 0.4858 | validation: 0.4807\r",
      "(179 / 10000) training: 0.4857 | validation: 0.4806\r",
      "(180 / 10000) training: 0.4856 | validation: 0.4805\r",
      "(181 / 10000) training: 0.4856 | validation: 0.4805\r",
      "(182 / 10000) training: 0.4855 | validation: 0.4804\r",
      "(183 / 10000) training: 0.4854 | validation: 0.4803\r",
      "(184 / 10000) training: 0.4853 | validation: 0.4802\r",
      "(185 / 10000) training: 0.4853 | validation: 0.4802\r",
      "(186 / 10000) training: 0.4852 | validation: 0.4801\r",
      "(187 / 10000) training: 0.4851 | validation: 0.4800\r",
      "(188 / 10000) training: 0.4850 | validation: 0.4800\r",
      "(189 / 10000) training: 0.4850 | validation: 0.4799\r",
      "(190 / 10000) training: 0.4849 | validation: 0.4798\r",
      "(191 / 10000) training: 0.4848 | validation: 0.4797\r",
      "(192 / 10000) training: 0.4848 | validation: 0.4797\r",
      "(193 / 10000) training: 0.4847 | validation: 0.4796\r",
      "(194 / 10000) training: 0.4846 | validation: 0.4795\r",
      "(195 / 10000) training: 0.4845 | validation: 0.4795\r",
      "(196 / 10000) training: 0.4845 | validation: 0.4794\r",
      "(197 / 10000) training: 0.4844 | validation: 0.4793\r",
      "(198 / 10000) training: 0.4843 | validation: 0.4792\r",
      "(199 / 10000) training: 0.4843 | validation: 0.4792\r",
      "(200 / 10000) training: 0.4842 | validation: 0.4791\r",
      "(201 / 10000) training: 0.4841 | validation: 0.4790\r",
      "(202 / 10000) training: 0.4841 | validation: 0.4790\r",
      "(203 / 10000) training: 0.4840 | validation: 0.4789\r",
      "(204 / 10000) training: 0.4839 | validation: 0.4788\r",
      "(205 / 10000) training: 0.4838 | validation: 0.4788\r",
      "(206 / 10000) training: 0.4838 | validation: 0.4787\r",
      "(207 / 10000) training: 0.4837 | validation: 0.4786\r",
      "(208 / 10000) training: 0.4836 | validation: 0.4785\r",
      "(209 / 10000) training: 0.4836 | validation: 0.4785\r",
      "(210 / 10000) training: 0.4835 | validation: 0.4784\r",
      "(211 / 10000) training: 0.4834 | validation: 0.4783\r",
      "(212 / 10000) training: 0.4833 | validation: 0.4783\r",
      "(213 / 10000) training: 0.4833 | validation: 0.4782\r",
      "(214 / 10000) training: 0.4832 | validation: 0.4781\r",
      "(215 / 10000) training: 0.4831 | validation: 0.4781\r",
      "(216 / 10000) training: 0.4831 | validation: 0.4780\r",
      "(217 / 10000) training: 0.4830 | validation: 0.4779\r",
      "(218 / 10000) training: 0.4829 | validation: 0.4778\r",
      "(219 / 10000) training: 0.4829 | validation: 0.4778\r",
      "(220 / 10000) training: 0.4828 | validation: 0.4777\r",
      "(221 / 10000) training: 0.4827 | validation: 0.4776\r",
      "(222 / 10000) training: 0.4827 | validation: 0.4776\r",
      "(223 / 10000) training: 0.4826 | validation: 0.4775\r",
      "(224 / 10000) training: 0.4825 | validation: 0.4774\r",
      "(225 / 10000) training: 0.4824 | validation: 0.4774\r",
      "(226 / 10000) training: 0.4824 | validation: 0.4773\r",
      "(227 / 10000) training: 0.4823 | validation: 0.4772\r",
      "(228 / 10000) training: 0.4822 | validation: 0.4772\r",
      "(229 / 10000) training: 0.4822 | validation: 0.4771\r",
      "(230 / 10000) training: 0.4821 | validation: 0.4770\r",
      "(231 / 10000) training: 0.4820 | validation: 0.4770\r",
      "(232 / 10000) training: 0.4820 | validation: 0.4769\r",
      "(233 / 10000) training: 0.4819 | validation: 0.4768\r",
      "(234 / 10000) training: 0.4818 | validation: 0.4767\r",
      "(235 / 10000) training: 0.4818 | validation: 0.4767\r",
      "(236 / 10000) training: 0.4817 | validation: 0.4766\r",
      "(237 / 10000) training: 0.4816 | validation: 0.4765\r",
      "(238 / 10000) training: 0.4816 | validation: 0.4765\r",
      "(239 / 10000) training: 0.4815 | validation: 0.4764\r",
      "(240 / 10000) training: 0.4814 | validation: 0.4763\r",
      "(241 / 10000) training: 0.4814 | validation: 0.4763\r",
      "(242 / 10000) training: 0.4813 | validation: 0.4762\r",
      "(243 / 10000) training: 0.4812 | validation: 0.4761\r",
      "(244 / 10000) training: 0.4811 | validation: 0.4761\r",
      "(245 / 10000) training: 0.4811 | validation: 0.4760\r",
      "(246 / 10000) training: 0.4810 | validation: 0.4759\r",
      "(247 / 10000) training: 0.4809 | validation: 0.4759\r",
      "(248 / 10000) training: 0.4809 | validation: 0.4758\r",
      "(249 / 10000) training: 0.4808 | validation: 0.4757\r",
      "(250 / 10000) training: 0.4807 | validation: 0.4757\r",
      "(251 / 10000) training: 0.4807 | validation: 0.4756\r",
      "(252 / 10000) training: 0.4806 | validation: 0.4755\r",
      "(253 / 10000) training: 0.4805 | validation: 0.4755\r",
      "(254 / 10000) training: 0.4805 | validation: 0.4754\r",
      "(255 / 10000) training: 0.4804 | validation: 0.4753\r",
      "(256 / 10000) training: 0.4803 | validation: 0.4753\r",
      "(257 / 10000) training: 0.4803 | validation: 0.4752\r",
      "(258 / 10000) training: 0.4802 | validation: 0.4751\r",
      "(259 / 10000) training: 0.4801 | validation: 0.4751\r",
      "(260 / 10000) training: 0.4801 | validation: 0.4750\r",
      "(261 / 10000) training: 0.4800 | validation: 0.4749\r",
      "(262 / 10000) training: 0.4799 | validation: 0.4749\r",
      "(263 / 10000) training: 0.4799 | validation: 0.4748\r",
      "(264 / 10000) training: 0.4798 | validation: 0.4747\r",
      "(265 / 10000) training: 0.4797 | validation: 0.4747\r",
      "(266 / 10000) training: 0.4797 | validation: 0.4746\r",
      "(267 / 10000) training: 0.4796 | validation: 0.4745\r",
      "(268 / 10000) training: 0.4795 | validation: 0.4745\r",
      "(269 / 10000) training: 0.4795 | validation: 0.4744\r",
      "(270 / 10000) training: 0.4794 | validation: 0.4743\r",
      "(271 / 10000) training: 0.4793 | validation: 0.4743\r",
      "(272 / 10000) training: 0.4793 | validation: 0.4742\r",
      "(273 / 10000) training: 0.4792 | validation: 0.4741\r",
      "(274 / 10000) training: 0.4792 | validation: 0.4741\r",
      "(275 / 10000) training: 0.4791 | validation: 0.4740\r",
      "(276 / 10000) training: 0.4790 | validation: 0.4739\r",
      "(277 / 10000) training: 0.4790 | validation: 0.4739\r",
      "(278 / 10000) training: 0.4789 | validation: 0.4738\r",
      "(279 / 10000) training: 0.4788 | validation: 0.4737\r",
      "(280 / 10000) training: 0.4788 | validation: 0.4737\r",
      "(281 / 10000) training: 0.4787 | validation: 0.4736\r",
      "(282 / 10000) training: 0.4786 | validation: 0.4736\r",
      "(283 / 10000) training: 0.4786 | validation: 0.4735\r",
      "(284 / 10000) training: 0.4785 | validation: 0.4734\r",
      "(285 / 10000) training: 0.4784 | validation: 0.4734\r",
      "(286 / 10000) training: 0.4784 | validation: 0.4733\r",
      "(287 / 10000) training: 0.4783 | validation: 0.4732\r",
      "(288 / 10000) training: 0.4782 | validation: 0.4732\r",
      "(289 / 10000) training: 0.4782 | validation: 0.4731\r",
      "(290 / 10000) training: 0.4781 | validation: 0.4730\r",
      "(291 / 10000) training: 0.4781 | validation: 0.4730\r",
      "(292 / 10000) training: 0.4780 | validation: 0.4729\r",
      "(293 / 10000) training: 0.4779 | validation: 0.4728\r",
      "(294 / 10000) training: 0.4779 | validation: 0.4728\r",
      "(295 / 10000) training: 0.4778 | validation: 0.4727\r",
      "(296 / 10000) training: 0.4777 | validation: 0.4727\r",
      "(297 / 10000) training: 0.4777 | validation: 0.4726\r",
      "(298 / 10000) training: 0.4776 | validation: 0.4725\r",
      "(299 / 10000) training: 0.4775 | validation: 0.4725\r",
      "(300 / 10000) training: 0.4775 | validation: 0.4724\r",
      "(301 / 10000) training: 0.4774 | validation: 0.4723\r",
      "(302 / 10000) training: 0.4773 | validation: 0.4723\r",
      "(303 / 10000) training: 0.4773 | validation: 0.4722\r",
      "(304 / 10000) training: 0.4772 | validation: 0.4721\r",
      "(305 / 10000) training: 0.4772 | validation: 0.4721\r",
      "(306 / 10000) training: 0.4771 | validation: 0.4720\r",
      "(307 / 10000) training: 0.4770 | validation: 0.4720\r",
      "(308 / 10000) training: 0.4770 | validation: 0.4719\r",
      "(309 / 10000) training: 0.4769 | validation: 0.4718\r",
      "(310 / 10000) training: 0.4768 | validation: 0.4718\r",
      "(311 / 10000) training: 0.4768 | validation: 0.4717\r",
      "(312 / 10000) training: 0.4767 | validation: 0.4716\r",
      "(313 / 10000) training: 0.4767 | validation: 0.4716\r",
      "(314 / 10000) training: 0.4766 | validation: 0.4715\r",
      "(315 / 10000) training: 0.4765 | validation: 0.4715\r",
      "(316 / 10000) training: 0.4765 | validation: 0.4714\r",
      "(317 / 10000) training: 0.4764 | validation: 0.4713\r",
      "(318 / 10000) training: 0.4763 | validation: 0.4713\r",
      "(319 / 10000) training: 0.4763 | validation: 0.4712\r",
      "(320 / 10000) training: 0.4762 | validation: 0.4711\r",
      "(321 / 10000) training: 0.4762 | validation: 0.4711\r",
      "(322 / 10000) training: 0.4761 | validation: 0.4710\r",
      "(323 / 10000) training: 0.4760 | validation: 0.4710\r",
      "(324 / 10000) training: 0.4760 | validation: 0.4709\r",
      "(325 / 10000) training: 0.4759 | validation: 0.4708\r",
      "(326 / 10000) training: 0.4758 | validation: 0.4708\r",
      "(327 / 10000) training: 0.4758 | validation: 0.4707\r",
      "(328 / 10000) training: 0.4757 | validation: 0.4706\r",
      "(329 / 10000) training: 0.4757 | validation: 0.4706\r",
      "(330 / 10000) training: 0.4756 | validation: 0.4705\r",
      "(331 / 10000) training: 0.4755 | validation: 0.4705\r",
      "(332 / 10000) training: 0.4755 | validation: 0.4704\r",
      "(333 / 10000) training: 0.4754 | validation: 0.4703\r",
      "(334 / 10000) training: 0.4753 | validation: 0.4703\r",
      "(335 / 10000) training: 0.4753 | validation: 0.4702\r",
      "(336 / 10000) training: 0.4752 | validation: 0.4702\r",
      "(337 / 10000) training: 0.4752 | validation: 0.4701\r",
      "(338 / 10000) training: 0.4751 | validation: 0.4700\r",
      "(339 / 10000) training: 0.4750 | validation: 0.4700\r",
      "(340 / 10000) training: 0.4750 | validation: 0.4699\r",
      "(341 / 10000) training: 0.4749 | validation: 0.4698\r",
      "(342 / 10000) training: 0.4749 | validation: 0.4698\r",
      "(343 / 10000) training: 0.4748 | validation: 0.4697\r",
      "(344 / 10000) training: 0.4747 | validation: 0.4697\r",
      "(345 / 10000) training: 0.4747 | validation: 0.4696\r",
      "(346 / 10000) training: 0.4746 | validation: 0.4695\r",
      "(347 / 10000) training: 0.4746 | validation: 0.4695\r",
      "(348 / 10000) training: 0.4745 | validation: 0.4694\r",
      "(349 / 10000) training: 0.4744 | validation: 0.4694\r",
      "(350 / 10000) training: 0.4744 | validation: 0.4693\r",
      "(351 / 10000) training: 0.4743 | validation: 0.4692\r",
      "(352 / 10000) training: 0.4743 | validation: 0.4692\r",
      "(353 / 10000) training: 0.4742 | validation: 0.4691\r",
      "(354 / 10000) training: 0.4741 | validation: 0.4691\r",
      "(355 / 10000) training: 0.4741 | validation: 0.4690\r",
      "(356 / 10000) training: 0.4740 | validation: 0.4689\r",
      "(357 / 10000) training: 0.4740 | validation: 0.4689\r",
      "(358 / 10000) training: 0.4739 | validation: 0.4688\r",
      "(359 / 10000) training: 0.4738 | validation: 0.4688\r",
      "(360 / 10000) training: 0.4738 | validation: 0.4687\r",
      "(361 / 10000) training: 0.4737 | validation: 0.4686\r",
      "(362 / 10000) training: 0.4737 | validation: 0.4686\r",
      "(363 / 10000) training: 0.4736 | validation: 0.4685\r",
      "(364 / 10000) training: 0.4735 | validation: 0.4685\r",
      "(365 / 10000) training: 0.4735 | validation: 0.4684\r",
      "(366 / 10000) training: 0.4734 | validation: 0.4683\r",
      "(367 / 10000) training: 0.4734 | validation: 0.4683\r",
      "(368 / 10000) training: 0.4733 | validation: 0.4682\r",
      "(369 / 10000) training: 0.4732 | validation: 0.4682"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "(370 / 10000) training: 0.4732 | validation: 0.4681\r",
      "(371 / 10000) training: 0.4731 | validation: 0.4680\r",
      "(372 / 10000) training: 0.4731 | validation: 0.4680\r",
      "(373 / 10000) training: 0.4730 | validation: 0.4679\r",
      "(374 / 10000) training: 0.4729 | validation: 0.4679\r",
      "(375 / 10000) training: 0.4729 | validation: 0.4678\r",
      "(376 / 10000) training: 0.4728 | validation: 0.4678\r",
      "(377 / 10000) training: 0.4728 | validation: 0.4677\r",
      "(378 / 10000) training: 0.4727 | validation: 0.4676\r",
      "(379 / 10000) training: 0.4727 | validation: 0.4676\r",
      "(380 / 10000) training: 0.4726 | validation: 0.4675\r",
      "(381 / 10000) training: 0.4725 | validation: 0.4675\r",
      "(382 / 10000) training: 0.4725 | validation: 0.4674\r",
      "(383 / 10000) training: 0.4724 | validation: 0.4673\r",
      "(384 / 10000) training: 0.4724 | validation: 0.4673\r",
      "(385 / 10000) training: 0.4723 | validation: 0.4672\r",
      "(386 / 10000) training: 0.4722 | validation: 0.4672\r",
      "(387 / 10000) training: 0.4722 | validation: 0.4671\r",
      "(388 / 10000) training: 0.4721 | validation: 0.4671\r",
      "(389 / 10000) training: 0.4721 | validation: 0.4670\r",
      "(390 / 10000) training: 0.4720 | validation: 0.4669\r",
      "(391 / 10000) training: 0.4720 | validation: 0.4669\r",
      "(392 / 10000) training: 0.4719 | validation: 0.4668\r",
      "(393 / 10000) training: 0.4718 | validation: 0.4668\r",
      "(394 / 10000) training: 0.4718 | validation: 0.4667\r",
      "(395 / 10000) training: 0.4717 | validation: 0.4667\r",
      "(396 / 10000) training: 0.4717 | validation: 0.4666\r",
      "(397 / 10000) training: 0.4716 | validation: 0.4665\r",
      "(398 / 10000) training: 0.4716 | validation: 0.4665\r",
      "(399 / 10000) training: 0.4715 | validation: 0.4664\r",
      "(400 / 10000) training: 0.4714 | validation: 0.4664\r",
      "(401 / 10000) training: 0.4714 | validation: 0.4663\r",
      "(402 / 10000) training: 0.4713 | validation: 0.4662\r",
      "(403 / 10000) training: 0.4713 | validation: 0.4662\r",
      "(404 / 10000) training: 0.4712 | validation: 0.4661\r",
      "(405 / 10000) training: 0.4712 | validation: 0.4661\r",
      "(406 / 10000) training: 0.4711 | validation: 0.4660\r",
      "(407 / 10000) training: 0.4710 | validation: 0.4660\r",
      "(408 / 10000) training: 0.4710 | validation: 0.4659\r",
      "(409 / 10000) training: 0.4709 | validation: 0.4659\r",
      "(410 / 10000) training: 0.4709 | validation: 0.4658\r",
      "(411 / 10000) training: 0.4708 | validation: 0.4657\r",
      "(412 / 10000) training: 0.4708 | validation: 0.4657\r",
      "(413 / 10000) training: 0.4707 | validation: 0.4656\r",
      "(414 / 10000) training: 0.4706 | validation: 0.4656\r",
      "(415 / 10000) training: 0.4706 | validation: 0.4655\r",
      "(416 / 10000) training: 0.4705 | validation: 0.4655\r",
      "(417 / 10000) training: 0.4705 | validation: 0.4654\r",
      "(418 / 10000) training: 0.4704 | validation: 0.4653\r",
      "(419 / 10000) training: 0.4704 | validation: 0.4653\r",
      "(420 / 10000) training: 0.4703 | validation: 0.4652\r",
      "(421 / 10000) training: 0.4702 | validation: 0.4652\r",
      "(422 / 10000) training: 0.4702 | validation: 0.4651\r",
      "(423 / 10000) training: 0.4701 | validation: 0.4651\r",
      "(424 / 10000) training: 0.4701 | validation: 0.4650\r",
      "(425 / 10000) training: 0.4700 | validation: 0.4650\r",
      "(426 / 10000) training: 0.4700 | validation: 0.4649\r",
      "(427 / 10000) training: 0.4699 | validation: 0.4648\r",
      "(428 / 10000) training: 0.4699 | validation: 0.4648\r",
      "(429 / 10000) training: 0.4698 | validation: 0.4647\r",
      "(430 / 10000) training: 0.4697 | validation: 0.4647\r",
      "(431 / 10000) training: 0.4697 | validation: 0.4646\r",
      "(432 / 10000) training: 0.4696 | validation: 0.4646\r",
      "(433 / 10000) training: 0.4696 | validation: 0.4645\r",
      "(434 / 10000) training: 0.4695 | validation: 0.4645\r",
      "(435 / 10000) training: 0.4695 | validation: 0.4644\r",
      "(436 / 10000) training: 0.4694 | validation: 0.4643\r",
      "(437 / 10000) training: 0.4694 | validation: 0.4643\r",
      "(438 / 10000) training: 0.4693 | validation: 0.4642\r",
      "(439 / 10000) training: 0.4693 | validation: 0.4642\r",
      "(440 / 10000) training: 0.4692 | validation: 0.4641\r",
      "(441 / 10000) training: 0.4691 | validation: 0.4641\r",
      "(442 / 10000) training: 0.4691 | validation: 0.4640\r",
      "(443 / 10000) training: 0.4690 | validation: 0.4640\r",
      "(444 / 10000) training: 0.4690 | validation: 0.4639\r",
      "(445 / 10000) training: 0.4689 | validation: 0.4638\r",
      "(446 / 10000) training: 0.4689 | validation: 0.4638\r",
      "(447 / 10000) training: 0.4688 | validation: 0.4637\r",
      "(448 / 10000) training: 0.4688 | validation: 0.4637\r",
      "(449 / 10000) training: 0.4687 | validation: 0.4636\r",
      "(450 / 10000) training: 0.4687 | validation: 0.4636\r",
      "(451 / 10000) training: 0.4686 | validation: 0.4635\r",
      "(452 / 10000) training: 0.4685 | validation: 0.4635\r",
      "(453 / 10000) training: 0.4685 | validation: 0.4634\r",
      "(454 / 10000) training: 0.4684 | validation: 0.4634\r",
      "(455 / 10000) training: 0.4684 | validation: 0.4633\r",
      "(456 / 10000) training: 0.4683 | validation: 0.4633\r",
      "(457 / 10000) training: 0.4683 | validation: 0.4632\r",
      "(458 / 10000) training: 0.4682 | validation: 0.4631\r",
      "(459 / 10000) training: 0.4682 | validation: 0.4631\r",
      "(460 / 10000) training: 0.4681 | validation: 0.4630\r",
      "(461 / 10000) training: 0.4681 | validation: 0.4630\r",
      "(462 / 10000) training: 0.4680 | validation: 0.4629\r",
      "(463 / 10000) training: 0.4680 | validation: 0.4629\r",
      "(464 / 10000) training: 0.4679 | validation: 0.4628\r",
      "(465 / 10000) training: 0.4678 | validation: 0.4628\r",
      "(466 / 10000) training: 0.4678 | validation: 0.4627\r",
      "(467 / 10000) training: 0.4677 | validation: 0.4627\r",
      "(468 / 10000) training: 0.4677 | validation: 0.4626\r",
      "(469 / 10000) training: 0.4676 | validation: 0.4626\r",
      "(470 / 10000) training: 0.4676 | validation: 0.4625\r",
      "(471 / 10000) training: 0.4675 | validation: 0.4624\r",
      "(472 / 10000) training: 0.4675 | validation: 0.4624\r",
      "(473 / 10000) training: 0.4674 | validation: 0.4623\r",
      "(474 / 10000) training: 0.4674 | validation: 0.4623\r",
      "(475 / 10000) training: 0.4673 | validation: 0.4622\r",
      "(476 / 10000) training: 0.4673 | validation: 0.4622\r",
      "(477 / 10000) training: 0.4672 | validation: 0.4621\r",
      "(478 / 10000) training: 0.4672 | validation: 0.4621\r",
      "(479 / 10000) training: 0.4671 | validation: 0.4620\r",
      "(480 / 10000) training: 0.4671 | validation: 0.4620\r",
      "(481 / 10000) training: 0.4670 | validation: 0.4619\r",
      "(482 / 10000) training: 0.4669 | validation: 0.4619\r",
      "(483 / 10000) training: 0.4669 | validation: 0.4618\r",
      "(484 / 10000) training: 0.4668 | validation: 0.4618\r",
      "(485 / 10000) training: 0.4668 | validation: 0.4617\r",
      "(486 / 10000) training: 0.4667 | validation: 0.4617\r",
      "(487 / 10000) training: 0.4667 | validation: 0.4616\r",
      "(488 / 10000) training: 0.4666 | validation: 0.4616\r",
      "(489 / 10000) training: 0.4666 | validation: 0.4615\r",
      "(490 / 10000) training: 0.4665 | validation: 0.4614\r",
      "(491 / 10000) training: 0.4665 | validation: 0.4614\r",
      "(492 / 10000) training: 0.4664 | validation: 0.4613\r",
      "(493 / 10000) training: 0.4664 | validation: 0.4613\r",
      "(494 / 10000) training: 0.4663 | validation: 0.4612\r",
      "(495 / 10000) training: 0.4663 | validation: 0.4612\r",
      "(496 / 10000) training: 0.4662 | validation: 0.4611\r",
      "(497 / 10000) training: 0.4662 | validation: 0.4611\r",
      "(498 / 10000) training: 0.4661 | validation: 0.4610\r",
      "(499 / 10000) training: 0.4661 | validation: 0.4610\r",
      "(500 / 10000) training: 0.4660 | validation: 0.4609\r",
      "(501 / 10000) training: 0.4660 | validation: 0.4609\r",
      "(502 / 10000) training: 0.4659 | validation: 0.4608\r",
      "(503 / 10000) training: 0.4659 | validation: 0.4608\r",
      "(504 / 10000) training: 0.4658 | validation: 0.4607\r",
      "(505 / 10000) training: 0.4658 | validation: 0.4607\r",
      "(506 / 10000) training: 0.4657 | validation: 0.4606\r",
      "(507 / 10000) training: 0.4657 | validation: 0.4606\r",
      "(508 / 10000) training: 0.4656 | validation: 0.4605\r",
      "(509 / 10000) training: 0.4656 | validation: 0.4605\r",
      "(510 / 10000) training: 0.4655 | validation: 0.4604\r",
      "(511 / 10000) training: 0.4654 | validation: 0.4604\r",
      "(512 / 10000) training: 0.4654 | validation: 0.4603\r",
      "(513 / 10000) training: 0.4653 | validation: 0.4603\r",
      "(514 / 10000) training: 0.4653 | validation: 0.4602\r",
      "(515 / 10000) training: 0.4652 | validation: 0.4602\r",
      "(516 / 10000) training: 0.4652 | validation: 0.4601\r",
      "(517 / 10000) training: 0.4651 | validation: 0.4601\r",
      "(518 / 10000) training: 0.4651 | validation: 0.4600\r",
      "(519 / 10000) training: 0.4650 | validation: 0.4600\r",
      "(520 / 10000) training: 0.4650 | validation: 0.4599\r",
      "(521 / 10000) training: 0.4649 | validation: 0.4599\r",
      "(522 / 10000) training: 0.4649 | validation: 0.4598\r",
      "(523 / 10000) training: 0.4648 | validation: 0.4598\r",
      "(524 / 10000) training: 0.4648 | validation: 0.4597\r",
      "(525 / 10000) training: 0.4647 | validation: 0.4597\r",
      "(526 / 10000) training: 0.4647 | validation: 0.4596\r",
      "(527 / 10000) training: 0.4646 | validation: 0.4596\r",
      "(528 / 10000) training: 0.4646 | validation: 0.4595\r",
      "(529 / 10000) training: 0.4645 | validation: 0.4595\r",
      "(530 / 10000) training: 0.4645 | validation: 0.4594\r",
      "(531 / 10000) training: 0.4644 | validation: 0.4594\r",
      "(532 / 10000) training: 0.4644 | validation: 0.4593\r",
      "(533 / 10000) training: 0.4643 | validation: 0.4593\r",
      "(534 / 10000) training: 0.4643 | validation: 0.4592\r",
      "(535 / 10000) training: 0.4642 | validation: 0.4592\r",
      "(536 / 10000) training: 0.4642 | validation: 0.4591\r",
      "(537 / 10000) training: 0.4641 | validation: 0.4591\r",
      "(538 / 10000) training: 0.4641 | validation: 0.4590\r",
      "(539 / 10000) training: 0.4640 | validation: 0.4590\r",
      "(540 / 10000) training: 0.4640 | validation: 0.4589\r",
      "(541 / 10000) training: 0.4639 | validation: 0.4589\r",
      "(542 / 10000) training: 0.4639 | validation: 0.4588\r",
      "(543 / 10000) training: 0.4638 | validation: 0.4588\r",
      "(544 / 10000) training: 0.4638 | validation: 0.4587\r",
      "(545 / 10000) training: 0.4638 | validation: 0.4587\r",
      "(546 / 10000) training: 0.4637 | validation: 0.4586\r",
      "(547 / 10000) training: 0.4637 | validation: 0.4586\r",
      "(548 / 10000) training: 0.4636 | validation: 0.4585\r",
      "(549 / 10000) training: 0.4636 | validation: 0.4585\r",
      "(550 / 10000) training: 0.4635 | validation: 0.4584\r",
      "(551 / 10000) training: 0.4635 | validation: 0.4584\r",
      "(552 / 10000) training: 0.4634 | validation: 0.4583\r",
      "(553 / 10000) training: 0.4634 | validation: 0.4583\r",
      "(554 / 10000) training: 0.4633 | validation: 0.4582\r",
      "(555 / 10000) training: 0.4633 | validation: 0.4582\r",
      "(556 / 10000) training: 0.4632 | validation: 0.4581\r",
      "(557 / 10000) training: 0.4632 | validation: 0.4581\r",
      "(558 / 10000) training: 0.4631 | validation: 0.4580\r",
      "(559 / 10000) training: 0.4631 | validation: 0.4580\r",
      "(560 / 10000) training: 0.4630 | validation: 0.4579\r",
      "(561 / 10000) training: 0.4630 | validation: 0.4579\r",
      "(562 / 10000) training: 0.4629 | validation: 0.4578\r",
      "(563 / 10000) training: 0.4629 | validation: 0.4578\r",
      "(564 / 10000) training: 0.4628 | validation: 0.4577\r",
      "(565 / 10000) training: 0.4628 | validation: 0.4577\r",
      "(566 / 10000) training: 0.4627 | validation: 0.4576"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "(567 / 10000) training: 0.4627 | validation: 0.4576\r",
      "(568 / 10000) training: 0.4626 | validation: 0.4576\r",
      "(569 / 10000) training: 0.4626 | validation: 0.4575\r",
      "(570 / 10000) training: 0.4625 | validation: 0.4575\r",
      "(571 / 10000) training: 0.4625 | validation: 0.4574\r",
      "(572 / 10000) training: 0.4624 | validation: 0.4574\r",
      "(573 / 10000) training: 0.4624 | validation: 0.4573\r",
      "(574 / 10000) training: 0.4624 | validation: 0.4573\r",
      "(575 / 10000) training: 0.4623 | validation: 0.4572\r",
      "(576 / 10000) training: 0.4623 | validation: 0.4572\r",
      "(577 / 10000) training: 0.4622 | validation: 0.4571\r",
      "(578 / 10000) training: 0.4622 | validation: 0.4571\r",
      "(579 / 10000) training: 0.4621 | validation: 0.4570\r",
      "(580 / 10000) training: 0.4621 | validation: 0.4570\r",
      "(581 / 10000) training: 0.4620 | validation: 0.4569\r",
      "(582 / 10000) training: 0.4620 | validation: 0.4569\r",
      "(583 / 10000) training: 0.4619 | validation: 0.4568\r",
      "(584 / 10000) training: 0.4619 | validation: 0.4568\r",
      "(585 / 10000) training: 0.4618 | validation: 0.4567\r",
      "(586 / 10000) training: 0.4618 | validation: 0.4567\r",
      "(587 / 10000) training: 0.4617 | validation: 0.4567\r",
      "(588 / 10000) training: 0.4617 | validation: 0.4566\r",
      "(589 / 10000) training: 0.4616 | validation: 0.4566\r",
      "(590 / 10000) training: 0.4616 | validation: 0.4565\r",
      "(591 / 10000) training: 0.4616 | validation: 0.4565\r",
      "(592 / 10000) training: 0.4615 | validation: 0.4564\r",
      "(593 / 10000) training: 0.4615 | validation: 0.4564\r",
      "(594 / 10000) training: 0.4614 | validation: 0.4563\r",
      "(595 / 10000) training: 0.4614 | validation: 0.4563\r",
      "(596 / 10000) training: 0.4613 | validation: 0.4562\r",
      "(597 / 10000) training: 0.4613 | validation: 0.4562\r",
      "(598 / 10000) training: 0.4612 | validation: 0.4561\r",
      "(599 / 10000) training: 0.4612 | validation: 0.4561\r",
      "(600 / 10000) training: 0.4611 | validation: 0.4560\r",
      "(601 / 10000) training: 0.4611 | validation: 0.4560\r",
      "(602 / 10000) training: 0.4610 | validation: 0.4560\r",
      "(603 / 10000) training: 0.4610 | validation: 0.4559\r",
      "(604 / 10000) training: 0.4609 | validation: 0.4559\r",
      "(605 / 10000) training: 0.4609 | validation: 0.4558\r",
      "(606 / 10000) training: 0.4609 | validation: 0.4558\r",
      "(607 / 10000) training: 0.4608 | validation: 0.4557\r",
      "(608 / 10000) training: 0.4608 | validation: 0.4557\r",
      "(609 / 10000) training: 0.4607 | validation: 0.4556\r",
      "(610 / 10000) training: 0.4607 | validation: 0.4556\r",
      "(611 / 10000) training: 0.4606 | validation: 0.4555\r",
      "(612 / 10000) training: 0.4606 | validation: 0.4555\r",
      "(613 / 10000) training: 0.4605 | validation: 0.4554\r",
      "(614 / 10000) training: 0.4605 | validation: 0.4554\r",
      "(615 / 10000) training: 0.4604 | validation: 0.4554\r",
      "(616 / 10000) training: 0.4604 | validation: 0.4553\r",
      "(617 / 10000) training: 0.4604 | validation: 0.4553\r",
      "(618 / 10000) training: 0.4603 | validation: 0.4552\r",
      "(619 / 10000) training: 0.4603 | validation: 0.4552\r",
      "(620 / 10000) training: 0.4602 | validation: 0.4551\r",
      "(621 / 10000) training: 0.4602 | validation: 0.4551\r",
      "(622 / 10000) training: 0.4601 | validation: 0.4550\r",
      "(623 / 10000) training: 0.4601 | validation: 0.4550\r",
      "(624 / 10000) training: 0.4600 | validation: 0.4549\r",
      "(625 / 10000) training: 0.4600 | validation: 0.4549\r",
      "(626 / 10000) training: 0.4599 | validation: 0.4549\r",
      "(627 / 10000) training: 0.4599 | validation: 0.4548\r",
      "(628 / 10000) training: 0.4599 | validation: 0.4548\r",
      "(629 / 10000) training: 0.4598 | validation: 0.4547\r",
      "(630 / 10000) training: 0.4598 | validation: 0.4547\r",
      "(631 / 10000) training: 0.4597 | validation: 0.4546\r",
      "(632 / 10000) training: 0.4597 | validation: 0.4546\r",
      "(633 / 10000) training: 0.4596 | validation: 0.4545\r",
      "(634 / 10000) training: 0.4596 | validation: 0.4545\r",
      "(635 / 10000) training: 0.4595 | validation: 0.4544\r",
      "(636 / 10000) training: 0.4595 | validation: 0.4544\r",
      "(637 / 10000) training: 0.4595 | validation: 0.4544\r",
      "(638 / 10000) training: 0.4594 | validation: 0.4543\r",
      "(639 / 10000) training: 0.4594 | validation: 0.4543\r",
      "(640 / 10000) training: 0.4593 | validation: 0.4542\r",
      "(641 / 10000) training: 0.4593 | validation: 0.4542\r",
      "(642 / 10000) training: 0.4592 | validation: 0.4541\r",
      "(643 / 10000) training: 0.4592 | validation: 0.4541\r",
      "(644 / 10000) training: 0.4591 | validation: 0.4540\r",
      "(645 / 10000) training: 0.4591 | validation: 0.4540\r",
      "(646 / 10000) training: 0.4591 | validation: 0.4540\r",
      "(647 / 10000) training: 0.4590 | validation: 0.4539\r",
      "(648 / 10000) training: 0.4590 | validation: 0.4539\r",
      "(649 / 10000) training: 0.4589 | validation: 0.4538\r",
      "(650 / 10000) training: 0.4589 | validation: 0.4538\r",
      "(651 / 10000) training: 0.4588 | validation: 0.4537\r",
      "(652 / 10000) training: 0.4588 | validation: 0.4537\r",
      "(653 / 10000) training: 0.4587 | validation: 0.4537\r",
      "(654 / 10000) training: 0.4587 | validation: 0.4536\r",
      "(655 / 10000) training: 0.4587 | validation: 0.4536\r",
      "(656 / 10000) training: 0.4586 | validation: 0.4535\r",
      "(657 / 10000) training: 0.4586 | validation: 0.4535\r",
      "(658 / 10000) training: 0.4585 | validation: 0.4534\r",
      "(659 / 10000) training: 0.4585 | validation: 0.4534\r",
      "(660 / 10000) training: 0.4584 | validation: 0.4533\r",
      "(661 / 10000) training: 0.4584 | validation: 0.4533\r",
      "(662 / 10000) training: 0.4584 | validation: 0.4533\r",
      "(663 / 10000) training: 0.4583 | validation: 0.4532\r",
      "(664 / 10000) training: 0.4583 | validation: 0.4532\r",
      "(665 / 10000) training: 0.4582 | validation: 0.4531\r",
      "(666 / 10000) training: 0.4582 | validation: 0.4531\r",
      "(667 / 10000) training: 0.4581 | validation: 0.4530\r",
      "(668 / 10000) training: 0.4581 | validation: 0.4530\r",
      "(669 / 10000) training: 0.4581 | validation: 0.4530\r",
      "(670 / 10000) training: 0.4580 | validation: 0.4529\r",
      "(671 / 10000) training: 0.4580 | validation: 0.4529\r",
      "(672 / 10000) training: 0.4579 | validation: 0.4528\r",
      "(673 / 10000) training: 0.4579 | validation: 0.4528\r",
      "(674 / 10000) training: 0.4578 | validation: 0.4527\r",
      "(675 / 10000) training: 0.4578 | validation: 0.4527\r",
      "(676 / 10000) training: 0.4578 | validation: 0.4527\r",
      "(677 / 10000) training: 0.4577 | validation: 0.4526\r",
      "(678 / 10000) training: 0.4577 | validation: 0.4526\r",
      "(679 / 10000) training: 0.4576 | validation: 0.4525\r",
      "(680 / 10000) training: 0.4576 | validation: 0.4525\r",
      "(681 / 10000) training: 0.4575 | validation: 0.4524\r",
      "(682 / 10000) training: 0.4575 | validation: 0.4524\r",
      "(683 / 10000) training: 0.4575 | validation: 0.4524\r",
      "(684 / 10000) training: 0.4574 | validation: 0.4523\r",
      "(685 / 10000) training: 0.4574 | validation: 0.4523\r",
      "(686 / 10000) training: 0.4573 | validation: 0.4522\r",
      "(687 / 10000) training: 0.4573 | validation: 0.4522\r",
      "(688 / 10000) training: 0.4572 | validation: 0.4521\r",
      "(689 / 10000) training: 0.4572 | validation: 0.4521\r",
      "(690 / 10000) training: 0.4572 | validation: 0.4521\r",
      "(691 / 10000) training: 0.4571 | validation: 0.4520\r",
      "(692 / 10000) training: 0.4571 | validation: 0.4520\r",
      "(693 / 10000) training: 0.4570 | validation: 0.4519\r",
      "(694 / 10000) training: 0.4570 | validation: 0.4519\r",
      "(695 / 10000) training: 0.4570 | validation: 0.4519\r",
      "(696 / 10000) training: 0.4569 | validation: 0.4518\r",
      "(697 / 10000) training: 0.4569 | validation: 0.4518\r",
      "(698 / 10000) training: 0.4568 | validation: 0.4517\r",
      "(699 / 10000) training: 0.4568 | validation: 0.4517\r",
      "(700 / 10000) training: 0.4567 | validation: 0.4516\r",
      "(701 / 10000) training: 0.4567 | validation: 0.4516\r",
      "(702 / 10000) training: 0.4567 | validation: 0.4516\r",
      "(703 / 10000) training: 0.4566 | validation: 0.4515\r",
      "(704 / 10000) training: 0.4566 | validation: 0.4515\r",
      "(705 / 10000) training: 0.4565 | validation: 0.4514\r",
      "(706 / 10000) training: 0.4565 | validation: 0.4514\r",
      "(707 / 10000) training: 0.4565 | validation: 0.4514\r",
      "(708 / 10000) training: 0.4564 | validation: 0.4513\r",
      "(709 / 10000) training: 0.4564 | validation: 0.4513\r",
      "(710 / 10000) training: 0.4563 | validation: 0.4512\r",
      "(711 / 10000) training: 0.4563 | validation: 0.4512\r",
      "(712 / 10000) training: 0.4562 | validation: 0.4511\r",
      "(713 / 10000) training: 0.4562 | validation: 0.4511\r",
      "(714 / 10000) training: 0.4562 | validation: 0.4511\r",
      "(715 / 10000) training: 0.4561 | validation: 0.4510\r",
      "(716 / 10000) training: 0.4561 | validation: 0.4510\r",
      "(717 / 10000) training: 0.4560 | validation: 0.4509\r",
      "(718 / 10000) training: 0.4560 | validation: 0.4509\r",
      "(719 / 10000) training: 0.4560 | validation: 0.4509\r",
      "(720 / 10000) training: 0.4559 | validation: 0.4508\r",
      "(721 / 10000) training: 0.4559 | validation: 0.4508\r",
      "(722 / 10000) training: 0.4558 | validation: 0.4507\r",
      "(723 / 10000) training: 0.4558 | validation: 0.4507\r",
      "(724 / 10000) training: 0.4558 | validation: 0.4507\r",
      "(725 / 10000) training: 0.4557 | validation: 0.4506\r",
      "(726 / 10000) training: 0.4557 | validation: 0.4506\r",
      "(727 / 10000) training: 0.4556 | validation: 0.4505\r",
      "(728 / 10000) training: 0.4556 | validation: 0.4505\r",
      "(729 / 10000) training: 0.4556 | validation: 0.4504\r",
      "(730 / 10000) training: 0.4555 | validation: 0.4504\r",
      "(731 / 10000) training: 0.4555 | validation: 0.4504\r",
      "(732 / 10000) training: 0.4554 | validation: 0.4503\r",
      "(733 / 10000) training: 0.4554 | validation: 0.4503\r",
      "(734 / 10000) training: 0.4554 | validation: 0.4502\r",
      "(735 / 10000) training: 0.4553 | validation: 0.4502\r",
      "(736 / 10000) training: 0.4553 | validation: 0.4502\r",
      "(737 / 10000) training: 0.4552 | validation: 0.4501\r",
      "(738 / 10000) training: 0.4552 | validation: 0.4501\r",
      "(739 / 10000) training: 0.4552 | validation: 0.4500\r",
      "(740 / 10000) training: 0.4551 | validation: 0.4500\r",
      "(741 / 10000) training: 0.4551 | validation: 0.4500\r",
      "(742 / 10000) training: 0.4550 | validation: 0.4499\r",
      "(743 / 10000) training: 0.4550 | validation: 0.4499\r",
      "(744 / 10000) training: 0.4550 | validation: 0.4498\r",
      "(745 / 10000) training: 0.4549 | validation: 0.4498\r",
      "(746 / 10000) training: 0.4549 | validation: 0.4498\r",
      "(747 / 10000) training: 0.4548 | validation: 0.4497\r",
      "(748 / 10000) training: 0.4548 | validation: 0.4497\r",
      "(749 / 10000) training: 0.4548 | validation: 0.4496\r",
      "(750 / 10000) training: 0.4547 | validation: 0.4496\r",
      "(751 / 10000) training: 0.4547 | validation: 0.4496\r",
      "(752 / 10000) training: 0.4546 | validation: 0.4495\r",
      "(753 / 10000) training: 0.4546 | validation: 0.4495\r",
      "(754 / 10000) training: 0.4546 | validation: 0.4494\r",
      "(755 / 10000) training: 0.4545 | validation: 0.4494\r",
      "(756 / 10000) training: 0.4545 | validation: 0.4494\r",
      "(757 / 10000) training: 0.4544 | validation: 0.4493\r",
      "(758 / 10000) training: 0.4544 | validation: 0.4493\r",
      "(759 / 10000) training: 0.4544 | validation: 0.4493\r",
      "(760 / 10000) training: 0.4543 | validation: 0.4492\r",
      "(761 / 10000) training: 0.4543 | validation: 0.4492\r",
      "(762 / 10000) training: 0.4543 | validation: 0.4491\r",
      "(763 / 10000) training: 0.4542 | validation: 0.4491"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "(764 / 10000) training: 0.4542 | validation: 0.4491\r",
      "(765 / 10000) training: 0.4541 | validation: 0.4490\r",
      "(766 / 10000) training: 0.4541 | validation: 0.4490\r",
      "(767 / 10000) training: 0.4541 | validation: 0.4489\r",
      "(768 / 10000) training: 0.4540 | validation: 0.4489\r",
      "(769 / 10000) training: 0.4540 | validation: 0.4489\r",
      "(770 / 10000) training: 0.4539 | validation: 0.4488\r",
      "(771 / 10000) training: 0.4539 | validation: 0.4488\r",
      "(772 / 10000) training: 0.4539 | validation: 0.4487\r",
      "(773 / 10000) training: 0.4538 | validation: 0.4487\r",
      "(774 / 10000) training: 0.4538 | validation: 0.4487\r",
      "(775 / 10000) training: 0.4537 | validation: 0.4486\r",
      "(776 / 10000) training: 0.4537 | validation: 0.4486\r",
      "(777 / 10000) training: 0.4537 | validation: 0.4486\r",
      "(778 / 10000) training: 0.4536 | validation: 0.4485\r",
      "(779 / 10000) training: 0.4536 | validation: 0.4485\r",
      "(780 / 10000) training: 0.4536 | validation: 0.4484\r",
      "(781 / 10000) training: 0.4535 | validation: 0.4484\r",
      "(782 / 10000) training: 0.4535 | validation: 0.4484\r",
      "(783 / 10000) training: 0.4534 | validation: 0.4483\r",
      "(784 / 10000) training: 0.4534 | validation: 0.4483\r",
      "(785 / 10000) training: 0.4534 | validation: 0.4482\r",
      "(786 / 10000) training: 0.4533 | validation: 0.4482\r",
      "(787 / 10000) training: 0.4533 | validation: 0.4482\r",
      "(788 / 10000) training: 0.4533 | validation: 0.4481\r",
      "(789 / 10000) training: 0.4532 | validation: 0.4481\r",
      "(790 / 10000) training: 0.4532 | validation: 0.4481\r",
      "(791 / 10000) training: 0.4531 | validation: 0.4480\r",
      "(792 / 10000) training: 0.4531 | validation: 0.4480\r",
      "(793 / 10000) training: 0.4531 | validation: 0.4479\r",
      "(794 / 10000) training: 0.4530 | validation: 0.4479\r",
      "(795 / 10000) training: 0.4530 | validation: 0.4479\r",
      "(796 / 10000) training: 0.4530 | validation: 0.4478\r",
      "(797 / 10000) training: 0.4529 | validation: 0.4478\r",
      "(798 / 10000) training: 0.4529 | validation: 0.4478\r",
      "(799 / 10000) training: 0.4528 | validation: 0.4477\r",
      "(800 / 10000) training: 0.4528 | validation: 0.4477\r",
      "(801 / 10000) training: 0.4528 | validation: 0.4476\r",
      "(802 / 10000) training: 0.4527 | validation: 0.4476\r",
      "(803 / 10000) training: 0.4527 | validation: 0.4476\r",
      "(804 / 10000) training: 0.4527 | validation: 0.4475\r",
      "(805 / 10000) training: 0.4526 | validation: 0.4475\r",
      "(806 / 10000) training: 0.4526 | validation: 0.4475\r",
      "(807 / 10000) training: 0.4525 | validation: 0.4474\r",
      "(808 / 10000) training: 0.4525 | validation: 0.4474\r",
      "(809 / 10000) training: 0.4525 | validation: 0.4473\r",
      "(810 / 10000) training: 0.4524 | validation: 0.4473\r",
      "(811 / 10000) training: 0.4524 | validation: 0.4473\r",
      "(812 / 10000) training: 0.4524 | validation: 0.4472\r",
      "(813 / 10000) training: 0.4523 | validation: 0.4472\r",
      "(814 / 10000) training: 0.4523 | validation: 0.4472\r",
      "(815 / 10000) training: 0.4522 | validation: 0.4471\r",
      "(816 / 10000) training: 0.4522 | validation: 0.4471\r",
      "(817 / 10000) training: 0.4522 | validation: 0.4470\r",
      "(818 / 10000) training: 0.4521 | validation: 0.4470\r",
      "(819 / 10000) training: 0.4521 | validation: 0.4470\r",
      "(820 / 10000) training: 0.4521 | validation: 0.4469\r",
      "(821 / 10000) training: 0.4520 | validation: 0.4469\r",
      "(822 / 10000) training: 0.4520 | validation: 0.4469\r",
      "(823 / 10000) training: 0.4520 | validation: 0.4468\r",
      "(824 / 10000) training: 0.4519 | validation: 0.4468\r",
      "(825 / 10000) training: 0.4519 | validation: 0.4467\r",
      "(826 / 10000) training: 0.4518 | validation: 0.4467\r",
      "(827 / 10000) training: 0.4518 | validation: 0.4467\r",
      "(828 / 10000) training: 0.4518 | validation: 0.4466\r",
      "(829 / 10000) training: 0.4517 | validation: 0.4466\r",
      "(830 / 10000) training: 0.4517 | validation: 0.4466\r",
      "(831 / 10000) training: 0.4517 | validation: 0.4465\r",
      "(832 / 10000) training: 0.4516 | validation: 0.4465\r",
      "(833 / 10000) training: 0.4516 | validation: 0.4465\r",
      "(834 / 10000) training: 0.4516 | validation: 0.4464\r",
      "(835 / 10000) training: 0.4515 | validation: 0.4464\r",
      "(836 / 10000) training: 0.4515 | validation: 0.4463\r",
      "(837 / 10000) training: 0.4514 | validation: 0.4463\r",
      "(838 / 10000) training: 0.4514 | validation: 0.4463\r",
      "(839 / 10000) training: 0.4514 | validation: 0.4462\r",
      "(840 / 10000) training: 0.4513 | validation: 0.4462\r",
      "(841 / 10000) training: 0.4513 | validation: 0.4462\r",
      "(842 / 10000) training: 0.4513 | validation: 0.4461\r",
      "(843 / 10000) training: 0.4512 | validation: 0.4461\r",
      "(844 / 10000) training: 0.4512 | validation: 0.4461\r",
      "(845 / 10000) training: 0.4512 | validation: 0.4460\r",
      "(846 / 10000) training: 0.4511 | validation: 0.4460\r",
      "(847 / 10000) training: 0.4511 | validation: 0.4460\r",
      "(848 / 10000) training: 0.4511 | validation: 0.4459\r",
      "(849 / 10000) training: 0.4510 | validation: 0.4459\r",
      "(850 / 10000) training: 0.4510 | validation: 0.4458\r",
      "(851 / 10000) training: 0.4509 | validation: 0.4458\r",
      "(852 / 10000) training: 0.4509 | validation: 0.4458\r",
      "(853 / 10000) training: 0.4509 | validation: 0.4457\r",
      "(854 / 10000) training: 0.4508 | validation: 0.4457\r",
      "(855 / 10000) training: 0.4508 | validation: 0.4457\r",
      "(856 / 10000) training: 0.4508 | validation: 0.4456\r",
      "(857 / 10000) training: 0.4507 | validation: 0.4456\r",
      "(858 / 10000) training: 0.4507 | validation: 0.4456\r",
      "(859 / 10000) training: 0.4507 | validation: 0.4455\r",
      "(860 / 10000) training: 0.4506 | validation: 0.4455\r",
      "(861 / 10000) training: 0.4506 | validation: 0.4455\r",
      "(862 / 10000) training: 0.4506 | validation: 0.4454\r",
      "(863 / 10000) training: 0.4505 | validation: 0.4454\r",
      "(864 / 10000) training: 0.4505 | validation: 0.4453\r",
      "(865 / 10000) training: 0.4505 | validation: 0.4453\r",
      "(866 / 10000) training: 0.4504 | validation: 0.4453\r",
      "(867 / 10000) training: 0.4504 | validation: 0.4452\r",
      "(868 / 10000) training: 0.4503 | validation: 0.4452\r",
      "(869 / 10000) training: 0.4503 | validation: 0.4452\r",
      "(870 / 10000) training: 0.4503 | validation: 0.4451\r",
      "(871 / 10000) training: 0.4502 | validation: 0.4451\r",
      "(872 / 10000) training: 0.4502 | validation: 0.4451\r",
      "(873 / 10000) training: 0.4502 | validation: 0.4450\r",
      "(874 / 10000) training: 0.4501 | validation: 0.4450\r",
      "(875 / 10000) training: 0.4501 | validation: 0.4450\r",
      "(876 / 10000) training: 0.4501 | validation: 0.4449\r",
      "(877 / 10000) training: 0.4500 | validation: 0.4449\r",
      "(878 / 10000) training: 0.4500 | validation: 0.4449\r",
      "(879 / 10000) training: 0.4500 | validation: 0.4448\r",
      "(880 / 10000) training: 0.4499 | validation: 0.4448\r",
      "(881 / 10000) training: 0.4499 | validation: 0.4448\r",
      "(882 / 10000) training: 0.4499 | validation: 0.4447\r",
      "(883 / 10000) training: 0.4498 | validation: 0.4447\r",
      "(884 / 10000) training: 0.4498 | validation: 0.4447\r",
      "(885 / 10000) training: 0.4498 | validation: 0.4446\r",
      "(886 / 10000) training: 0.4497 | validation: 0.4446\r",
      "(887 / 10000) training: 0.4497 | validation: 0.4445\r",
      "(888 / 10000) training: 0.4497 | validation: 0.4445\r",
      "(889 / 10000) training: 0.4496 | validation: 0.4445\r",
      "(890 / 10000) training: 0.4496 | validation: 0.4444\r",
      "(891 / 10000) training: 0.4496 | validation: 0.4444\r",
      "(892 / 10000) training: 0.4495 | validation: 0.4444\r",
      "(893 / 10000) training: 0.4495 | validation: 0.4443\r",
      "(894 / 10000) training: 0.4495 | validation: 0.4443\r",
      "(895 / 10000) training: 0.4494 | validation: 0.4443\r",
      "(896 / 10000) training: 0.4494 | validation: 0.4442\r",
      "(897 / 10000) training: 0.4494 | validation: 0.4442\r",
      "(898 / 10000) training: 0.4493 | validation: 0.4442\r",
      "(899 / 10000) training: 0.4493 | validation: 0.4441\r",
      "(900 / 10000) training: 0.4493 | validation: 0.4441\r",
      "(901 / 10000) training: 0.4492 | validation: 0.4441\r",
      "(902 / 10000) training: 0.4492 | validation: 0.4440\r",
      "(903 / 10000) training: 0.4492 | validation: 0.4440\r",
      "(904 / 10000) training: 0.4491 | validation: 0.4440\r",
      "(905 / 10000) training: 0.4491 | validation: 0.4439\r",
      "(906 / 10000) training: 0.4491 | validation: 0.4439\r",
      "(907 / 10000) training: 0.4490 | validation: 0.4439\r",
      "(908 / 10000) training: 0.4490 | validation: 0.4438\r",
      "(909 / 10000) training: 0.4490 | validation: 0.4438\r",
      "(910 / 10000) training: 0.4489 | validation: 0.4438\r",
      "(911 / 10000) training: 0.4489 | validation: 0.4437\r",
      "(912 / 10000) training: 0.4489 | validation: 0.4437\r",
      "(913 / 10000) training: 0.4488 | validation: 0.4437\r",
      "(914 / 10000) training: 0.4488 | validation: 0.4436\r",
      "(915 / 10000) training: 0.4488 | validation: 0.4436\r",
      "(916 / 10000) training: 0.4487 | validation: 0.4436\r",
      "(917 / 10000) training: 0.4487 | validation: 0.4435\r",
      "(918 / 10000) training: 0.4487 | validation: 0.4435\r",
      "(919 / 10000) training: 0.4486 | validation: 0.4435\r",
      "(920 / 10000) training: 0.4486 | validation: 0.4434\r",
      "(921 / 10000) training: 0.4486 | validation: 0.4434\r",
      "(922 / 10000) training: 0.4485 | validation: 0.4434\r",
      "(923 / 10000) training: 0.4485 | validation: 0.4433\r",
      "(924 / 10000) training: 0.4485 | validation: 0.4433\r",
      "(925 / 10000) training: 0.4484 | validation: 0.4433\r",
      "(926 / 10000) training: 0.4484 | validation: 0.4432\r",
      "(927 / 10000) training: 0.4484 | validation: 0.4432\r",
      "(928 / 10000) training: 0.4483 | validation: 0.4432\r",
      "(929 / 10000) training: 0.4483 | validation: 0.4431\r",
      "(930 / 10000) training: 0.4483 | validation: 0.4431\r",
      "(931 / 10000) training: 0.4482 | validation: 0.4431\r",
      "(932 / 10000) training: 0.4482 | validation: 0.4430\r",
      "(933 / 10000) training: 0.4482 | validation: 0.4430\r",
      "(934 / 10000) training: 0.4481 | validation: 0.4430\r",
      "(935 / 10000) training: 0.4481 | validation: 0.4429\r",
      "(936 / 10000) training: 0.4481 | validation: 0.4429\r",
      "(937 / 10000) training: 0.4480 | validation: 0.4429\r",
      "(938 / 10000) training: 0.4480 | validation: 0.4428\r",
      "(939 / 10000) training: 0.4480 | validation: 0.4428\r",
      "(940 / 10000) training: 0.4479 | validation: 0.4428\r",
      "(941 / 10000) training: 0.4479 | validation: 0.4427\r",
      "(942 / 10000) training: 0.4479 | validation: 0.4427\r",
      "(943 / 10000) training: 0.4478 | validation: 0.4427\r",
      "(944 / 10000) training: 0.4478 | validation: 0.4426\r",
      "(945 / 10000) training: 0.4478 | validation: 0.4426\r",
      "(946 / 10000) training: 0.4477 | validation: 0.4426\r",
      "(947 / 10000) training: 0.4477 | validation: 0.4426\r",
      "(948 / 10000) training: 0.4477 | validation: 0.4425\r",
      "(949 / 10000) training: 0.4476 | validation: 0.4425\r",
      "(950 / 10000) training: 0.4476 | validation: 0.4425\r",
      "(951 / 10000) training: 0.4476 | validation: 0.4424\r",
      "(952 / 10000) training: 0.4475 | validation: 0.4424\r",
      "(953 / 10000) training: 0.4475 | validation: 0.4424\r",
      "(954 / 10000) training: 0.4475 | validation: 0.4423\r",
      "(955 / 10000) training: 0.4475 | validation: 0.4423\r",
      "(956 / 10000) training: 0.4474 | validation: 0.4423\r",
      "(957 / 10000) training: 0.4474 | validation: 0.4422\r",
      "(958 / 10000) training: 0.4474 | validation: 0.4422\r",
      "(959 / 10000) training: 0.4473 | validation: 0.4422\r",
      "(960 / 10000) training: 0.4473 | validation: 0.4421\r",
      "(961 / 10000) training: 0.4473 | validation: 0.4421\r",
      "(962 / 10000) training: 0.4472 | validation: 0.4421"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "(963 / 10000) training: 0.4472 | validation: 0.4420\r",
      "(964 / 10000) training: 0.4472 | validation: 0.4420\r",
      "(965 / 10000) training: 0.4471 | validation: 0.4420\r",
      "(966 / 10000) training: 0.4471 | validation: 0.4419\r",
      "(967 / 10000) training: 0.4471 | validation: 0.4419\r",
      "(968 / 10000) training: 0.4470 | validation: 0.4419\r",
      "(969 / 10000) training: 0.4470 | validation: 0.4419\r",
      "(970 / 10000) training: 0.4470 | validation: 0.4418\r",
      "(971 / 10000) training: 0.4470 | validation: 0.4418\r",
      "(972 / 10000) training: 0.4469 | validation: 0.4418\r",
      "(973 / 10000) training: 0.4469 | validation: 0.4417\r",
      "(974 / 10000) training: 0.4469 | validation: 0.4417\r",
      "(975 / 10000) training: 0.4468 | validation: 0.4417\r",
      "(976 / 10000) training: 0.4468 | validation: 0.4416\r",
      "(977 / 10000) training: 0.4468 | validation: 0.4416\r",
      "(978 / 10000) training: 0.4467 | validation: 0.4416\r",
      "(979 / 10000) training: 0.4467 | validation: 0.4415\r",
      "(980 / 10000) training: 0.4467 | validation: 0.4415\r",
      "(981 / 10000) training: 0.4466 | validation: 0.4415\r",
      "(982 / 10000) training: 0.4466 | validation: 0.4414\r",
      "(983 / 10000) training: 0.4466 | validation: 0.4414\r",
      "(984 / 10000) training: 0.4465 | validation: 0.4414\r",
      "(985 / 10000) training: 0.4465 | validation: 0.4414\r",
      "(986 / 10000) training: 0.4465 | validation: 0.4413\r",
      "(987 / 10000) training: 0.4465 | validation: 0.4413\r",
      "(988 / 10000) training: 0.4464 | validation: 0.4413\r",
      "(989 / 10000) training: 0.4464 | validation: 0.4412\r",
      "(990 / 10000) training: 0.4464 | validation: 0.4412\r",
      "(991 / 10000) training: 0.4463 | validation: 0.4412\r",
      "(992 / 10000) training: 0.4463 | validation: 0.4411\r",
      "(993 / 10000) training: 0.4463 | validation: 0.4411\r",
      "(994 / 10000) training: 0.4462 | validation: 0.4411\r",
      "(995 / 10000) training: 0.4462 | validation: 0.4410\r",
      "(996 / 10000) training: 0.4462 | validation: 0.4410\r",
      "(997 / 10000) training: 0.4461 | validation: 0.4410\r",
      "(998 / 10000) training: 0.4461 | validation: 0.4410\r",
      "(999 / 10000) training: 0.4461 | validation: 0.4409\r",
      "(1000 / 10000) training: 0.4461 | validation: 0.4409\r",
      "(1001 / 10000) training: 0.4460 | validation: 0.4409\r",
      "(1002 / 10000) training: 0.4460 | validation: 0.4408\r",
      "(1003 / 10000) training: 0.4460 | validation: 0.4408\r",
      "(1004 / 10000) training: 0.4459 | validation: 0.4408\r",
      "(1005 / 10000) training: 0.4459 | validation: 0.4407\r",
      "(1006 / 10000) training: 0.4459 | validation: 0.4407\r",
      "(1007 / 10000) training: 0.4458 | validation: 0.4407\r",
      "(1008 / 10000) training: 0.4458 | validation: 0.4406\r",
      "(1009 / 10000) training: 0.4458 | validation: 0.4406\r",
      "(1010 / 10000) training: 0.4458 | validation: 0.4406\r",
      "(1011 / 10000) training: 0.4457 | validation: 0.4406\r",
      "(1012 / 10000) training: 0.4457 | validation: 0.4405\r",
      "(1013 / 10000) training: 0.4457 | validation: 0.4405\r",
      "(1014 / 10000) training: 0.4456 | validation: 0.4405\r",
      "(1015 / 10000) training: 0.4456 | validation: 0.4404\r",
      "(1016 / 10000) training: 0.4456 | validation: 0.4404\r",
      "(1017 / 10000) training: 0.4455 | validation: 0.4404\r",
      "(1018 / 10000) training: 0.4455 | validation: 0.4403\r",
      "(1019 / 10000) training: 0.4455 | validation: 0.4403\r",
      "(1020 / 10000) training: 0.4455 | validation: 0.4403\r",
      "(1021 / 10000) training: 0.4454 | validation: 0.4403\r",
      "(1022 / 10000) training: 0.4454 | validation: 0.4402\r",
      "(1023 / 10000) training: 0.4454 | validation: 0.4402\r",
      "(1024 / 10000) training: 0.4453 | validation: 0.4402\r",
      "(1025 / 10000) training: 0.4453 | validation: 0.4401\r",
      "(1026 / 10000) training: 0.4453 | validation: 0.4401\r",
      "(1027 / 10000) training: 0.4453 | validation: 0.4401\r",
      "(1028 / 10000) training: 0.4452 | validation: 0.4400\r",
      "(1029 / 10000) training: 0.4452 | validation: 0.4400\r",
      "(1030 / 10000) training: 0.4452 | validation: 0.4400\r",
      "(1031 / 10000) training: 0.4451 | validation: 0.4400\r",
      "(1032 / 10000) training: 0.4451 | validation: 0.4399\r",
      "(1033 / 10000) training: 0.4451 | validation: 0.4399\r",
      "(1034 / 10000) training: 0.4450 | validation: 0.4399\r",
      "(1035 / 10000) training: 0.4450 | validation: 0.4398\r",
      "(1036 / 10000) training: 0.4450 | validation: 0.4398\r",
      "(1037 / 10000) training: 0.4450 | validation: 0.4398\r",
      "(1038 / 10000) training: 0.4449 | validation: 0.4398\r",
      "(1039 / 10000) training: 0.4449 | validation: 0.4397\r",
      "(1040 / 10000) training: 0.4449 | validation: 0.4397\r",
      "(1041 / 10000) training: 0.4448 | validation: 0.4397\r",
      "(1042 / 10000) training: 0.4448 | validation: 0.4396\r",
      "(1043 / 10000) training: 0.4448 | validation: 0.4396\r",
      "(1044 / 10000) training: 0.4448 | validation: 0.4396\r",
      "(1045 / 10000) training: 0.4447 | validation: 0.4395\r",
      "(1046 / 10000) training: 0.4447 | validation: 0.4395\r",
      "(1047 / 10000) training: 0.4447 | validation: 0.4395\r",
      "(1048 / 10000) training: 0.4446 | validation: 0.4395\r",
      "(1049 / 10000) training: 0.4446 | validation: 0.4394\r",
      "(1050 / 10000) training: 0.4446 | validation: 0.4394\r",
      "(1051 / 10000) training: 0.4446 | validation: 0.4394\r",
      "(1052 / 10000) training: 0.4445 | validation: 0.4393\r",
      "(1053 / 10000) training: 0.4445 | validation: 0.4393\r",
      "(1054 / 10000) training: 0.4445 | validation: 0.4393\r",
      "(1055 / 10000) training: 0.4444 | validation: 0.4393\r",
      "(1056 / 10000) training: 0.4444 | validation: 0.4392\r",
      "(1057 / 10000) training: 0.4444 | validation: 0.4392\r",
      "(1058 / 10000) training: 0.4444 | validation: 0.4392\r",
      "(1059 / 10000) training: 0.4443 | validation: 0.4391\r",
      "(1060 / 10000) training: 0.4443 | validation: 0.4391\r",
      "(1061 / 10000) training: 0.4443 | validation: 0.4391\r",
      "(1062 / 10000) training: 0.4442 | validation: 0.4391\r",
      "(1063 / 10000) training: 0.4442 | validation: 0.4390\r",
      "(1064 / 10000) training: 0.4442 | validation: 0.4390\r",
      "(1065 / 10000) training: 0.4442 | validation: 0.4390\r",
      "(1066 / 10000) training: 0.4441 | validation: 0.4389\r",
      "(1067 / 10000) training: 0.4441 | validation: 0.4389\r",
      "(1068 / 10000) training: 0.4441 | validation: 0.4389\r",
      "(1069 / 10000) training: 0.4440 | validation: 0.4389\r",
      "(1070 / 10000) training: 0.4440 | validation: 0.4388\r",
      "(1071 / 10000) training: 0.4440 | validation: 0.4388\r",
      "(1072 / 10000) training: 0.4440 | validation: 0.4388\r",
      "(1073 / 10000) training: 0.4439 | validation: 0.4387\r",
      "(1074 / 10000) training: 0.4439 | validation: 0.4387\r",
      "(1075 / 10000) training: 0.4439 | validation: 0.4387\r",
      "(1076 / 10000) training: 0.4438 | validation: 0.4387\r",
      "(1077 / 10000) training: 0.4438 | validation: 0.4386\r",
      "(1078 / 10000) training: 0.4438 | validation: 0.4386\r",
      "(1079 / 10000) training: 0.4438 | validation: 0.4386\r",
      "(1080 / 10000) training: 0.4437 | validation: 0.4385\r",
      "(1081 / 10000) training: 0.4437 | validation: 0.4385\r",
      "(1082 / 10000) training: 0.4437 | validation: 0.4385\r",
      "(1083 / 10000) training: 0.4437 | validation: 0.4385\r",
      "(1084 / 10000) training: 0.4436 | validation: 0.4384\r",
      "(1085 / 10000) training: 0.4436 | validation: 0.4384\r",
      "(1086 / 10000) training: 0.4436 | validation: 0.4384\r",
      "(1087 / 10000) training: 0.4435 | validation: 0.4383\r",
      "(1088 / 10000) training: 0.4435 | validation: 0.4383\r",
      "(1089 / 10000) training: 0.4435 | validation: 0.4383\r",
      "(1090 / 10000) training: 0.4435 | validation: 0.4383\r",
      "(1091 / 10000) training: 0.4434 | validation: 0.4382\r",
      "(1092 / 10000) training: 0.4434 | validation: 0.4382\r",
      "(1093 / 10000) training: 0.4434 | validation: 0.4382\r",
      "(1094 / 10000) training: 0.4434 | validation: 0.4382\r",
      "(1095 / 10000) training: 0.4433 | validation: 0.4381\r",
      "(1096 / 10000) training: 0.4433 | validation: 0.4381\r",
      "(1097 / 10000) training: 0.4433 | validation: 0.4381\r",
      "(1098 / 10000) training: 0.4432 | validation: 0.4380\r",
      "(1099 / 10000) training: 0.4432 | validation: 0.4380\r",
      "(1100 / 10000) training: 0.4432 | validation: 0.4380\r",
      "(1101 / 10000) training: 0.4432 | validation: 0.4380\r",
      "(1102 / 10000) training: 0.4431 | validation: 0.4379\r",
      "(1103 / 10000) training: 0.4431 | validation: 0.4379\r",
      "(1104 / 10000) training: 0.4431 | validation: 0.4379\r",
      "(1105 / 10000) training: 0.4431 | validation: 0.4379\r",
      "(1106 / 10000) training: 0.4430 | validation: 0.4378\r",
      "(1107 / 10000) training: 0.4430 | validation: 0.4378\r",
      "(1108 / 10000) training: 0.4430 | validation: 0.4378\r",
      "(1109 / 10000) training: 0.4429 | validation: 0.4377\r",
      "(1110 / 10000) training: 0.4429 | validation: 0.4377\r",
      "(1111 / 10000) training: 0.4429 | validation: 0.4377\r",
      "(1112 / 10000) training: 0.4429 | validation: 0.4377\r",
      "(1113 / 10000) training: 0.4428 | validation: 0.4376\r",
      "(1114 / 10000) training: 0.4428 | validation: 0.4376\r",
      "(1115 / 10000) training: 0.4428 | validation: 0.4376\r",
      "(1116 / 10000) training: 0.4428 | validation: 0.4376\r",
      "(1117 / 10000) training: 0.4427 | validation: 0.4375\r",
      "(1118 / 10000) training: 0.4427 | validation: 0.4375\r",
      "(1119 / 10000) training: 0.4427 | validation: 0.4375\r",
      "(1120 / 10000) training: 0.4426 | validation: 0.4374\r",
      "(1121 / 10000) training: 0.4426 | validation: 0.4374\r",
      "(1122 / 10000) training: 0.4426 | validation: 0.4374\r",
      "(1123 / 10000) training: 0.4426 | validation: 0.4374\r",
      "(1124 / 10000) training: 0.4425 | validation: 0.4373\r",
      "(1125 / 10000) training: 0.4425 | validation: 0.4373\r",
      "(1126 / 10000) training: 0.4425 | validation: 0.4373\r",
      "(1127 / 10000) training: 0.4425 | validation: 0.4373\r",
      "(1128 / 10000) training: 0.4424 | validation: 0.4372\r",
      "(1129 / 10000) training: 0.4424 | validation: 0.4372\r",
      "(1130 / 10000) training: 0.4424 | validation: 0.4372\r",
      "(1131 / 10000) training: 0.4424 | validation: 0.4372\r",
      "(1132 / 10000) training: 0.4423 | validation: 0.4371\r",
      "(1133 / 10000) training: 0.4423 | validation: 0.4371\r",
      "(1134 / 10000) training: 0.4423 | validation: 0.4371\r",
      "(1135 / 10000) training: 0.4423 | validation: 0.4370\r",
      "(1136 / 10000) training: 0.4422 | validation: 0.4370\r",
      "(1137 / 10000) training: 0.4422 | validation: 0.4370\r",
      "(1138 / 10000) training: 0.4422 | validation: 0.4370\r",
      "(1139 / 10000) training: 0.4421 | validation: 0.4369\r",
      "(1140 / 10000) training: 0.4421 | validation: 0.4369\r",
      "(1141 / 10000) training: 0.4421 | validation: 0.4369\r",
      "(1142 / 10000) training: 0.4421 | validation: 0.4369\r",
      "(1143 / 10000) training: 0.4420 | validation: 0.4368\r",
      "(1144 / 10000) training: 0.4420 | validation: 0.4368\r",
      "(1145 / 10000) training: 0.4420 | validation: 0.4368\r",
      "(1146 / 10000) training: 0.4420 | validation: 0.4368\r",
      "(1147 / 10000) training: 0.4419 | validation: 0.4367\r",
      "(1148 / 10000) training: 0.4419 | validation: 0.4367\r",
      "(1149 / 10000) training: 0.4419 | validation: 0.4367\r",
      "(1150 / 10000) training: 0.4419 | validation: 0.4366\r",
      "(1151 / 10000) training: 0.4418 | validation: 0.4366\r",
      "(1152 / 10000) training: 0.4418 | validation: 0.4366\r",
      "(1153 / 10000) training: 0.4418 | validation: 0.4366"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "(1154 / 10000) training: 0.4418 | validation: 0.4365\r",
      "(1155 / 10000) training: 0.4417 | validation: 0.4365\r",
      "(1156 / 10000) training: 0.4417 | validation: 0.4365\r",
      "(1157 / 10000) training: 0.4417 | validation: 0.4365\r",
      "(1158 / 10000) training: 0.4417 | validation: 0.4364\r",
      "(1159 / 10000) training: 0.4416 | validation: 0.4364\r",
      "(1160 / 10000) training: 0.4416 | validation: 0.4364\r",
      "(1161 / 10000) training: 0.4416 | validation: 0.4364\r",
      "(1162 / 10000) training: 0.4416 | validation: 0.4363\r",
      "(1163 / 10000) training: 0.4415 | validation: 0.4363\r",
      "(1164 / 10000) training: 0.4415 | validation: 0.4363\r",
      "(1165 / 10000) training: 0.4415 | validation: 0.4363\r",
      "(1166 / 10000) training: 0.4414 | validation: 0.4362\r",
      "(1167 / 10000) training: 0.4414 | validation: 0.4362\r",
      "(1168 / 10000) training: 0.4414 | validation: 0.4362\r",
      "(1169 / 10000) training: 0.4414 | validation: 0.4362\r",
      "(1170 / 10000) training: 0.4413 | validation: 0.4361\r",
      "(1171 / 10000) training: 0.4413 | validation: 0.4361\r",
      "(1172 / 10000) training: 0.4413 | validation: 0.4361\r",
      "(1173 / 10000) training: 0.4413 | validation: 0.4361\r",
      "(1174 / 10000) training: 0.4412 | validation: 0.4360\r",
      "(1175 / 10000) training: 0.4412 | validation: 0.4360\r",
      "(1176 / 10000) training: 0.4412 | validation: 0.4360\r",
      "(1177 / 10000) training: 0.4412 | validation: 0.4360\r",
      "(1178 / 10000) training: 0.4411 | validation: 0.4359\r",
      "(1179 / 10000) training: 0.4411 | validation: 0.4359\r",
      "(1180 / 10000) training: 0.4411 | validation: 0.4359\r",
      "(1181 / 10000) training: 0.4411 | validation: 0.4359\r",
      "(1182 / 10000) training: 0.4410 | validation: 0.4358\r",
      "(1183 / 10000) training: 0.4410 | validation: 0.4358\r",
      "(1184 / 10000) training: 0.4410 | validation: 0.4358\r",
      "(1185 / 10000) training: 0.4410 | validation: 0.4358\r",
      "(1186 / 10000) training: 0.4409 | validation: 0.4357\r",
      "(1187 / 10000) training: 0.4409 | validation: 0.4357\r",
      "(1188 / 10000) training: 0.4409 | validation: 0.4357\r",
      "(1189 / 10000) training: 0.4409 | validation: 0.4357\r",
      "(1190 / 10000) training: 0.4408 | validation: 0.4356\r",
      "(1191 / 10000) training: 0.4408 | validation: 0.4356\r",
      "(1192 / 10000) training: 0.4408 | validation: 0.4356\r",
      "(1193 / 10000) training: 0.4408 | validation: 0.4355\r",
      "(1194 / 10000) training: 0.4407 | validation: 0.4355\r",
      "(1195 / 10000) training: 0.4407 | validation: 0.4355\r",
      "(1196 / 10000) training: 0.4407 | validation: 0.4355\r",
      "(1197 / 10000) training: 0.4407 | validation: 0.4355\r",
      "(1198 / 10000) training: 0.4406 | validation: 0.4354\r",
      "(1199 / 10000) training: 0.4406 | validation: 0.4354\r",
      "(1200 / 10000) training: 0.4406 | validation: 0.4354\r",
      "(1201 / 10000) training: 0.4406 | validation: 0.4354\r",
      "(1202 / 10000) training: 0.4406 | validation: 0.4353\r",
      "(1203 / 10000) training: 0.4405 | validation: 0.4353\r",
      "(1204 / 10000) training: 0.4405 | validation: 0.4353\r",
      "(1205 / 10000) training: 0.4405 | validation: 0.4353\r",
      "(1206 / 10000) training: 0.4405 | validation: 0.4352\r",
      "(1207 / 10000) training: 0.4404 | validation: 0.4352\r",
      "(1208 / 10000) training: 0.4404 | validation: 0.4352\r",
      "(1209 / 10000) training: 0.4404 | validation: 0.4352\r",
      "(1210 / 10000) training: 0.4404 | validation: 0.4351\r",
      "(1211 / 10000) training: 0.4403 | validation: 0.4351\r",
      "(1212 / 10000) training: 0.4403 | validation: 0.4351\r",
      "(1213 / 10000) training: 0.4403 | validation: 0.4351\r",
      "(1214 / 10000) training: 0.4403 | validation: 0.4350\r",
      "(1215 / 10000) training: 0.4402 | validation: 0.4350\r",
      "(1216 / 10000) training: 0.4402 | validation: 0.4350\r",
      "(1217 / 10000) training: 0.4402 | validation: 0.4350\r",
      "(1218 / 10000) training: 0.4402 | validation: 0.4349\r",
      "(1219 / 10000) training: 0.4401 | validation: 0.4349\r",
      "(1220 / 10000) training: 0.4401 | validation: 0.4349\r",
      "(1221 / 10000) training: 0.4401 | validation: 0.4349\r",
      "(1222 / 10000) training: 0.4401 | validation: 0.4348\r",
      "(1223 / 10000) training: 0.4400 | validation: 0.4348\r",
      "(1224 / 10000) training: 0.4400 | validation: 0.4348\r",
      "(1225 / 10000) training: 0.4400 | validation: 0.4348\r",
      "(1226 / 10000) training: 0.4400 | validation: 0.4347\r",
      "(1227 / 10000) training: 0.4399 | validation: 0.4347\r",
      "(1228 / 10000) training: 0.4399 | validation: 0.4347\r",
      "(1229 / 10000) training: 0.4399 | validation: 0.4347\r",
      "(1230 / 10000) training: 0.4399 | validation: 0.4346\r",
      "(1231 / 10000) training: 0.4399 | validation: 0.4346\r",
      "(1232 / 10000) training: 0.4398 | validation: 0.4346\r",
      "(1233 / 10000) training: 0.4398 | validation: 0.4346\r",
      "(1234 / 10000) training: 0.4398 | validation: 0.4345\r",
      "(1235 / 10000) training: 0.4398 | validation: 0.4345\r",
      "(1236 / 10000) training: 0.4397 | validation: 0.4345\r",
      "(1237 / 10000) training: 0.4397 | validation: 0.4345\r",
      "(1238 / 10000) training: 0.4397 | validation: 0.4345\r",
      "(1239 / 10000) training: 0.4397 | validation: 0.4344\r",
      "(1240 / 10000) training: 0.4396 | validation: 0.4344\r",
      "(1241 / 10000) training: 0.4396 | validation: 0.4344\r",
      "(1242 / 10000) training: 0.4396 | validation: 0.4344\r",
      "(1243 / 10000) training: 0.4396 | validation: 0.4343\r",
      "(1244 / 10000) training: 0.4395 | validation: 0.4343\r",
      "(1245 / 10000) training: 0.4395 | validation: 0.4343\r",
      "(1246 / 10000) training: 0.4395 | validation: 0.4343\r",
      "(1247 / 10000) training: 0.4395 | validation: 0.4342\r",
      "(1248 / 10000) training: 0.4395 | validation: 0.4342\r",
      "(1249 / 10000) training: 0.4394 | validation: 0.4342\r",
      "(1250 / 10000) training: 0.4394 | validation: 0.4342\r",
      "(1251 / 10000) training: 0.4394 | validation: 0.4341\r",
      "(1252 / 10000) training: 0.4394 | validation: 0.4341\r",
      "(1253 / 10000) training: 0.4393 | validation: 0.4341\r",
      "(1254 / 10000) training: 0.4393 | validation: 0.4341\r",
      "(1255 / 10000) training: 0.4393 | validation: 0.4340\r",
      "(1256 / 10000) training: 0.4393 | validation: 0.4340\r",
      "(1257 / 10000) training: 0.4392 | validation: 0.4340\r",
      "(1258 / 10000) training: 0.4392 | validation: 0.4340\r",
      "(1259 / 10000) training: 0.4392 | validation: 0.4340\r",
      "(1260 / 10000) training: 0.4392 | validation: 0.4339\r",
      "(1261 / 10000) training: 0.4392 | validation: 0.4339\r",
      "(1262 / 10000) training: 0.4391 | validation: 0.4339\r",
      "(1263 / 10000) training: 0.4391 | validation: 0.4339\r",
      "(1264 / 10000) training: 0.4391 | validation: 0.4338\r",
      "(1265 / 10000) training: 0.4391 | validation: 0.4338\r",
      "(1266 / 10000) training: 0.4390 | validation: 0.4338\r",
      "(1267 / 10000) training: 0.4390 | validation: 0.4338\r",
      "(1268 / 10000) training: 0.4390 | validation: 0.4337\r",
      "(1269 / 10000) training: 0.4390 | validation: 0.4337\r",
      "(1270 / 10000) training: 0.4389 | validation: 0.4337\r",
      "(1271 / 10000) training: 0.4389 | validation: 0.4337\r",
      "(1272 / 10000) training: 0.4389 | validation: 0.4337\r",
      "(1273 / 10000) training: 0.4389 | validation: 0.4336\r",
      "(1274 / 10000) training: 0.4389 | validation: 0.4336\r",
      "(1275 / 10000) training: 0.4388 | validation: 0.4336\r",
      "(1276 / 10000) training: 0.4388 | validation: 0.4336\r",
      "(1277 / 10000) training: 0.4388 | validation: 0.4335\r",
      "(1278 / 10000) training: 0.4388 | validation: 0.4335\r",
      "(1279 / 10000) training: 0.4387 | validation: 0.4335\r",
      "(1280 / 10000) training: 0.4387 | validation: 0.4335\r",
      "(1281 / 10000) training: 0.4387 | validation: 0.4334\r",
      "(1282 / 10000) training: 0.4387 | validation: 0.4334\r",
      "(1283 / 10000) training: 0.4387 | validation: 0.4334\r",
      "(1284 / 10000) training: 0.4386 | validation: 0.4334\r",
      "(1285 / 10000) training: 0.4386 | validation: 0.4334\r",
      "(1286 / 10000) training: 0.4386 | validation: 0.4333\r",
      "(1287 / 10000) training: 0.4386 | validation: 0.4333\r",
      "(1288 / 10000) training: 0.4385 | validation: 0.4333\r",
      "(1289 / 10000) training: 0.4385 | validation: 0.4333\r",
      "(1290 / 10000) training: 0.4385 | validation: 0.4332\r",
      "(1291 / 10000) training: 0.4385 | validation: 0.4332\r",
      "(1292 / 10000) training: 0.4385 | validation: 0.4332\r",
      "(1293 / 10000) training: 0.4384 | validation: 0.4332\r",
      "(1294 / 10000) training: 0.4384 | validation: 0.4332\r",
      "(1295 / 10000) training: 0.4384 | validation: 0.4331\r",
      "(1296 / 10000) training: 0.4384 | validation: 0.4331\r",
      "(1297 / 10000) training: 0.4383 | validation: 0.4331\r",
      "(1298 / 10000) training: 0.4383 | validation: 0.4331\r",
      "(1299 / 10000) training: 0.4383 | validation: 0.4330\r",
      "(1300 / 10000) training: 0.4383 | validation: 0.4330\r",
      "(1301 / 10000) training: 0.4383 | validation: 0.4330\r",
      "(1302 / 10000) training: 0.4382 | validation: 0.4330\r",
      "(1303 / 10000) training: 0.4382 | validation: 0.4330\r",
      "(1304 / 10000) training: 0.4382 | validation: 0.4329\r",
      "(1305 / 10000) training: 0.4382 | validation: 0.4329\r",
      "(1306 / 10000) training: 0.4381 | validation: 0.4329\r",
      "(1307 / 10000) training: 0.4381 | validation: 0.4329\r",
      "(1308 / 10000) training: 0.4381 | validation: 0.4328\r",
      "(1309 / 10000) training: 0.4381 | validation: 0.4328\r",
      "(1310 / 10000) training: 0.4381 | validation: 0.4328\r",
      "(1311 / 10000) training: 0.4380 | validation: 0.4328\r",
      "(1312 / 10000) training: 0.4380 | validation: 0.4328\r",
      "(1313 / 10000) training: 0.4380 | validation: 0.4327\r",
      "(1314 / 10000) training: 0.4380 | validation: 0.4327\r",
      "(1315 / 10000) training: 0.4379 | validation: 0.4327\r",
      "(1316 / 10000) training: 0.4379 | validation: 0.4327\r",
      "(1317 / 10000) training: 0.4379 | validation: 0.4326\r",
      "(1318 / 10000) training: 0.4379 | validation: 0.4326\r",
      "(1319 / 10000) training: 0.4379 | validation: 0.4326\r",
      "(1320 / 10000) training: 0.4378 | validation: 0.4326\r",
      "(1321 / 10000) training: 0.4378 | validation: 0.4326\r",
      "(1322 / 10000) training: 0.4378 | validation: 0.4325\r",
      "(1323 / 10000) training: 0.4378 | validation: 0.4325\r",
      "(1324 / 10000) training: 0.4378 | validation: 0.4325\r",
      "(1325 / 10000) training: 0.4377 | validation: 0.4325\r",
      "(1326 / 10000) training: 0.4377 | validation: 0.4324\r",
      "(1327 / 10000) training: 0.4377 | validation: 0.4324\r",
      "(1328 / 10000) training: 0.4377 | validation: 0.4324\r",
      "(1329 / 10000) training: 0.4376 | validation: 0.4324\r",
      "(1330 / 10000) training: 0.4376 | validation: 0.4324\r",
      "(1331 / 10000) training: 0.4376 | validation: 0.4323\r",
      "(1332 / 10000) training: 0.4376 | validation: 0.4323\r",
      "(1333 / 10000) training: 0.4376 | validation: 0.4323\r",
      "(1334 / 10000) training: 0.4375 | validation: 0.4323\r",
      "(1335 / 10000) training: 0.4375 | validation: 0.4322\r",
      "(1336 / 10000) training: 0.4375 | validation: 0.4322\r",
      "(1337 / 10000) training: 0.4375 | validation: 0.4322\r",
      "(1338 / 10000) training: 0.4375 | validation: 0.4322\r",
      "(1339 / 10000) training: 0.4374 | validation: 0.4322\r",
      "(1340 / 10000) training: 0.4374 | validation: 0.4321\r",
      "(1341 / 10000) training: 0.4374 | validation: 0.4321\r",
      "(1342 / 10000) training: 0.4374 | validation: 0.4321\r",
      "(1343 / 10000) training: 0.4373 | validation: 0.4321\r",
      "(1344 / 10000) training: 0.4373 | validation: 0.4321\r",
      "(1345 / 10000) training: 0.4373 | validation: 0.4320\r",
      "(1346 / 10000) training: 0.4373 | validation: 0.4320\r",
      "(1347 / 10000) training: 0.4373 | validation: 0.4320"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "(1348 / 10000) training: 0.4372 | validation: 0.4320\r",
      "(1349 / 10000) training: 0.4372 | validation: 0.4319\r",
      "(1350 / 10000) training: 0.4372 | validation: 0.4319\r",
      "(1351 / 10000) training: 0.4372 | validation: 0.4319\r",
      "(1352 / 10000) training: 0.4372 | validation: 0.4319\r",
      "(1353 / 10000) training: 0.4371 | validation: 0.4319\r",
      "(1354 / 10000) training: 0.4371 | validation: 0.4318\r",
      "(1355 / 10000) training: 0.4371 | validation: 0.4318\r",
      "(1356 / 10000) training: 0.4371 | validation: 0.4318\r",
      "(1357 / 10000) training: 0.4371 | validation: 0.4318\r",
      "(1358 / 10000) training: 0.4370 | validation: 0.4318\r",
      "(1359 / 10000) training: 0.4370 | validation: 0.4317\r",
      "(1360 / 10000) training: 0.4370 | validation: 0.4317\r",
      "(1361 / 10000) training: 0.4370 | validation: 0.4317\r",
      "(1362 / 10000) training: 0.4369 | validation: 0.4317\r",
      "(1363 / 10000) training: 0.4369 | validation: 0.4317\r",
      "(1364 / 10000) training: 0.4369 | validation: 0.4316\r",
      "(1365 / 10000) training: 0.4369 | validation: 0.4316\r",
      "(1366 / 10000) training: 0.4369 | validation: 0.4316\r",
      "(1367 / 10000) training: 0.4368 | validation: 0.4316\r",
      "(1368 / 10000) training: 0.4368 | validation: 0.4315\r",
      "(1369 / 10000) training: 0.4368 | validation: 0.4315\r",
      "(1370 / 10000) training: 0.4368 | validation: 0.4315\r",
      "(1371 / 10000) training: 0.4368 | validation: 0.4315\r",
      "(1372 / 10000) training: 0.4367 | validation: 0.4315\r",
      "(1373 / 10000) training: 0.4367 | validation: 0.4314\r",
      "(1374 / 10000) training: 0.4367 | validation: 0.4314\r",
      "(1375 / 10000) training: 0.4367 | validation: 0.4314\r",
      "(1376 / 10000) training: 0.4367 | validation: 0.4314\r",
      "(1377 / 10000) training: 0.4366 | validation: 0.4314\r",
      "(1378 / 10000) training: 0.4366 | validation: 0.4313\r",
      "(1379 / 10000) training: 0.4366 | validation: 0.4313\r",
      "(1380 / 10000) training: 0.4366 | validation: 0.4313\r",
      "(1381 / 10000) training: 0.4366 | validation: 0.4313\r",
      "(1382 / 10000) training: 0.4365 | validation: 0.4313\r",
      "(1383 / 10000) training: 0.4365 | validation: 0.4312\r",
      "(1384 / 10000) training: 0.4365 | validation: 0.4312\r",
      "(1385 / 10000) training: 0.4365 | validation: 0.4312\r",
      "(1386 / 10000) training: 0.4365 | validation: 0.4312\r",
      "(1387 / 10000) training: 0.4364 | validation: 0.4312\r",
      "(1388 / 10000) training: 0.4364 | validation: 0.4311\r",
      "(1389 / 10000) training: 0.4364 | validation: 0.4311\r",
      "(1390 / 10000) training: 0.4364 | validation: 0.4311\r",
      "(1391 / 10000) training: 0.4364 | validation: 0.4311\r",
      "(1392 / 10000) training: 0.4363 | validation: 0.4311\r",
      "(1393 / 10000) training: 0.4363 | validation: 0.4310\r",
      "(1394 / 10000) training: 0.4363 | validation: 0.4310\r",
      "(1395 / 10000) training: 0.4363 | validation: 0.4310\r",
      "(1396 / 10000) training: 0.4363 | validation: 0.4310\r",
      "(1397 / 10000) training: 0.4362 | validation: 0.4310\r",
      "(1398 / 10000) training: 0.4362 | validation: 0.4309\r",
      "(1399 / 10000) training: 0.4362 | validation: 0.4309\r",
      "(1400 / 10000) training: 0.4362 | validation: 0.4309\r",
      "(1401 / 10000) training: 0.4362 | validation: 0.4309\r",
      "(1402 / 10000) training: 0.4361 | validation: 0.4309\r",
      "(1403 / 10000) training: 0.4361 | validation: 0.4308\r",
      "(1404 / 10000) training: 0.4361 | validation: 0.4308\r",
      "(1405 / 10000) training: 0.4361 | validation: 0.4308\r",
      "(1406 / 10000) training: 0.4361 | validation: 0.4308\r",
      "(1407 / 10000) training: 0.4360 | validation: 0.4308\r",
      "(1408 / 10000) training: 0.4360 | validation: 0.4307\r",
      "(1409 / 10000) training: 0.4360 | validation: 0.4307\r",
      "(1410 / 10000) training: 0.4360 | validation: 0.4307\r",
      "(1411 / 10000) training: 0.4360 | validation: 0.4307\r",
      "(1412 / 10000) training: 0.4359 | validation: 0.4307\r",
      "(1413 / 10000) training: 0.4359 | validation: 0.4306\r",
      "(1414 / 10000) training: 0.4359 | validation: 0.4306\r",
      "(1415 / 10000) training: 0.4359 | validation: 0.4306\r",
      "(1416 / 10000) training: 0.4359 | validation: 0.4306\r",
      "(1417 / 10000) training: 0.4358 | validation: 0.4306\r",
      "(1418 / 10000) training: 0.4358 | validation: 0.4305\r",
      "(1419 / 10000) training: 0.4358 | validation: 0.4305\r",
      "(1420 / 10000) training: 0.4358 | validation: 0.4305\r",
      "(1421 / 10000) training: 0.4358 | validation: 0.4305\r",
      "(1422 / 10000) training: 0.4357 | validation: 0.4305\r",
      "(1423 / 10000) training: 0.4357 | validation: 0.4304\r",
      "(1424 / 10000) training: 0.4357 | validation: 0.4304\r",
      "(1425 / 10000) training: 0.4357 | validation: 0.4304\r",
      "(1426 / 10000) training: 0.4357 | validation: 0.4304\r",
      "(1427 / 10000) training: 0.4356 | validation: 0.4304\r",
      "(1428 / 10000) training: 0.4356 | validation: 0.4303\r",
      "(1429 / 10000) training: 0.4356 | validation: 0.4303\r",
      "(1430 / 10000) training: 0.4356 | validation: 0.4303\r",
      "(1431 / 10000) training: 0.4356 | validation: 0.4303\r",
      "(1432 / 10000) training: 0.4356 | validation: 0.4303\r",
      "(1433 / 10000) training: 0.4355 | validation: 0.4302\r",
      "(1434 / 10000) training: 0.4355 | validation: 0.4302\r",
      "(1435 / 10000) training: 0.4355 | validation: 0.4302\r",
      "(1436 / 10000) training: 0.4355 | validation: 0.4302\r",
      "(1437 / 10000) training: 0.4355 | validation: 0.4302\r",
      "(1438 / 10000) training: 0.4354 | validation: 0.4301\r",
      "(1439 / 10000) training: 0.4354 | validation: 0.4301\r",
      "(1440 / 10000) training: 0.4354 | validation: 0.4301\r",
      "(1441 / 10000) training: 0.4354 | validation: 0.4301\r",
      "(1442 / 10000) training: 0.4354 | validation: 0.4301\r",
      "(1443 / 10000) training: 0.4353 | validation: 0.4300\r",
      "(1444 / 10000) training: 0.4353 | validation: 0.4300\r",
      "(1445 / 10000) training: 0.4353 | validation: 0.4300\r",
      "(1446 / 10000) training: 0.4353 | validation: 0.4300\r",
      "(1447 / 10000) training: 0.4353 | validation: 0.4300\r",
      "(1448 / 10000) training: 0.4352 | validation: 0.4299\r",
      "(1449 / 10000) training: 0.4352 | validation: 0.4299\r",
      "(1450 / 10000) training: 0.4352 | validation: 0.4299\r",
      "(1451 / 10000) training: 0.4352 | validation: 0.4299\r",
      "(1452 / 10000) training: 0.4352 | validation: 0.4299\r",
      "(1453 / 10000) training: 0.4352 | validation: 0.4299\r",
      "(1454 / 10000) training: 0.4351 | validation: 0.4298\r",
      "(1455 / 10000) training: 0.4351 | validation: 0.4298\r",
      "(1456 / 10000) training: 0.4351 | validation: 0.4298\r",
      "(1457 / 10000) training: 0.4351 | validation: 0.4298\r",
      "(1458 / 10000) training: 0.4351 | validation: 0.4298\r",
      "(1459 / 10000) training: 0.4350 | validation: 0.4297\r",
      "(1460 / 10000) training: 0.4350 | validation: 0.4297\r",
      "(1461 / 10000) training: 0.4350 | validation: 0.4297\r",
      "(1462 / 10000) training: 0.4350 | validation: 0.4297\r",
      "(1463 / 10000) training: 0.4350 | validation: 0.4297\r",
      "(1464 / 10000) training: 0.4349 | validation: 0.4296\r",
      "(1465 / 10000) training: 0.4349 | validation: 0.4296\r",
      "(1466 / 10000) training: 0.4349 | validation: 0.4296\r",
      "(1467 / 10000) training: 0.4349 | validation: 0.4296\r",
      "(1468 / 10000) training: 0.4349 | validation: 0.4296\r",
      "(1469 / 10000) training: 0.4349 | validation: 0.4295\r",
      "(1470 / 10000) training: 0.4348 | validation: 0.4295\r",
      "(1471 / 10000) training: 0.4348 | validation: 0.4295\r",
      "(1472 / 10000) training: 0.4348 | validation: 0.4295\r",
      "(1473 / 10000) training: 0.4348 | validation: 0.4295\r",
      "(1474 / 10000) training: 0.4348 | validation: 0.4295\r",
      "(1475 / 10000) training: 0.4347 | validation: 0.4294\r",
      "(1476 / 10000) training: 0.4347 | validation: 0.4294\r",
      "(1477 / 10000) training: 0.4347 | validation: 0.4294\r",
      "(1478 / 10000) training: 0.4347 | validation: 0.4294\r",
      "(1479 / 10000) training: 0.4347 | validation: 0.4294\r",
      "(1480 / 10000) training: 0.4347 | validation: 0.4293\r",
      "(1481 / 10000) training: 0.4346 | validation: 0.4293\r",
      "(1482 / 10000) training: 0.4346 | validation: 0.4293\r",
      "(1483 / 10000) training: 0.4346 | validation: 0.4293\r",
      "(1484 / 10000) training: 0.4346 | validation: 0.4293\r",
      "(1485 / 10000) training: 0.4346 | validation: 0.4292\r",
      "(1486 / 10000) training: 0.4345 | validation: 0.4292\r",
      "(1487 / 10000) training: 0.4345 | validation: 0.4292\r",
      "(1488 / 10000) training: 0.4345 | validation: 0.4292\r",
      "(1489 / 10000) training: 0.4345 | validation: 0.4292\r",
      "(1490 / 10000) training: 0.4345 | validation: 0.4292\r",
      "(1491 / 10000) training: 0.4345 | validation: 0.4291\r",
      "(1492 / 10000) training: 0.4344 | validation: 0.4291\r",
      "(1493 / 10000) training: 0.4344 | validation: 0.4291\r",
      "(1494 / 10000) training: 0.4344 | validation: 0.4291\r",
      "(1495 / 10000) training: 0.4344 | validation: 0.4291\r",
      "(1496 / 10000) training: 0.4344 | validation: 0.4290\r",
      "(1497 / 10000) training: 0.4343 | validation: 0.4290\r",
      "(1498 / 10000) training: 0.4343 | validation: 0.4290\r",
      "(1499 / 10000) training: 0.4343 | validation: 0.4290\r",
      "(1500 / 10000) training: 0.4343 | validation: 0.4290\r",
      "(1501 / 10000) training: 0.4343 | validation: 0.4290\r",
      "(1502 / 10000) training: 0.4343 | validation: 0.4289\r",
      "(1503 / 10000) training: 0.4342 | validation: 0.4289\r",
      "(1504 / 10000) training: 0.4342 | validation: 0.4289\r",
      "(1505 / 10000) training: 0.4342 | validation: 0.4289\r",
      "(1506 / 10000) training: 0.4342 | validation: 0.4289\r",
      "(1507 / 10000) training: 0.4342 | validation: 0.4288\r",
      "(1508 / 10000) training: 0.4341 | validation: 0.4288\r",
      "(1509 / 10000) training: 0.4341 | validation: 0.4288\r",
      "(1510 / 10000) training: 0.4341 | validation: 0.4288\r",
      "(1511 / 10000) training: 0.4341 | validation: 0.4288\r",
      "(1512 / 10000) training: 0.4341 | validation: 0.4288\r",
      "(1513 / 10000) training: 0.4341 | validation: 0.4287\r",
      "(1514 / 10000) training: 0.4340 | validation: 0.4287\r",
      "(1515 / 10000) training: 0.4340 | validation: 0.4287\r",
      "(1516 / 10000) training: 0.4340 | validation: 0.4287\r",
      "(1517 / 10000) training: 0.4340 | validation: 0.4287\r",
      "(1518 / 10000) training: 0.4340 | validation: 0.4286\r",
      "(1519 / 10000) training: 0.4340 | validation: 0.4286\r",
      "(1520 / 10000) training: 0.4339 | validation: 0.4286\r",
      "(1521 / 10000) training: 0.4339 | validation: 0.4286\r",
      "(1522 / 10000) training: 0.4339 | validation: 0.4286\r",
      "(1523 / 10000) training: 0.4339 | validation: 0.4286\r",
      "(1524 / 10000) training: 0.4339 | validation: 0.4285\r",
      "(1525 / 10000) training: 0.4338 | validation: 0.4285\r",
      "(1526 / 10000) training: 0.4338 | validation: 0.4285\r",
      "(1527 / 10000) training: 0.4338 | validation: 0.4285\r",
      "(1528 / 10000) training: 0.4338 | validation: 0.4285\r",
      "(1529 / 10000) training: 0.4338 | validation: 0.4285\r",
      "(1530 / 10000) training: 0.4338 | validation: 0.4284\r",
      "(1531 / 10000) training: 0.4337 | validation: 0.4284\r",
      "(1532 / 10000) training: 0.4337 | validation: 0.4284\r",
      "(1533 / 10000) training: 0.4337 | validation: 0.4284\r",
      "(1534 / 10000) training: 0.4337 | validation: 0.4284\r",
      "(1535 / 10000) training: 0.4337 | validation: 0.4283\r",
      "(1536 / 10000) training: 0.4337 | validation: 0.4283\r",
      "(1537 / 10000) training: 0.4336 | validation: 0.4283\r",
      "(1538 / 10000) training: 0.4336 | validation: 0.4283\r",
      "(1539 / 10000) training: 0.4336 | validation: 0.4283\r",
      "(1540 / 10000) training: 0.4336 | validation: 0.4283\r",
      "(1541 / 10000) training: 0.4336 | validation: 0.4282\r",
      "(1542 / 10000) training: 0.4336 | validation: 0.4282\r",
      "(1543 / 10000) training: 0.4335 | validation: 0.4282\r",
      "(1544 / 10000) training: 0.4335 | validation: 0.4282"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "(1545 / 10000) training: 0.4335 | validation: 0.4282\r",
      "(1546 / 10000) training: 0.4335 | validation: 0.4282\r",
      "(1547 / 10000) training: 0.4335 | validation: 0.4281\r",
      "(1548 / 10000) training: 0.4335 | validation: 0.4281\r",
      "(1549 / 10000) training: 0.4334 | validation: 0.4281\r",
      "(1550 / 10000) training: 0.4334 | validation: 0.4281\r",
      "(1551 / 10000) training: 0.4334 | validation: 0.4281\r",
      "(1552 / 10000) training: 0.4334 | validation: 0.4281\r",
      "(1553 / 10000) training: 0.4334 | validation: 0.4280\r",
      "(1554 / 10000) training: 0.4334 | validation: 0.4280\r",
      "(1555 / 10000) training: 0.4333 | validation: 0.4280\r",
      "(1556 / 10000) training: 0.4333 | validation: 0.4280\r",
      "(1557 / 10000) training: 0.4333 | validation: 0.4280\r",
      "(1558 / 10000) training: 0.4333 | validation: 0.4279\r",
      "(1559 / 10000) training: 0.4333 | validation: 0.4279\r",
      "(1560 / 10000) training: 0.4332 | validation: 0.4279\r",
      "(1561 / 10000) training: 0.4332 | validation: 0.4279\r",
      "(1562 / 10000) training: 0.4332 | validation: 0.4279\r",
      "(1563 / 10000) training: 0.4332 | validation: 0.4279\r",
      "(1564 / 10000) training: 0.4332 | validation: 0.4278\r",
      "(1565 / 10000) training: 0.4332 | validation: 0.4278\r",
      "(1566 / 10000) training: 0.4331 | validation: 0.4278\r",
      "(1567 / 10000) training: 0.4331 | validation: 0.4278\r",
      "(1568 / 10000) training: 0.4331 | validation: 0.4278\r",
      "(1569 / 10000) training: 0.4331 | validation: 0.4278\r",
      "(1570 / 10000) training: 0.4331 | validation: 0.4277\r",
      "(1571 / 10000) training: 0.4331 | validation: 0.4277\r",
      "(1572 / 10000) training: 0.4330 | validation: 0.4277\r",
      "(1573 / 10000) training: 0.4330 | validation: 0.4277\r",
      "(1574 / 10000) training: 0.4330 | validation: 0.4277\r",
      "(1575 / 10000) training: 0.4330 | validation: 0.4277\r",
      "(1576 / 10000) training: 0.4330 | validation: 0.4276\r",
      "(1577 / 10000) training: 0.4330 | validation: 0.4276\r",
      "(1578 / 10000) training: 0.4329 | validation: 0.4276\r",
      "(1579 / 10000) training: 0.4329 | validation: 0.4276\r",
      "(1580 / 10000) training: 0.4329 | validation: 0.4276\r",
      "(1581 / 10000) training: 0.4329 | validation: 0.4276\r",
      "(1582 / 10000) training: 0.4329 | validation: 0.4275\r",
      "(1583 / 10000) training: 0.4329 | validation: 0.4275\r",
      "(1584 / 10000) training: 0.4329 | validation: 0.4275\r",
      "(1585 / 10000) training: 0.4328 | validation: 0.4275\r",
      "(1586 / 10000) training: 0.4328 | validation: 0.4275\r",
      "(1587 / 10000) training: 0.4328 | validation: 0.4275\r",
      "(1588 / 10000) training: 0.4328 | validation: 0.4274\r",
      "(1589 / 10000) training: 0.4328 | validation: 0.4274\r",
      "(1590 / 10000) training: 0.4328 | validation: 0.4274\r",
      "(1591 / 10000) training: 0.4327 | validation: 0.4274\r",
      "(1592 / 10000) training: 0.4327 | validation: 0.4274\r",
      "(1593 / 10000) training: 0.4327 | validation: 0.4274\r",
      "(1594 / 10000) training: 0.4327 | validation: 0.4273\r",
      "(1595 / 10000) training: 0.4327 | validation: 0.4273\r",
      "(1596 / 10000) training: 0.4327 | validation: 0.4273\r",
      "(1597 / 10000) training: 0.4326 | validation: 0.4273\r",
      "(1598 / 10000) training: 0.4326 | validation: 0.4273\r",
      "(1599 / 10000) training: 0.4326 | validation: 0.4273\r",
      "(1600 / 10000) training: 0.4326 | validation: 0.4272\r",
      "(1601 / 10000) training: 0.4326 | validation: 0.4272\r",
      "(1602 / 10000) training: 0.4326 | validation: 0.4272\r",
      "(1603 / 10000) training: 0.4325 | validation: 0.4272\r",
      "(1604 / 10000) training: 0.4325 | validation: 0.4272\r",
      "(1605 / 10000) training: 0.4325 | validation: 0.4272\r",
      "(1606 / 10000) training: 0.4325 | validation: 0.4271\r",
      "(1607 / 10000) training: 0.4325 | validation: 0.4271\r",
      "(1608 / 10000) training: 0.4325 | validation: 0.4271\r",
      "(1609 / 10000) training: 0.4324 | validation: 0.4271\r",
      "(1610 / 10000) training: 0.4324 | validation: 0.4271\r",
      "(1611 / 10000) training: 0.4324 | validation: 0.4271\r",
      "(1612 / 10000) training: 0.4324 | validation: 0.4270\r",
      "(1613 / 10000) training: 0.4324 | validation: 0.4270\r",
      "(1614 / 10000) training: 0.4324 | validation: 0.4270\r",
      "(1615 / 10000) training: 0.4324 | validation: 0.4270\r",
      "(1616 / 10000) training: 0.4323 | validation: 0.4270\r",
      "(1617 / 10000) training: 0.4323 | validation: 0.4270\r",
      "(1618 / 10000) training: 0.4323 | validation: 0.4270\r",
      "(1619 / 10000) training: 0.4323 | validation: 0.4269\r",
      "(1620 / 10000) training: 0.4323 | validation: 0.4269\r",
      "(1621 / 10000) training: 0.4323 | validation: 0.4269\r",
      "(1622 / 10000) training: 0.4322 | validation: 0.4269\r",
      "(1623 / 10000) training: 0.4322 | validation: 0.4269\r",
      "(1624 / 10000) training: 0.4322 | validation: 0.4269\r",
      "(1625 / 10000) training: 0.4322 | validation: 0.4268\r",
      "(1626 / 10000) training: 0.4322 | validation: 0.4268\r",
      "(1627 / 10000) training: 0.4322 | validation: 0.4268\r",
      "(1628 / 10000) training: 0.4321 | validation: 0.4268\r",
      "(1629 / 10000) training: 0.4321 | validation: 0.4268\r",
      "(1630 / 10000) training: 0.4321 | validation: 0.4268\r",
      "(1631 / 10000) training: 0.4321 | validation: 0.4267\r",
      "(1632 / 10000) training: 0.4321 | validation: 0.4267\r",
      "(1633 / 10000) training: 0.4321 | validation: 0.4267\r",
      "(1634 / 10000) training: 0.4321 | validation: 0.4267\r",
      "(1635 / 10000) training: 0.4320 | validation: 0.4267\r",
      "(1636 / 10000) training: 0.4320 | validation: 0.4267\r",
      "(1637 / 10000) training: 0.4320 | validation: 0.4266\r",
      "(1638 / 10000) training: 0.4320 | validation: 0.4266\r",
      "(1639 / 10000) training: 0.4320 | validation: 0.4266\r",
      "(1640 / 10000) training: 0.4320 | validation: 0.4266\r",
      "(1641 / 10000) training: 0.4319 | validation: 0.4266\r",
      "(1642 / 10000) training: 0.4319 | validation: 0.4266\r",
      "(1643 / 10000) training: 0.4319 | validation: 0.4266\r",
      "(1644 / 10000) training: 0.4319 | validation: 0.4265\r",
      "(1645 / 10000) training: 0.4319 | validation: 0.4265\r",
      "(1646 / 10000) training: 0.4319 | validation: 0.4265\r",
      "(1647 / 10000) training: 0.4319 | validation: 0.4265\r",
      "(1648 / 10000) training: 0.4318 | validation: 0.4265\r",
      "(1649 / 10000) training: 0.4318 | validation: 0.4265\r",
      "(1650 / 10000) training: 0.4318 | validation: 0.4264\r",
      "(1651 / 10000) training: 0.4318 | validation: 0.4264\r",
      "(1652 / 10000) training: 0.4318 | validation: 0.4264\r",
      "(1653 / 10000) training: 0.4318 | validation: 0.4264\r",
      "(1654 / 10000) training: 0.4317 | validation: 0.4264\r",
      "(1655 / 10000) training: 0.4317 | validation: 0.4264\r",
      "(1656 / 10000) training: 0.4317 | validation: 0.4263\r",
      "(1657 / 10000) training: 0.4317 | validation: 0.4263\r",
      "(1658 / 10000) training: 0.4317 | validation: 0.4263\r",
      "(1659 / 10000) training: 0.4317 | validation: 0.4263\r",
      "(1660 / 10000) training: 0.4317 | validation: 0.4263\r",
      "(1661 / 10000) training: 0.4316 | validation: 0.4263\r",
      "(1662 / 10000) training: 0.4316 | validation: 0.4263\r",
      "(1663 / 10000) training: 0.4316 | validation: 0.4262\r",
      "(1664 / 10000) training: 0.4316 | validation: 0.4262\r",
      "(1665 / 10000) training: 0.4316 | validation: 0.4262\r",
      "(1666 / 10000) training: 0.4316 | validation: 0.4262\r",
      "(1667 / 10000) training: 0.4315 | validation: 0.4262\r",
      "(1668 / 10000) training: 0.4315 | validation: 0.4262\r",
      "(1669 / 10000) training: 0.4315 | validation: 0.4261\r",
      "(1670 / 10000) training: 0.4315 | validation: 0.4261\r",
      "(1671 / 10000) training: 0.4315 | validation: 0.4261\r",
      "(1672 / 10000) training: 0.4315 | validation: 0.4261\r",
      "(1673 / 10000) training: 0.4315 | validation: 0.4261\r",
      "(1674 / 10000) training: 0.4314 | validation: 0.4261\r",
      "(1675 / 10000) training: 0.4314 | validation: 0.4261\r",
      "(1676 / 10000) training: 0.4314 | validation: 0.4260\r",
      "(1677 / 10000) training: 0.4314 | validation: 0.4260\r",
      "(1678 / 10000) training: 0.4314 | validation: 0.4260\r",
      "(1679 / 10000) training: 0.4314 | validation: 0.4260\r",
      "(1680 / 10000) training: 0.4314 | validation: 0.4260\r",
      "(1681 / 10000) training: 0.4313 | validation: 0.4260\r",
      "(1682 / 10000) training: 0.4313 | validation: 0.4260\r",
      "(1683 / 10000) training: 0.4313 | validation: 0.4259\r",
      "(1684 / 10000) training: 0.4313 | validation: 0.4259\r",
      "(1685 / 10000) training: 0.4313 | validation: 0.4259\r",
      "(1686 / 10000) training: 0.4313 | validation: 0.4259\r",
      "(1687 / 10000) training: 0.4312 | validation: 0.4259\r",
      "(1688 / 10000) training: 0.4312 | validation: 0.4259\r",
      "(1689 / 10000) training: 0.4312 | validation: 0.4258\r",
      "(1690 / 10000) training: 0.4312 | validation: 0.4258\r",
      "(1691 / 10000) training: 0.4312 | validation: 0.4258\r",
      "(1692 / 10000) training: 0.4312 | validation: 0.4258\r",
      "(1693 / 10000) training: 0.4312 | validation: 0.4258\r",
      "(1694 / 10000) training: 0.4311 | validation: 0.4258\r",
      "(1695 / 10000) training: 0.4311 | validation: 0.4258\r",
      "(1696 / 10000) training: 0.4311 | validation: 0.4257\r",
      "(1697 / 10000) training: 0.4311 | validation: 0.4257\r",
      "(1698 / 10000) training: 0.4311 | validation: 0.4257\r",
      "(1699 / 10000) training: 0.4311 | validation: 0.4257\r",
      "(1700 / 10000) training: 0.4311 | validation: 0.4257\r",
      "(1701 / 10000) training: 0.4310 | validation: 0.4257\r",
      "(1702 / 10000) training: 0.4310 | validation: 0.4257\r",
      "(1703 / 10000) training: 0.4310 | validation: 0.4256\r",
      "(1704 / 10000) training: 0.4310 | validation: 0.4256\r",
      "(1705 / 10000) training: 0.4310 | validation: 0.4256\r",
      "(1706 / 10000) training: 0.4310 | validation: 0.4256\r",
      "(1707 / 10000) training: 0.4310 | validation: 0.4256\r",
      "(1708 / 10000) training: 0.4309 | validation: 0.4256\r",
      "(1709 / 10000) training: 0.4309 | validation: 0.4255\r",
      "(1710 / 10000) training: 0.4309 | validation: 0.4255\r",
      "(1711 / 10000) training: 0.4309 | validation: 0.4255\r",
      "(1712 / 10000) training: 0.4309 | validation: 0.4255\r",
      "(1713 / 10000) training: 0.4309 | validation: 0.4255\r",
      "(1714 / 10000) training: 0.4309 | validation: 0.4255\r",
      "(1715 / 10000) training: 0.4308 | validation: 0.4255\r",
      "(1716 / 10000) training: 0.4308 | validation: 0.4254\r",
      "(1717 / 10000) training: 0.4308 | validation: 0.4254\r",
      "(1718 / 10000) training: 0.4308 | validation: 0.4254\r",
      "(1719 / 10000) training: 0.4308 | validation: 0.4254\r",
      "(1720 / 10000) training: 0.4308 | validation: 0.4254\r",
      "(1721 / 10000) training: 0.4308 | validation: 0.4254\r",
      "(1722 / 10000) training: 0.4307 | validation: 0.4254\r",
      "(1723 / 10000) training: 0.4307 | validation: 0.4253\r",
      "(1724 / 10000) training: 0.4307 | validation: 0.4253\r",
      "(1725 / 10000) training: 0.4307 | validation: 0.4253\r",
      "(1726 / 10000) training: 0.4307 | validation: 0.4253\r",
      "(1727 / 10000) training: 0.4307 | validation: 0.4253\r",
      "(1728 / 10000) training: 0.4307 | validation: 0.4253\r",
      "(1729 / 10000) training: 0.4306 | validation: 0.4253\r",
      "(1730 / 10000) training: 0.4306 | validation: 0.4252\r",
      "(1731 / 10000) training: 0.4306 | validation: 0.4252\r",
      "(1732 / 10000) training: 0.4306 | validation: 0.4252\r",
      "(1733 / 10000) training: 0.4306 | validation: 0.4252\r",
      "(1734 / 10000) training: 0.4306 | validation: 0.4252\r",
      "(1735 / 10000) training: 0.4306 | validation: 0.4252\r",
      "(1736 / 10000) training: 0.4305 | validation: 0.4252\r",
      "(1737 / 10000) training: 0.4305 | validation: 0.4251\r",
      "(1738 / 10000) training: 0.4305 | validation: 0.4251\r",
      "(1739 / 10000) training: 0.4305 | validation: 0.4251"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "(1740 / 10000) training: 0.4305 | validation: 0.4251\r",
      "(1741 / 10000) training: 0.4305 | validation: 0.4251\r",
      "(1742 / 10000) training: 0.4305 | validation: 0.4251\r",
      "(1743 / 10000) training: 0.4304 | validation: 0.4251\r",
      "(1744 / 10000) training: 0.4304 | validation: 0.4250\r",
      "(1745 / 10000) training: 0.4304 | validation: 0.4250\r",
      "(1746 / 10000) training: 0.4304 | validation: 0.4250\r",
      "(1747 / 10000) training: 0.4304 | validation: 0.4250\r",
      "(1748 / 10000) training: 0.4304 | validation: 0.4250\r",
      "(1749 / 10000) training: 0.4304 | validation: 0.4250\r",
      "(1750 / 10000) training: 0.4304 | validation: 0.4250\r",
      "(1751 / 10000) training: 0.4303 | validation: 0.4249\r",
      "(1752 / 10000) training: 0.4303 | validation: 0.4249\r",
      "(1753 / 10000) training: 0.4303 | validation: 0.4249\r",
      "(1754 / 10000) training: 0.4303 | validation: 0.4249\r",
      "(1755 / 10000) training: 0.4303 | validation: 0.4249\r",
      "(1756 / 10000) training: 0.4303 | validation: 0.4249\r",
      "(1757 / 10000) training: 0.4303 | validation: 0.4249\r",
      "(1758 / 10000) training: 0.4302 | validation: 0.4248\r",
      "(1759 / 10000) training: 0.4302 | validation: 0.4248\r",
      "(1760 / 10000) training: 0.4302 | validation: 0.4248\r",
      "(1761 / 10000) training: 0.4302 | validation: 0.4248\r",
      "(1762 / 10000) training: 0.4302 | validation: 0.4248\r",
      "(1763 / 10000) training: 0.4302 | validation: 0.4248\r",
      "(1764 / 10000) training: 0.4302 | validation: 0.4248\r",
      "(1765 / 10000) training: 0.4301 | validation: 0.4247\r",
      "(1766 / 10000) training: 0.4301 | validation: 0.4247\r",
      "(1767 / 10000) training: 0.4301 | validation: 0.4247\r",
      "(1768 / 10000) training: 0.4301 | validation: 0.4247\r",
      "(1769 / 10000) training: 0.4301 | validation: 0.4247\r",
      "(1770 / 10000) training: 0.4301 | validation: 0.4247\r",
      "(1771 / 10000) training: 0.4301 | validation: 0.4247\r",
      "(1772 / 10000) training: 0.4301 | validation: 0.4246\r",
      "(1773 / 10000) training: 0.4300 | validation: 0.4246\r",
      "(1774 / 10000) training: 0.4300 | validation: 0.4246\r",
      "(1775 / 10000) training: 0.4300 | validation: 0.4246\r",
      "(1776 / 10000) training: 0.4300 | validation: 0.4246\r",
      "(1777 / 10000) training: 0.4300 | validation: 0.4246\r",
      "(1778 / 10000) training: 0.4300 | validation: 0.4246\r",
      "(1779 / 10000) training: 0.4300 | validation: 0.4246\r",
      "(1780 / 10000) training: 0.4299 | validation: 0.4245\r",
      "(1781 / 10000) training: 0.4299 | validation: 0.4245\r",
      "(1782 / 10000) training: 0.4299 | validation: 0.4245\r",
      "(1783 / 10000) training: 0.4299 | validation: 0.4245\r",
      "(1784 / 10000) training: 0.4299 | validation: 0.4245\r",
      "(1785 / 10000) training: 0.4299 | validation: 0.4245\r",
      "(1786 / 10000) training: 0.4299 | validation: 0.4245\r",
      "(1787 / 10000) training: 0.4299 | validation: 0.4244\r",
      "(1788 / 10000) training: 0.4298 | validation: 0.4244\r",
      "(1789 / 10000) training: 0.4298 | validation: 0.4244\r",
      "(1790 / 10000) training: 0.4298 | validation: 0.4244\r",
      "(1791 / 10000) training: 0.4298 | validation: 0.4244\r",
      "(1792 / 10000) training: 0.4298 | validation: 0.4244\r",
      "(1793 / 10000) training: 0.4298 | validation: 0.4244\r",
      "(1794 / 10000) training: 0.4298 | validation: 0.4243\r",
      "(1795 / 10000) training: 0.4297 | validation: 0.4243\r",
      "(1796 / 10000) training: 0.4297 | validation: 0.4243\r",
      "(1797 / 10000) training: 0.4297 | validation: 0.4243\r",
      "(1798 / 10000) training: 0.4297 | validation: 0.4243\r",
      "(1799 / 10000) training: 0.4297 | validation: 0.4243\r",
      "(1800 / 10000) training: 0.4297 | validation: 0.4243\r",
      "(1801 / 10000) training: 0.4297 | validation: 0.4243\r",
      "(1802 / 10000) training: 0.4297 | validation: 0.4242\r",
      "(1803 / 10000) training: 0.4296 | validation: 0.4242\r",
      "(1804 / 10000) training: 0.4296 | validation: 0.4242\r",
      "(1805 / 10000) training: 0.4296 | validation: 0.4242\r",
      "(1806 / 10000) training: 0.4296 | validation: 0.4242\r",
      "(1807 / 10000) training: 0.4296 | validation: 0.4242\r",
      "(1808 / 10000) training: 0.4296 | validation: 0.4242\r",
      "(1809 / 10000) training: 0.4296 | validation: 0.4241\r",
      "(1810 / 10000) training: 0.4295 | validation: 0.4241\r",
      "(1811 / 10000) training: 0.4295 | validation: 0.4241\r",
      "(1812 / 10000) training: 0.4295 | validation: 0.4241\r",
      "(1813 / 10000) training: 0.4295 | validation: 0.4241\r",
      "(1814 / 10000) training: 0.4295 | validation: 0.4241\r",
      "(1815 / 10000) training: 0.4295 | validation: 0.4241\r",
      "(1816 / 10000) training: 0.4295 | validation: 0.4241\r",
      "(1817 / 10000) training: 0.4295 | validation: 0.4240\r",
      "(1818 / 10000) training: 0.4294 | validation: 0.4240\r",
      "(1819 / 10000) training: 0.4294 | validation: 0.4240\r",
      "(1820 / 10000) training: 0.4294 | validation: 0.4240\r",
      "(1821 / 10000) training: 0.4294 | validation: 0.4240\r",
      "(1822 / 10000) training: 0.4294 | validation: 0.4240\r",
      "(1823 / 10000) training: 0.4294 | validation: 0.4240\r",
      "(1824 / 10000) training: 0.4294 | validation: 0.4240\r",
      "(1825 / 10000) training: 0.4294 | validation: 0.4239\r",
      "(1826 / 10000) training: 0.4293 | validation: 0.4239\r",
      "(1827 / 10000) training: 0.4293 | validation: 0.4239\r",
      "(1828 / 10000) training: 0.4293 | validation: 0.4239\r",
      "(1829 / 10000) training: 0.4293 | validation: 0.4239\r",
      "(1830 / 10000) training: 0.4293 | validation: 0.4239\r",
      "(1831 / 10000) training: 0.4293 | validation: 0.4239\r",
      "(1832 / 10000) training: 0.4293 | validation: 0.4238\r",
      "(1833 / 10000) training: 0.4293 | validation: 0.4238\r",
      "(1834 / 10000) training: 0.4292 | validation: 0.4238\r",
      "(1835 / 10000) training: 0.4292 | validation: 0.4238\r",
      "(1836 / 10000) training: 0.4292 | validation: 0.4238\r",
      "(1837 / 10000) training: 0.4292 | validation: 0.4238\r",
      "(1838 / 10000) training: 0.4292 | validation: 0.4238\r",
      "(1839 / 10000) training: 0.4292 | validation: 0.4238\r",
      "(1840 / 10000) training: 0.4292 | validation: 0.4237\r",
      "(1841 / 10000) training: 0.4292 | validation: 0.4237\r",
      "(1842 / 10000) training: 0.4291 | validation: 0.4237\r",
      "(1843 / 10000) training: 0.4291 | validation: 0.4237\r",
      "(1844 / 10000) training: 0.4291 | validation: 0.4237\r",
      "(1845 / 10000) training: 0.4291 | validation: 0.4237\r",
      "(1846 / 10000) training: 0.4291 | validation: 0.4237\r",
      "(1847 / 10000) training: 0.4291 | validation: 0.4237\r",
      "(1848 / 10000) training: 0.4291 | validation: 0.4236\r",
      "(1849 / 10000) training: 0.4291 | validation: 0.4236\r",
      "(1850 / 10000) training: 0.4290 | validation: 0.4236\r",
      "(1851 / 10000) training: 0.4290 | validation: 0.4236\r",
      "(1852 / 10000) training: 0.4290 | validation: 0.4236\r",
      "(1853 / 10000) training: 0.4290 | validation: 0.4236\r",
      "(1854 / 10000) training: 0.4290 | validation: 0.4236\r",
      "(1855 / 10000) training: 0.4290 | validation: 0.4236\r",
      "(1856 / 10000) training: 0.4290 | validation: 0.4235\r",
      "(1857 / 10000) training: 0.4290 | validation: 0.4235\r",
      "(1858 / 10000) training: 0.4289 | validation: 0.4235\r",
      "(1859 / 10000) training: 0.4289 | validation: 0.4235\r",
      "(1860 / 10000) training: 0.4289 | validation: 0.4235\r",
      "(1861 / 10000) training: 0.4289 | validation: 0.4235\r",
      "(1862 / 10000) training: 0.4289 | validation: 0.4235\r",
      "(1863 / 10000) training: 0.4289 | validation: 0.4235\r",
      "(1864 / 10000) training: 0.4289 | validation: 0.4234\r",
      "(1865 / 10000) training: 0.4289 | validation: 0.4234\r",
      "(1866 / 10000) training: 0.4288 | validation: 0.4234\r",
      "(1867 / 10000) training: 0.4288 | validation: 0.4234\r",
      "(1868 / 10000) training: 0.4288 | validation: 0.4234\r",
      "(1869 / 10000) training: 0.4288 | validation: 0.4234\r",
      "(1870 / 10000) training: 0.4288 | validation: 0.4234\r",
      "(1871 / 10000) training: 0.4288 | validation: 0.4234\r",
      "(1872 / 10000) training: 0.4288 | validation: 0.4233\r",
      "(1873 / 10000) training: 0.4288 | validation: 0.4233\r",
      "(1874 / 10000) training: 0.4287 | validation: 0.4233\r",
      "(1875 / 10000) training: 0.4287 | validation: 0.4233\r",
      "(1876 / 10000) training: 0.4287 | validation: 0.4233\r",
      "(1877 / 10000) training: 0.4287 | validation: 0.4233\r",
      "(1878 / 10000) training: 0.4287 | validation: 0.4233\r",
      "(1879 / 10000) training: 0.4287 | validation: 0.4233\r",
      "(1880 / 10000) training: 0.4287 | validation: 0.4232\r",
      "(1881 / 10000) training: 0.4287 | validation: 0.4232\r",
      "(1882 / 10000) training: 0.4286 | validation: 0.4232\r",
      "(1883 / 10000) training: 0.4286 | validation: 0.4232\r",
      "(1884 / 10000) training: 0.4286 | validation: 0.4232\r",
      "(1885 / 10000) training: 0.4286 | validation: 0.4232\r",
      "(1886 / 10000) training: 0.4286 | validation: 0.4232\r",
      "(1887 / 10000) training: 0.4286 | validation: 0.4232\r",
      "(1888 / 10000) training: 0.4286 | validation: 0.4231\r",
      "(1889 / 10000) training: 0.4286 | validation: 0.4231\r",
      "(1890 / 10000) training: 0.4286 | validation: 0.4231\r",
      "(1891 / 10000) training: 0.4285 | validation: 0.4231\r",
      "(1892 / 10000) training: 0.4285 | validation: 0.4231\r",
      "(1893 / 10000) training: 0.4285 | validation: 0.4231\r",
      "(1894 / 10000) training: 0.4285 | validation: 0.4231\r",
      "(1895 / 10000) training: 0.4285 | validation: 0.4231\r",
      "(1896 / 10000) training: 0.4285 | validation: 0.4230\r",
      "(1897 / 10000) training: 0.4285 | validation: 0.4230\r",
      "(1898 / 10000) training: 0.4285 | validation: 0.4230\r",
      "(1899 / 10000) training: 0.4284 | validation: 0.4230\r",
      "(1900 / 10000) training: 0.4284 | validation: 0.4230\r",
      "(1901 / 10000) training: 0.4284 | validation: 0.4230\r",
      "(1902 / 10000) training: 0.4284 | validation: 0.4230\r",
      "(1903 / 10000) training: 0.4284 | validation: 0.4230\r",
      "(1904 / 10000) training: 0.4284 | validation: 0.4229\r",
      "(1905 / 10000) training: 0.4284 | validation: 0.4229\r",
      "(1906 / 10000) training: 0.4284 | validation: 0.4229\r",
      "(1907 / 10000) training: 0.4284 | validation: 0.4229\r",
      "(1908 / 10000) training: 0.4283 | validation: 0.4229\r",
      "(1909 / 10000) training: 0.4283 | validation: 0.4229\r",
      "(1910 / 10000) training: 0.4283 | validation: 0.4229\r",
      "(1911 / 10000) training: 0.4283 | validation: 0.4229\r",
      "(1912 / 10000) training: 0.4283 | validation: 0.4228\r",
      "(1913 / 10000) training: 0.4283 | validation: 0.4228\r",
      "(1914 / 10000) training: 0.4283 | validation: 0.4228\r",
      "(1915 / 10000) training: 0.4283 | validation: 0.4228\r",
      "(1916 / 10000) training: 0.4282 | validation: 0.4228\r",
      "(1917 / 10000) training: 0.4282 | validation: 0.4228\r",
      "(1918 / 10000) training: 0.4282 | validation: 0.4228\r",
      "(1919 / 10000) training: 0.4282 | validation: 0.4228\r",
      "(1920 / 10000) training: 0.4282 | validation: 0.4228\r",
      "(1921 / 10000) training: 0.4282 | validation: 0.4227\r",
      "(1922 / 10000) training: 0.4282 | validation: 0.4227\r",
      "(1923 / 10000) training: 0.4282 | validation: 0.4227\r",
      "(1924 / 10000) training: 0.4282 | validation: 0.4227\r",
      "(1925 / 10000) training: 0.4281 | validation: 0.4227\r",
      "(1926 / 10000) training: 0.4281 | validation: 0.4227\r",
      "(1927 / 10000) training: 0.4281 | validation: 0.4227\r",
      "(1928 / 10000) training: 0.4281 | validation: 0.4227\r",
      "(1929 / 10000) training: 0.4281 | validation: 0.4226\r",
      "(1930 / 10000) training: 0.4281 | validation: 0.4226\r",
      "(1931 / 10000) training: 0.4281 | validation: 0.4226\r",
      "(1932 / 10000) training: 0.4281 | validation: 0.4226\r",
      "(1933 / 10000) training: 0.4281 | validation: 0.4226\r",
      "(1934 / 10000) training: 0.4280 | validation: 0.4226\r",
      "(1935 / 10000) training: 0.4280 | validation: 0.4226"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "(1936 / 10000) training: 0.4280 | validation: 0.4226\r",
      "(1937 / 10000) training: 0.4280 | validation: 0.4226\r",
      "(1938 / 10000) training: 0.4280 | validation: 0.4225\r",
      "(1939 / 10000) training: 0.4280 | validation: 0.4225\r",
      "(1940 / 10000) training: 0.4280 | validation: 0.4225\r",
      "(1941 / 10000) training: 0.4280 | validation: 0.4225\r",
      "(1942 / 10000) training: 0.4279 | validation: 0.4225\r",
      "(1943 / 10000) training: 0.4279 | validation: 0.4225\r",
      "(1944 / 10000) training: 0.4279 | validation: 0.4225\r",
      "(1945 / 10000) training: 0.4279 | validation: 0.4225\r",
      "(1946 / 10000) training: 0.4279 | validation: 0.4224\r",
      "(1947 / 10000) training: 0.4279 | validation: 0.4224\r",
      "(1948 / 10000) training: 0.4279 | validation: 0.4224\r",
      "(1949 / 10000) training: 0.4279 | validation: 0.4224\r",
      "(1950 / 10000) training: 0.4279 | validation: 0.4224\r",
      "(1951 / 10000) training: 0.4278 | validation: 0.4224\r",
      "(1952 / 10000) training: 0.4278 | validation: 0.4224\r",
      "(1953 / 10000) training: 0.4278 | validation: 0.4224\r",
      "(1954 / 10000) training: 0.4278 | validation: 0.4224\r",
      "(1955 / 10000) training: 0.4278 | validation: 0.4223\r",
      "(1956 / 10000) training: 0.4278 | validation: 0.4223\r",
      "(1957 / 10000) training: 0.4278 | validation: 0.4223\r",
      "(1958 / 10000) training: 0.4278 | validation: 0.4223\r",
      "(1959 / 10000) training: 0.4278 | validation: 0.4223\r",
      "(1960 / 10000) training: 0.4277 | validation: 0.4223\r",
      "(1961 / 10000) training: 0.4277 | validation: 0.4223\r",
      "(1962 / 10000) training: 0.4277 | validation: 0.4223\r",
      "(1963 / 10000) training: 0.4277 | validation: 0.4223\r",
      "(1964 / 10000) training: 0.4277 | validation: 0.4222\r",
      "(1965 / 10000) training: 0.4277 | validation: 0.4222\r",
      "(1966 / 10000) training: 0.4277 | validation: 0.4222\r",
      "(1967 / 10000) training: 0.4277 | validation: 0.4222\r",
      "(1968 / 10000) training: 0.4277 | validation: 0.4222\r",
      "(1969 / 10000) training: 0.4276 | validation: 0.4222\r",
      "(1970 / 10000) training: 0.4276 | validation: 0.4222\r",
      "(1971 / 10000) training: 0.4276 | validation: 0.4222\r",
      "(1972 / 10000) training: 0.4276 | validation: 0.4222\r",
      "(1973 / 10000) training: 0.4276 | validation: 0.4221\r",
      "(1974 / 10000) training: 0.4276 | validation: 0.4221\r",
      "(1975 / 10000) training: 0.4276 | validation: 0.4221\r",
      "(1976 / 10000) training: 0.4276 | validation: 0.4221\r",
      "(1977 / 10000) training: 0.4276 | validation: 0.4221\r",
      "(1978 / 10000) training: 0.4276 | validation: 0.4221\r",
      "(1979 / 10000) training: 0.4275 | validation: 0.4221\r",
      "(1980 / 10000) training: 0.4275 | validation: 0.4221\r",
      "(1981 / 10000) training: 0.4275 | validation: 0.4221\r",
      "(1982 / 10000) training: 0.4275 | validation: 0.4220\r",
      "(1983 / 10000) training: 0.4275 | validation: 0.4220\r",
      "(1984 / 10000) training: 0.4275 | validation: 0.4220\r",
      "(1985 / 10000) training: 0.4275 | validation: 0.4220\r",
      "(1986 / 10000) training: 0.4275 | validation: 0.4220\r",
      "(1987 / 10000) training: 0.4275 | validation: 0.4220\r",
      "(1988 / 10000) training: 0.4274 | validation: 0.4220\r",
      "(1989 / 10000) training: 0.4274 | validation: 0.4220\r",
      "(1990 / 10000) training: 0.4274 | validation: 0.4220\r",
      "(1991 / 10000) training: 0.4274 | validation: 0.4219\r",
      "(1992 / 10000) training: 0.4274 | validation: 0.4219\r",
      "(1993 / 10000) training: 0.4274 | validation: 0.4219\r",
      "(1994 / 10000) training: 0.4274 | validation: 0.4219\r",
      "(1995 / 10000) training: 0.4274 | validation: 0.4219\r",
      "(1996 / 10000) training: 0.4274 | validation: 0.4219\r",
      "(1997 / 10000) training: 0.4273 | validation: 0.4219\r",
      "(1998 / 10000) training: 0.4273 | validation: 0.4219\r",
      "(1999 / 10000) training: 0.4273 | validation: 0.4219\r",
      "(2000 / 10000) training: 0.4273 | validation: 0.4218\r",
      "(2001 / 10000) training: 0.4273 | validation: 0.4218\r",
      "(2002 / 10000) training: 0.4273 | validation: 0.4218\r",
      "(2003 / 10000) training: 0.4273 | validation: 0.4218\r",
      "(2004 / 10000) training: 0.4273 | validation: 0.4218\r",
      "(2005 / 10000) training: 0.4273 | validation: 0.4218\r",
      "(2006 / 10000) training: 0.4272 | validation: 0.4218\r",
      "(2007 / 10000) training: 0.4272 | validation: 0.4218\r",
      "(2008 / 10000) training: 0.4272 | validation: 0.4218\r",
      "(2009 / 10000) training: 0.4272 | validation: 0.4217\r",
      "(2010 / 10000) training: 0.4272 | validation: 0.4217\r",
      "(2011 / 10000) training: 0.4272 | validation: 0.4217\r",
      "(2012 / 10000) training: 0.4272 | validation: 0.4217\r",
      "(2013 / 10000) training: 0.4272 | validation: 0.4217\r",
      "(2014 / 10000) training: 0.4272 | validation: 0.4217\r",
      "(2015 / 10000) training: 0.4272 | validation: 0.4217\r",
      "(2016 / 10000) training: 0.4271 | validation: 0.4217\r",
      "(2017 / 10000) training: 0.4271 | validation: 0.4217\r",
      "(2018 / 10000) training: 0.4271 | validation: 0.4216\r",
      "(2019 / 10000) training: 0.4271 | validation: 0.4216\r",
      "(2020 / 10000) training: 0.4271 | validation: 0.4216\r",
      "(2021 / 10000) training: 0.4271 | validation: 0.4216\r",
      "(2022 / 10000) training: 0.4271 | validation: 0.4216\r",
      "(2023 / 10000) training: 0.4271 | validation: 0.4216\r",
      "(2024 / 10000) training: 0.4271 | validation: 0.4216\r",
      "(2025 / 10000) training: 0.4271 | validation: 0.4216\r",
      "(2026 / 10000) training: 0.4270 | validation: 0.4216\r",
      "(2027 / 10000) training: 0.4270 | validation: 0.4215\r",
      "(2028 / 10000) training: 0.4270 | validation: 0.4215\r",
      "(2029 / 10000) training: 0.4270 | validation: 0.4215\r",
      "(2030 / 10000) training: 0.4270 | validation: 0.4215\r",
      "(2031 / 10000) training: 0.4270 | validation: 0.4215\r",
      "(2032 / 10000) training: 0.4270 | validation: 0.4215\r",
      "(2033 / 10000) training: 0.4270 | validation: 0.4215\r",
      "(2034 / 10000) training: 0.4270 | validation: 0.4215\r",
      "(2035 / 10000) training: 0.4269 | validation: 0.4215\r",
      "(2036 / 10000) training: 0.4269 | validation: 0.4215\r",
      "(2037 / 10000) training: 0.4269 | validation: 0.4214\r",
      "(2038 / 10000) training: 0.4269 | validation: 0.4214\r",
      "(2039 / 10000) training: 0.4269 | validation: 0.4214\r",
      "(2040 / 10000) training: 0.4269 | validation: 0.4214\r",
      "(2041 / 10000) training: 0.4269 | validation: 0.4214\r",
      "(2042 / 10000) training: 0.4269 | validation: 0.4214\r",
      "(2043 / 10000) training: 0.4269 | validation: 0.4214\r",
      "(2044 / 10000) training: 0.4269 | validation: 0.4214\r",
      "(2045 / 10000) training: 0.4268 | validation: 0.4214\r",
      "(2046 / 10000) training: 0.4268 | validation: 0.4213\r",
      "(2047 / 10000) training: 0.4268 | validation: 0.4213\r",
      "(2048 / 10000) training: 0.4268 | validation: 0.4213\r",
      "(2049 / 10000) training: 0.4268 | validation: 0.4213\r",
      "(2050 / 10000) training: 0.4268 | validation: 0.4213\r",
      "(2051 / 10000) training: 0.4268 | validation: 0.4213\r",
      "(2052 / 10000) training: 0.4268 | validation: 0.4213\r",
      "(2053 / 10000) training: 0.4268 | validation: 0.4213\r",
      "(2054 / 10000) training: 0.4268 | validation: 0.4213\r",
      "(2055 / 10000) training: 0.4267 | validation: 0.4213\r",
      "(2056 / 10000) training: 0.4267 | validation: 0.4212\r",
      "(2057 / 10000) training: 0.4267 | validation: 0.4212\r",
      "(2058 / 10000) training: 0.4267 | validation: 0.4212\r",
      "(2059 / 10000) training: 0.4267 | validation: 0.4212\r",
      "(2060 / 10000) training: 0.4267 | validation: 0.4212\r",
      "(2061 / 10000) training: 0.4267 | validation: 0.4212\r",
      "(2062 / 10000) training: 0.4267 | validation: 0.4212\r",
      "(2063 / 10000) training: 0.4267 | validation: 0.4212\r",
      "(2064 / 10000) training: 0.4267 | validation: 0.4212\r",
      "(2065 / 10000) training: 0.4266 | validation: 0.4212\r",
      "(2066 / 10000) training: 0.4266 | validation: 0.4211\r",
      "(2067 / 10000) training: 0.4266 | validation: 0.4211\r",
      "(2068 / 10000) training: 0.4266 | validation: 0.4211\r",
      "(2069 / 10000) training: 0.4266 | validation: 0.4211\r",
      "(2070 / 10000) training: 0.4266 | validation: 0.4211\r",
      "(2071 / 10000) training: 0.4266 | validation: 0.4211\r",
      "(2072 / 10000) training: 0.4266 | validation: 0.4211\r",
      "(2073 / 10000) training: 0.4266 | validation: 0.4211\r",
      "(2074 / 10000) training: 0.4266 | validation: 0.4211\r",
      "(2075 / 10000) training: 0.4265 | validation: 0.4211\r",
      "(2076 / 10000) training: 0.4265 | validation: 0.4210\r",
      "(2077 / 10000) training: 0.4265 | validation: 0.4210\r",
      "(2078 / 10000) training: 0.4265 | validation: 0.4210\r",
      "(2079 / 10000) training: 0.4265 | validation: 0.4210\r",
      "(2080 / 10000) training: 0.4265 | validation: 0.4210\r",
      "(2081 / 10000) training: 0.4265 | validation: 0.4210\r",
      "(2082 / 10000) training: 0.4265 | validation: 0.4210\r",
      "(2083 / 10000) training: 0.4265 | validation: 0.4210\r",
      "(2084 / 10000) training: 0.4265 | validation: 0.4210\r",
      "(2085 / 10000) training: 0.4264 | validation: 0.4209\r",
      "(2086 / 10000) training: 0.4264 | validation: 0.4209\r",
      "(2087 / 10000) training: 0.4264 | validation: 0.4209\r",
      "(2088 / 10000) training: 0.4264 | validation: 0.4209\r",
      "(2089 / 10000) training: 0.4264 | validation: 0.4209\r",
      "(2090 / 10000) training: 0.4264 | validation: 0.4209\r",
      "(2091 / 10000) training: 0.4264 | validation: 0.4209\r",
      "(2092 / 10000) training: 0.4264 | validation: 0.4209\r",
      "(2093 / 10000) training: 0.4264 | validation: 0.4209\r",
      "(2094 / 10000) training: 0.4264 | validation: 0.4209\r",
      "(2095 / 10000) training: 0.4263 | validation: 0.4208\r",
      "(2096 / 10000) training: 0.4263 | validation: 0.4208\r",
      "(2097 / 10000) training: 0.4263 | validation: 0.4208\r",
      "(2098 / 10000) training: 0.4263 | validation: 0.4208\r",
      "(2099 / 10000) training: 0.4263 | validation: 0.4208\r",
      "(2100 / 10000) training: 0.4263 | validation: 0.4208\r",
      "(2101 / 10000) training: 0.4263 | validation: 0.4208\r",
      "(2102 / 10000) training: 0.4263 | validation: 0.4208\r",
      "(2103 / 10000) training: 0.4263 | validation: 0.4208\r",
      "(2104 / 10000) training: 0.4263 | validation: 0.4208\r",
      "(2105 / 10000) training: 0.4263 | validation: 0.4208\r",
      "(2106 / 10000) training: 0.4262 | validation: 0.4207\r",
      "(2107 / 10000) training: 0.4262 | validation: 0.4207\r",
      "(2108 / 10000) training: 0.4262 | validation: 0.4207\r",
      "(2109 / 10000) training: 0.4262 | validation: 0.4207\r",
      "(2110 / 10000) training: 0.4262 | validation: 0.4207\r",
      "(2111 / 10000) training: 0.4262 | validation: 0.4207\r",
      "(2112 / 10000) training: 0.4262 | validation: 0.4207\r",
      "(2113 / 10000) training: 0.4262 | validation: 0.4207\r",
      "(2114 / 10000) training: 0.4262 | validation: 0.4207\r",
      "(2115 / 10000) training: 0.4262 | validation: 0.4207\r",
      "(2116 / 10000) training: 0.4261 | validation: 0.4206\r",
      "(2117 / 10000) training: 0.4261 | validation: 0.4206\r",
      "(2118 / 10000) training: 0.4261 | validation: 0.4206\r",
      "(2119 / 10000) training: 0.4261 | validation: 0.4206\r",
      "(2120 / 10000) training: 0.4261 | validation: 0.4206\r",
      "(2121 / 10000) training: 0.4261 | validation: 0.4206\r",
      "(2122 / 10000) training: 0.4261 | validation: 0.4206\r",
      "(2123 / 10000) training: 0.4261 | validation: 0.4206\r",
      "(2124 / 10000) training: 0.4261 | validation: 0.4206\r",
      "(2125 / 10000) training: 0.4261 | validation: 0.4206\r",
      "(2126 / 10000) training: 0.4261 | validation: 0.4205\r",
      "(2127 / 10000) training: 0.4260 | validation: 0.4205\r",
      "(2128 / 10000) training: 0.4260 | validation: 0.4205\r",
      "(2129 / 10000) training: 0.4260 | validation: 0.4205\r",
      "(2130 / 10000) training: 0.4260 | validation: 0.4205\r",
      "(2131 / 10000) training: 0.4260 | validation: 0.4205\r",
      "(2132 / 10000) training: 0.4260 | validation: 0.4205"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "(2133 / 10000) training: 0.4260 | validation: 0.4205\r",
      "(2134 / 10000) training: 0.4260 | validation: 0.4205\r",
      "(2135 / 10000) training: 0.4260 | validation: 0.4205\r",
      "(2136 / 10000) training: 0.4260 | validation: 0.4204\r",
      "(2137 / 10000) training: 0.4260 | validation: 0.4204\r",
      "(2138 / 10000) training: 0.4259 | validation: 0.4204\r",
      "(2139 / 10000) training: 0.4259 | validation: 0.4204\r",
      "(2140 / 10000) training: 0.4259 | validation: 0.4204\r",
      "(2141 / 10000) training: 0.4259 | validation: 0.4204\r",
      "(2142 / 10000) training: 0.4259 | validation: 0.4204\r",
      "(2143 / 10000) training: 0.4259 | validation: 0.4204\r",
      "(2144 / 10000) training: 0.4259 | validation: 0.4204\r",
      "(2145 / 10000) training: 0.4259 | validation: 0.4204\r",
      "(2146 / 10000) training: 0.4259 | validation: 0.4204\r",
      "(2147 / 10000) training: 0.4259 | validation: 0.4203\r",
      "(2148 / 10000) training: 0.4259 | validation: 0.4203\r",
      "(2149 / 10000) training: 0.4258 | validation: 0.4203\r",
      "(2150 / 10000) training: 0.4258 | validation: 0.4203\r",
      "(2151 / 10000) training: 0.4258 | validation: 0.4203\r",
      "(2152 / 10000) training: 0.4258 | validation: 0.4203\r",
      "(2153 / 10000) training: 0.4258 | validation: 0.4203\r",
      "(2154 / 10000) training: 0.4258 | validation: 0.4203\r",
      "(2155 / 10000) training: 0.4258 | validation: 0.4203\r",
      "(2156 / 10000) training: 0.4258 | validation: 0.4203\r",
      "(2157 / 10000) training: 0.4258 | validation: 0.4203\r",
      "(2158 / 10000) training: 0.4258 | validation: 0.4202\r",
      "(2159 / 10000) training: 0.4258 | validation: 0.4202\r",
      "(2160 / 10000) training: 0.4257 | validation: 0.4202\r",
      "(2161 / 10000) training: 0.4257 | validation: 0.4202\r",
      "(2162 / 10000) training: 0.4257 | validation: 0.4202\r",
      "(2163 / 10000) training: 0.4257 | validation: 0.4202\r",
      "(2164 / 10000) training: 0.4257 | validation: 0.4202\r",
      "(2165 / 10000) training: 0.4257 | validation: 0.4202\r",
      "(2166 / 10000) training: 0.4257 | validation: 0.4202\r",
      "(2167 / 10000) training: 0.4257 | validation: 0.4202\r",
      "(2168 / 10000) training: 0.4257 | validation: 0.4201\r",
      "(2169 / 10000) training: 0.4257 | validation: 0.4201\r",
      "(2170 / 10000) training: 0.4257 | validation: 0.4201\r",
      "(2171 / 10000) training: 0.4256 | validation: 0.4201\r",
      "(2172 / 10000) training: 0.4256 | validation: 0.4201\r",
      "(2173 / 10000) training: 0.4256 | validation: 0.4201\r",
      "(2174 / 10000) training: 0.4256 | validation: 0.4201\r",
      "(2175 / 10000) training: 0.4256 | validation: 0.4201\r",
      "(2176 / 10000) training: 0.4256 | validation: 0.4201\r",
      "(2177 / 10000) training: 0.4256 | validation: 0.4201\r",
      "(2178 / 10000) training: 0.4256 | validation: 0.4201\r",
      "(2179 / 10000) training: 0.4256 | validation: 0.4200\r",
      "(2180 / 10000) training: 0.4256 | validation: 0.4200\r",
      "(2181 / 10000) training: 0.4256 | validation: 0.4200\r",
      "(2182 / 10000) training: 0.4255 | validation: 0.4200\r",
      "(2183 / 10000) training: 0.4255 | validation: 0.4200\r",
      "(2184 / 10000) training: 0.4255 | validation: 0.4200\r",
      "(2185 / 10000) training: 0.4255 | validation: 0.4200\r",
      "(2186 / 10000) training: 0.4255 | validation: 0.4200\r",
      "(2187 / 10000) training: 0.4255 | validation: 0.4200\r",
      "(2188 / 10000) training: 0.4255 | validation: 0.4200\r",
      "(2189 / 10000) training: 0.4255 | validation: 0.4200\r",
      "(2190 / 10000) training: 0.4255 | validation: 0.4199\r",
      "(2191 / 10000) training: 0.4255 | validation: 0.4199\r",
      "(2192 / 10000) training: 0.4255 | validation: 0.4199\r",
      "(2193 / 10000) training: 0.4254 | validation: 0.4199\r",
      "(2194 / 10000) training: 0.4254 | validation: 0.4199\r",
      "(2195 / 10000) training: 0.4254 | validation: 0.4199\r",
      "(2196 / 10000) training: 0.4254 | validation: 0.4199\r",
      "(2197 / 10000) training: 0.4254 | validation: 0.4199\r",
      "(2198 / 10000) training: 0.4254 | validation: 0.4199\r",
      "(2199 / 10000) training: 0.4254 | validation: 0.4199\r",
      "(2200 / 10000) training: 0.4254 | validation: 0.4199\r",
      "(2201 / 10000) training: 0.4254 | validation: 0.4198\r",
      "(2202 / 10000) training: 0.4254 | validation: 0.4198\r",
      "(2203 / 10000) training: 0.4254 | validation: 0.4198\r",
      "(2204 / 10000) training: 0.4254 | validation: 0.4198\r",
      "(2205 / 10000) training: 0.4253 | validation: 0.4198\r",
      "(2206 / 10000) training: 0.4253 | validation: 0.4198\r",
      "(2207 / 10000) training: 0.4253 | validation: 0.4198\r",
      "(2208 / 10000) training: 0.4253 | validation: 0.4198\r",
      "(2209 / 10000) training: 0.4253 | validation: 0.4198\r",
      "(2210 / 10000) training: 0.4253 | validation: 0.4198\r",
      "(2211 / 10000) training: 0.4253 | validation: 0.4198\r",
      "(2212 / 10000) training: 0.4253 | validation: 0.4198\r",
      "(2213 / 10000) training: 0.4253 | validation: 0.4197\r",
      "(2214 / 10000) training: 0.4253 | validation: 0.4197\r",
      "(2215 / 10000) training: 0.4253 | validation: 0.4197\r",
      "(2216 / 10000) training: 0.4253 | validation: 0.4197\r",
      "(2217 / 10000) training: 0.4252 | validation: 0.4197\r",
      "(2218 / 10000) training: 0.4252 | validation: 0.4197\r",
      "(2219 / 10000) training: 0.4252 | validation: 0.4197\r",
      "(2220 / 10000) training: 0.4252 | validation: 0.4197\r",
      "(2221 / 10000) training: 0.4252 | validation: 0.4197\r",
      "(2222 / 10000) training: 0.4252 | validation: 0.4197\r",
      "(2223 / 10000) training: 0.4252 | validation: 0.4197\r",
      "(2224 / 10000) training: 0.4252 | validation: 0.4196\r",
      "(2225 / 10000) training: 0.4252 | validation: 0.4196\r",
      "(2226 / 10000) training: 0.4252 | validation: 0.4196\r",
      "(2227 / 10000) training: 0.4252 | validation: 0.4196\r",
      "(2228 / 10000) training: 0.4251 | validation: 0.4196\r",
      "(2229 / 10000) training: 0.4251 | validation: 0.4196\r",
      "(2230 / 10000) training: 0.4251 | validation: 0.4196\r",
      "(2231 / 10000) training: 0.4251 | validation: 0.4196\r",
      "(2232 / 10000) training: 0.4251 | validation: 0.4196\r",
      "(2233 / 10000) training: 0.4251 | validation: 0.4196\r",
      "(2234 / 10000) training: 0.4251 | validation: 0.4196\r",
      "(2235 / 10000) training: 0.4251 | validation: 0.4195\r",
      "(2236 / 10000) training: 0.4251 | validation: 0.4195\r",
      "(2237 / 10000) training: 0.4251 | validation: 0.4195\r",
      "(2238 / 10000) training: 0.4251 | validation: 0.4195\r",
      "(2239 / 10000) training: 0.4251 | validation: 0.4195\r",
      "(2240 / 10000) training: 0.4250 | validation: 0.4195\r",
      "(2241 / 10000) training: 0.4250 | validation: 0.4195\r",
      "(2242 / 10000) training: 0.4250 | validation: 0.4195\r",
      "(2243 / 10000) training: 0.4250 | validation: 0.4195\r",
      "(2244 / 10000) training: 0.4250 | validation: 0.4195\r",
      "(2245 / 10000) training: 0.4250 | validation: 0.4195\r",
      "(2246 / 10000) training: 0.4250 | validation: 0.4195\r",
      "(2247 / 10000) training: 0.4250 | validation: 0.4194\r",
      "(2248 / 10000) training: 0.4250 | validation: 0.4194\r",
      "(2249 / 10000) training: 0.4250 | validation: 0.4194\r",
      "(2250 / 10000) training: 0.4250 | validation: 0.4194\r",
      "(2251 / 10000) training: 0.4250 | validation: 0.4194\r",
      "(2252 / 10000) training: 0.4249 | validation: 0.4194\r",
      "(2253 / 10000) training: 0.4249 | validation: 0.4194\r",
      "(2254 / 10000) training: 0.4249 | validation: 0.4194\r",
      "(2255 / 10000) training: 0.4249 | validation: 0.4194\r",
      "(2256 / 10000) training: 0.4249 | validation: 0.4194\r",
      "(2257 / 10000) training: 0.4249 | validation: 0.4194\r",
      "(2258 / 10000) training: 0.4249 | validation: 0.4194\r",
      "(2259 / 10000) training: 0.4249 | validation: 0.4193\r",
      "(2260 / 10000) training: 0.4249 | validation: 0.4193\r",
      "(2261 / 10000) training: 0.4249 | validation: 0.4193\r",
      "(2262 / 10000) training: 0.4249 | validation: 0.4193\r",
      "(2263 / 10000) training: 0.4249 | validation: 0.4193\r",
      "(2264 / 10000) training: 0.4249 | validation: 0.4193\r",
      "(2265 / 10000) training: 0.4248 | validation: 0.4193\r",
      "(2266 / 10000) training: 0.4248 | validation: 0.4193\r",
      "(2267 / 10000) training: 0.4248 | validation: 0.4193\r",
      "(2268 / 10000) training: 0.4248 | validation: 0.4193\r",
      "(2269 / 10000) training: 0.4248 | validation: 0.4193\r",
      "(2270 / 10000) training: 0.4248 | validation: 0.4193\r",
      "(2271 / 10000) training: 0.4248 | validation: 0.4192\r",
      "(2272 / 10000) training: 0.4248 | validation: 0.4192\r",
      "(2273 / 10000) training: 0.4248 | validation: 0.4192\r",
      "(2274 / 10000) training: 0.4248 | validation: 0.4192\r",
      "(2275 / 10000) training: 0.4248 | validation: 0.4192\r",
      "(2276 / 10000) training: 0.4248 | validation: 0.4192\r",
      "(2277 / 10000) training: 0.4247 | validation: 0.4192\r",
      "(2278 / 10000) training: 0.4247 | validation: 0.4192\r",
      "(2279 / 10000) training: 0.4247 | validation: 0.4192\r",
      "(2280 / 10000) training: 0.4247 | validation: 0.4192\r",
      "(2281 / 10000) training: 0.4247 | validation: 0.4192\r",
      "(2282 / 10000) training: 0.4247 | validation: 0.4192\r",
      "(2283 / 10000) training: 0.4247 | validation: 0.4191\r",
      "(2284 / 10000) training: 0.4247 | validation: 0.4191\r",
      "(2285 / 10000) training: 0.4247 | validation: 0.4191\r",
      "(2286 / 10000) training: 0.4247 | validation: 0.4191\r",
      "(2287 / 10000) training: 0.4247 | validation: 0.4191\r",
      "(2288 / 10000) training: 0.4247 | validation: 0.4191\r",
      "(2289 / 10000) training: 0.4247 | validation: 0.4191\r",
      "(2290 / 10000) training: 0.4246 | validation: 0.4191\r",
      "(2291 / 10000) training: 0.4246 | validation: 0.4191\r",
      "(2292 / 10000) training: 0.4246 | validation: 0.4191\r",
      "(2293 / 10000) training: 0.4246 | validation: 0.4191\r",
      "(2294 / 10000) training: 0.4246 | validation: 0.4191\r",
      "(2295 / 10000) training: 0.4246 | validation: 0.4190\r",
      "(2296 / 10000) training: 0.4246 | validation: 0.4190\r",
      "(2297 / 10000) training: 0.4246 | validation: 0.4190\r",
      "(2298 / 10000) training: 0.4246 | validation: 0.4190\r",
      "(2299 / 10000) training: 0.4246 | validation: 0.4190\r",
      "(2300 / 10000) training: 0.4246 | validation: 0.4190\r",
      "(2301 / 10000) training: 0.4246 | validation: 0.4190\r",
      "(2302 / 10000) training: 0.4245 | validation: 0.4190\r",
      "(2303 / 10000) training: 0.4245 | validation: 0.4190\r",
      "(2304 / 10000) training: 0.4245 | validation: 0.4190\r",
      "(2305 / 10000) training: 0.4245 | validation: 0.4190\r",
      "(2306 / 10000) training: 0.4245 | validation: 0.4190\r",
      "(2307 / 10000) training: 0.4245 | validation: 0.4189\r",
      "(2308 / 10000) training: 0.4245 | validation: 0.4189\r",
      "(2309 / 10000) training: 0.4245 | validation: 0.4189\r",
      "(2310 / 10000) training: 0.4245 | validation: 0.4189\r",
      "(2311 / 10000) training: 0.4245 | validation: 0.4189\r",
      "(2312 / 10000) training: 0.4245 | validation: 0.4189\r",
      "(2313 / 10000) training: 0.4245 | validation: 0.4189\r",
      "(2314 / 10000) training: 0.4245 | validation: 0.4189\r",
      "(2315 / 10000) training: 0.4244 | validation: 0.4189\r",
      "(2316 / 10000) training: 0.4244 | validation: 0.4189\r",
      "(2317 / 10000) training: 0.4244 | validation: 0.4189\r",
      "(2318 / 10000) training: 0.4244 | validation: 0.4189\r",
      "(2319 / 10000) training: 0.4244 | validation: 0.4189\r",
      "(2320 / 10000) training: 0.4244 | validation: 0.4188\r",
      "(2321 / 10000) training: 0.4244 | validation: 0.4188\r",
      "(2322 / 10000) training: 0.4244 | validation: 0.4188\r",
      "(2323 / 10000) training: 0.4244 | validation: 0.4188\r",
      "(2324 / 10000) training: 0.4244 | validation: 0.4188\r",
      "(2325 / 10000) training: 0.4244 | validation: 0.4188\r",
      "(2326 / 10000) training: 0.4244 | validation: 0.4188\r",
      "(2327 / 10000) training: 0.4244 | validation: 0.4188\r",
      "(2328 / 10000) training: 0.4243 | validation: 0.4188\r",
      "(2329 / 10000) training: 0.4243 | validation: 0.4188\r",
      "(2330 / 10000) training: 0.4243 | validation: 0.4188\r",
      "(2331 / 10000) training: 0.4243 | validation: 0.4188"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "(2332 / 10000) training: 0.4243 | validation: 0.4187\r",
      "(2333 / 10000) training: 0.4243 | validation: 0.4187\r",
      "(2334 / 10000) training: 0.4243 | validation: 0.4187\r",
      "(2335 / 10000) training: 0.4243 | validation: 0.4187\r",
      "(2336 / 10000) training: 0.4243 | validation: 0.4187\r",
      "(2337 / 10000) training: 0.4243 | validation: 0.4187\r",
      "(2338 / 10000) training: 0.4243 | validation: 0.4187\r",
      "(2339 / 10000) training: 0.4243 | validation: 0.4187\r",
      "(2340 / 10000) training: 0.4243 | validation: 0.4187\r",
      "(2341 / 10000) training: 0.4243 | validation: 0.4187\r",
      "(2342 / 10000) training: 0.4242 | validation: 0.4187\r",
      "(2343 / 10000) training: 0.4242 | validation: 0.4187\r",
      "(2344 / 10000) training: 0.4242 | validation: 0.4187\r",
      "(2345 / 10000) training: 0.4242 | validation: 0.4186\r",
      "(2346 / 10000) training: 0.4242 | validation: 0.4186\r",
      "(2347 / 10000) training: 0.4242 | validation: 0.4186\r",
      "(2348 / 10000) training: 0.4242 | validation: 0.4186\r",
      "(2349 / 10000) training: 0.4242 | validation: 0.4186\r",
      "(2350 / 10000) training: 0.4242 | validation: 0.4186\r",
      "(2351 / 10000) training: 0.4242 | validation: 0.4186\r",
      "(2352 / 10000) training: 0.4242 | validation: 0.4186\r",
      "(2353 / 10000) training: 0.4242 | validation: 0.4186\r",
      "(2354 / 10000) training: 0.4242 | validation: 0.4186\r",
      "(2355 / 10000) training: 0.4241 | validation: 0.4186\r",
      "(2356 / 10000) training: 0.4241 | validation: 0.4186\r",
      "(2357 / 10000) training: 0.4241 | validation: 0.4186\r",
      "(2358 / 10000) training: 0.4241 | validation: 0.4185\r",
      "(2359 / 10000) training: 0.4241 | validation: 0.4185\r",
      "(2360 / 10000) training: 0.4241 | validation: 0.4185\r",
      "(2361 / 10000) training: 0.4241 | validation: 0.4185\r",
      "(2362 / 10000) training: 0.4241 | validation: 0.4185\r",
      "(2363 / 10000) training: 0.4241 | validation: 0.4185\r",
      "(2364 / 10000) training: 0.4241 | validation: 0.4185\r",
      "(2365 / 10000) training: 0.4241 | validation: 0.4185\r",
      "(2366 / 10000) training: 0.4241 | validation: 0.4185\r",
      "(2367 / 10000) training: 0.4241 | validation: 0.4185\r",
      "(2368 / 10000) training: 0.4241 | validation: 0.4185\r",
      "(2369 / 10000) training: 0.4240 | validation: 0.4185\r",
      "(2370 / 10000) training: 0.4240 | validation: 0.4185\r",
      "(2371 / 10000) training: 0.4240 | validation: 0.4184\r",
      "(2372 / 10000) training: 0.4240 | validation: 0.4184\r",
      "(2373 / 10000) training: 0.4240 | validation: 0.4184\r",
      "(2374 / 10000) training: 0.4240 | validation: 0.4184\r",
      "(2375 / 10000) training: 0.4240 | validation: 0.4184\r",
      "(2376 / 10000) training: 0.4240 | validation: 0.4184\r",
      "(2377 / 10000) training: 0.4240 | validation: 0.4184\r",
      "(2378 / 10000) training: 0.4240 | validation: 0.4184\r",
      "(2379 / 10000) training: 0.4240 | validation: 0.4184\r",
      "(2380 / 10000) training: 0.4240 | validation: 0.4184\r",
      "(2381 / 10000) training: 0.4240 | validation: 0.4184\r",
      "(2382 / 10000) training: 0.4239 | validation: 0.4184\r",
      "(2383 / 10000) training: 0.4239 | validation: 0.4184\r",
      "(2384 / 10000) training: 0.4239 | validation: 0.4184\r",
      "(2385 / 10000) training: 0.4239 | validation: 0.4183\r",
      "(2386 / 10000) training: 0.4239 | validation: 0.4183\r",
      "(2387 / 10000) training: 0.4239 | validation: 0.4183\r",
      "(2388 / 10000) training: 0.4239 | validation: 0.4183\r",
      "(2389 / 10000) training: 0.4239 | validation: 0.4183\r",
      "(2390 / 10000) training: 0.4239 | validation: 0.4183\r",
      "(2391 / 10000) training: 0.4239 | validation: 0.4183\r",
      "(2392 / 10000) training: 0.4239 | validation: 0.4183\r",
      "(2393 / 10000) training: 0.4239 | validation: 0.4183\r",
      "(2394 / 10000) training: 0.4239 | validation: 0.4183\r",
      "(2395 / 10000) training: 0.4239 | validation: 0.4183\r",
      "(2396 / 10000) training: 0.4238 | validation: 0.4183\r",
      "(2397 / 10000) training: 0.4238 | validation: 0.4183\r",
      "(2398 / 10000) training: 0.4238 | validation: 0.4182\r",
      "(2399 / 10000) training: 0.4238 | validation: 0.4182\r",
      "(2400 / 10000) training: 0.4238 | validation: 0.4182\r",
      "(2401 / 10000) training: 0.4238 | validation: 0.4182\r",
      "(2402 / 10000) training: 0.4238 | validation: 0.4182\r",
      "(2403 / 10000) training: 0.4238 | validation: 0.4182\r",
      "(2404 / 10000) training: 0.4238 | validation: 0.4182\r",
      "(2405 / 10000) training: 0.4238 | validation: 0.4182\r",
      "(2406 / 10000) training: 0.4238 | validation: 0.4182\r",
      "(2407 / 10000) training: 0.4238 | validation: 0.4182\r",
      "(2408 / 10000) training: 0.4238 | validation: 0.4182\r",
      "(2409 / 10000) training: 0.4238 | validation: 0.4182\r",
      "(2410 / 10000) training: 0.4238 | validation: 0.4182\r",
      "(2411 / 10000) training: 0.4237 | validation: 0.4182\r",
      "(2412 / 10000) training: 0.4237 | validation: 0.4181\r",
      "(2413 / 10000) training: 0.4237 | validation: 0.4181\r",
      "(2414 / 10000) training: 0.4237 | validation: 0.4181\r",
      "(2415 / 10000) training: 0.4237 | validation: 0.4181\r",
      "(2416 / 10000) training: 0.4237 | validation: 0.4181\r",
      "(2417 / 10000) training: 0.4237 | validation: 0.4181\r",
      "(2418 / 10000) training: 0.4237 | validation: 0.4181\r",
      "(2419 / 10000) training: 0.4237 | validation: 0.4181\r",
      "(2420 / 10000) training: 0.4237 | validation: 0.4181\r",
      "(2421 / 10000) training: 0.4237 | validation: 0.4181\r",
      "(2422 / 10000) training: 0.4237 | validation: 0.4181\r",
      "(2423 / 10000) training: 0.4237 | validation: 0.4181\r",
      "(2424 / 10000) training: 0.4237 | validation: 0.4181\r",
      "(2425 / 10000) training: 0.4236 | validation: 0.4181\r",
      "(2426 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2427 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2428 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2429 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2430 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2431 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2432 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2433 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2434 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2435 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2436 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2437 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2438 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2439 / 10000) training: 0.4236 | validation: 0.4180\r",
      "(2440 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2441 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2442 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2443 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2444 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2445 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2446 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2447 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2448 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2449 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2450 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2451 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2452 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2453 / 10000) training: 0.4235 | validation: 0.4179\r",
      "(2454 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2455 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2456 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2457 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2458 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2459 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2460 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2461 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2462 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2463 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2464 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2465 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2466 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2467 / 10000) training: 0.4234 | validation: 0.4178\r",
      "(2468 / 10000) training: 0.4234 | validation: 0.4177\r",
      "(2469 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2470 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2471 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2472 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2473 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2474 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2475 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2476 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2477 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2478 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2479 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2480 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2481 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2482 / 10000) training: 0.4233 | validation: 0.4177\r",
      "(2483 / 10000) training: 0.4233 | validation: 0.4176\r",
      "(2484 / 10000) training: 0.4233 | validation: 0.4176\r",
      "(2485 / 10000) training: 0.4232 | validation: 0.4176\r",
      "(2486 / 10000) training: 0.4232 | validation: 0.4176\r",
      "(2487 / 10000) training: 0.4232 | validation: 0.4176\r",
      "(2488 / 10000) training: 0.4232 | validation: 0.4176\r",
      "(2489 / 10000) training: 0.4232 | validation: 0.4176\r",
      "(2490 / 10000) training: 0.4232 | validation: 0.4176\r",
      "(2491 / 10000) training: 0.4232 | validation: 0.4176\r",
      "(2492 / 10000) training: 0.4232 | validation: 0.4176\r",
      "(2493 / 10000) training: 0.4232 | validation: 0.4176\r",
      "(2494 / 10000) training: 0.4232 | validation: 0.4176\r",
      "(2495 / 10000) training: 0.4232 | validation: 0.4176\r",
      "(2496 / 10000) training: 0.4232 | validation: 0.4176\r",
      "(2497 / 10000) training: 0.4232 | validation: 0.4176\r",
      "(2498 / 10000) training: 0.4232 | validation: 0.4175\r",
      "(2499 / 10000) training: 0.4232 | validation: 0.4175\r",
      "(2500 / 10000) training: 0.4231 | validation: 0.4175\r",
      "(2501 / 10000) training: 0.4231 | validation: 0.4175\r",
      "(2502 / 10000) training: 0.4231 | validation: 0.4175\r",
      "(2503 / 10000) training: 0.4231 | validation: 0.4175\r",
      "(2504 / 10000) training: 0.4231 | validation: 0.4175\r",
      "(2505 / 10000) training: 0.4231 | validation: 0.4175\r",
      "(2506 / 10000) training: 0.4231 | validation: 0.4175\r",
      "(2507 / 10000) training: 0.4231 | validation: 0.4175\r",
      "(2508 / 10000) training: 0.4231 | validation: 0.4175\r",
      "(2509 / 10000) training: 0.4231 | validation: 0.4175\r",
      "(2510 / 10000) training: 0.4231 | validation: 0.4175\r",
      "(2511 / 10000) training: 0.4231 | validation: 0.4175\r",
      "(2512 / 10000) training: 0.4231 | validation: 0.4175\r",
      "(2513 / 10000) training: 0.4231 | validation: 0.4174\r",
      "(2514 / 10000) training: 0.4231 | validation: 0.4174\r",
      "(2515 / 10000) training: 0.4231 | validation: 0.4174\r",
      "(2516 / 10000) training: 0.4230 | validation: 0.4174\r",
      "(2517 / 10000) training: 0.4230 | validation: 0.4174\r",
      "(2518 / 10000) training: 0.4230 | validation: 0.4174\r",
      "(2519 / 10000) training: 0.4230 | validation: 0.4174\r",
      "(2520 / 10000) training: 0.4230 | validation: 0.4174\r",
      "(2521 / 10000) training: 0.4230 | validation: 0.4174\r",
      "(2522 / 10000) training: 0.4230 | validation: 0.4174\r",
      "(2523 / 10000) training: 0.4230 | validation: 0.4174\r",
      "(2524 / 10000) training: 0.4230 | validation: 0.4174\r",
      "(2525 / 10000) training: 0.4230 | validation: 0.4174\r",
      "(2526 / 10000) training: 0.4230 | validation: 0.4174\r",
      "(2527 / 10000) training: 0.4230 | validation: 0.4174\r",
      "(2528 / 10000) training: 0.4230 | validation: 0.4173\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2529 / 10000) training: 0.4230 | validation: 0.4173\r",
      "(2530 / 10000) training: 0.4230 | validation: 0.4173\r",
      "(2531 / 10000) training: 0.4230 | validation: 0.4173\r",
      "(2532 / 10000) training: 0.4229 | validation: 0.4173\r",
      "(2533 / 10000) training: 0.4229 | validation: 0.4173\r",
      "(2534 / 10000) training: 0.4229 | validation: 0.4173\r",
      "(2535 / 10000) training: 0.4229 | validation: 0.4173\r",
      "(2536 / 10000) training: 0.4229 | validation: 0.4173\r",
      "(2537 / 10000) training: 0.4229 | validation: 0.4173\r",
      "(2538 / 10000) training: 0.4229 | validation: 0.4173\r",
      "(2539 / 10000) training: 0.4229 | validation: 0.4173\r",
      "(2540 / 10000) training: 0.4229 | validation: 0.4173\r",
      "(2541 / 10000) training: 0.4229 | validation: 0.4173\r",
      "(2542 / 10000) training: 0.4229 | validation: 0.4173\r",
      "(2543 / 10000) training: 0.4229 | validation: 0.4173\r",
      "(2544 / 10000) training: 0.4229 | validation: 0.4172\r",
      "(2545 / 10000) training: 0.4229 | validation: 0.4172\r",
      "(2546 / 10000) training: 0.4229 | validation: 0.4172\r",
      "(2547 / 10000) training: 0.4229 | validation: 0.4172\r",
      "(2548 / 10000) training: 0.4228 | validation: 0.4172\r",
      "(2549 / 10000) training: 0.4228 | validation: 0.4172\r",
      "(2550 / 10000) training: 0.4228 | validation: 0.4172\r",
      "(2551 / 10000) training: 0.4228 | validation: 0.4172\r",
      "(2552 / 10000) training: 0.4228 | validation: 0.4172\r",
      "(2553 / 10000) training: 0.4228 | validation: 0.4172\r",
      "(2554 / 10000) training: 0.4228 | validation: 0.4172\r",
      "(2555 / 10000) training: 0.4228 | validation: 0.4172\r",
      "(2556 / 10000) training: 0.4228 | validation: 0.4172\r",
      "(2557 / 10000) training: 0.4228 | validation: 0.4172\r",
      "(2558 / 10000) training: 0.4228 | validation: 0.4172\r",
      "(2559 / 10000) training: 0.4228 | validation: 0.4172\r",
      "(2560 / 10000) training: 0.4228 | validation: 0.4171\r",
      "(2561 / 10000) training: 0.4228 | validation: 0.4171\r",
      "(2562 / 10000) training: 0.4228 | validation: 0.4171\r",
      "(2563 / 10000) training: 0.4228 | validation: 0.4171\r",
      "(2564 / 10000) training: 0.4228 | validation: 0.4171\r",
      "(2565 / 10000) training: 0.4227 | validation: 0.4171\r",
      "(2566 / 10000) training: 0.4227 | validation: 0.4171\r",
      "(2567 / 10000) training: 0.4227 | validation: 0.4171\r",
      "(2568 / 10000) training: 0.4227 | validation: 0.4171\r",
      "(2569 / 10000) training: 0.4227 | validation: 0.4171\r",
      "(2570 / 10000) training: 0.4227 | validation: 0.4171\r",
      "(2571 / 10000) training: 0.4227 | validation: 0.4171\r",
      "(2572 / 10000) training: 0.4227 | validation: 0.4171\r",
      "(2573 / 10000) training: 0.4227 | validation: 0.4171\r",
      "(2574 / 10000) training: 0.4227 | validation: 0.4171\r",
      "(2575 / 10000) training: 0.4227 | validation: 0.4171\r",
      "(2576 / 10000) training: 0.4227 | validation: 0.4170\r",
      "(2577 / 10000) training: 0.4227 | validation: 0.4170\r",
      "(2578 / 10000) training: 0.4227 | validation: 0.4170\r",
      "(2579 / 10000) training: 0.4227 | validation: 0.4170\r",
      "(2580 / 10000) training: 0.4227 | validation: 0.4170\r",
      "(2581 / 10000) training: 0.4227 | validation: 0.4170\r",
      "(2582 / 10000) training: 0.4226 | validation: 0.4170\r",
      "(2583 / 10000) training: 0.4226 | validation: 0.4170\r",
      "(2584 / 10000) training: 0.4226 | validation: 0.4170\r",
      "(2585 / 10000) training: 0.4226 | validation: 0.4170\r",
      "(2586 / 10000) training: 0.4226 | validation: 0.4170\r",
      "(2587 / 10000) training: 0.4226 | validation: 0.4170\r",
      "(2588 / 10000) training: 0.4226 | validation: 0.4170\r",
      "(2589 / 10000) training: 0.4226 | validation: 0.4170\r",
      "(2590 / 10000) training: 0.4226 | validation: 0.4170\r",
      "(2591 / 10000) training: 0.4226 | validation: 0.4170\r",
      "(2592 / 10000) training: 0.4226 | validation: 0.4169\r",
      "(2593 / 10000) training: 0.4226 | validation: 0.4169\r",
      "(2594 / 10000) training: 0.4226 | validation: 0.4169\r",
      "(2595 / 10000) training: 0.4226 | validation: 0.4169\r",
      "(2596 / 10000) training: 0.4226 | validation: 0.4169\r",
      "(2597 / 10000) training: 0.4226 | validation: 0.4169\r",
      "(2598 / 10000) training: 0.4226 | validation: 0.4169\r",
      "(2599 / 10000) training: 0.4225 | validation: 0.4169\r",
      "(2600 / 10000) training: 0.4225 | validation: 0.4169\r",
      "(2601 / 10000) training: 0.4225 | validation: 0.4169\r",
      "(2602 / 10000) training: 0.4225 | validation: 0.4169\r",
      "(2603 / 10000) training: 0.4225 | validation: 0.4169\r",
      "(2604 / 10000) training: 0.4225 | validation: 0.4169\r",
      "(2605 / 10000) training: 0.4225 | validation: 0.4169\r",
      "(2606 / 10000) training: 0.4225 | validation: 0.4169\r",
      "(2607 / 10000) training: 0.4225 | validation: 0.4169\r",
      "(2608 / 10000) training: 0.4225 | validation: 0.4169\r",
      "(2609 / 10000) training: 0.4225 | validation: 0.4168\r",
      "(2610 / 10000) training: 0.4225 | validation: 0.4168\r",
      "(2611 / 10000) training: 0.4225 | validation: 0.4168\r",
      "(2612 / 10000) training: 0.4225 | validation: 0.4168\r",
      "(2613 / 10000) training: 0.4225 | validation: 0.4168\r",
      "(2614 / 10000) training: 0.4225 | validation: 0.4168\r",
      "(2615 / 10000) training: 0.4225 | validation: 0.4168\r",
      "(2616 / 10000) training: 0.4224 | validation: 0.4168\r",
      "(2617 / 10000) training: 0.4224 | validation: 0.4168\r",
      "(2618 / 10000) training: 0.4224 | validation: 0.4168\r",
      "(2619 / 10000) training: 0.4224 | validation: 0.4168\r",
      "(2620 / 10000) training: 0.4224 | validation: 0.4168\r",
      "(2621 / 10000) training: 0.4224 | validation: 0.4168\r",
      "(2622 / 10000) training: 0.4224 | validation: 0.4168\r",
      "(2623 / 10000) training: 0.4224 | validation: 0.4168\r",
      "(2624 / 10000) training: 0.4224 | validation: 0.4168\r",
      "(2625 / 10000) training: 0.4224 | validation: 0.4168\r",
      "(2626 / 10000) training: 0.4224 | validation: 0.4167\r",
      "(2627 / 10000) training: 0.4224 | validation: 0.4167\r",
      "(2628 / 10000) training: 0.4224 | validation: 0.4167\r",
      "(2629 / 10000) training: 0.4224 | validation: 0.4167\r",
      "(2630 / 10000) training: 0.4224 | validation: 0.4167\r",
      "(2631 / 10000) training: 0.4224 | validation: 0.4167\r",
      "(2632 / 10000) training: 0.4224 | validation: 0.4167\r",
      "(2633 / 10000) training: 0.4224 | validation: 0.4167\r",
      "(2634 / 10000) training: 0.4223 | validation: 0.4167\r",
      "(2635 / 10000) training: 0.4223 | validation: 0.4167\r",
      "(2636 / 10000) training: 0.4223 | validation: 0.4167\r",
      "(2637 / 10000) training: 0.4223 | validation: 0.4167\r",
      "(2638 / 10000) training: 0.4223 | validation: 0.4167\r",
      "(2639 / 10000) training: 0.4223 | validation: 0.4167\r",
      "(2640 / 10000) training: 0.4223 | validation: 0.4167\r",
      "(2641 / 10000) training: 0.4223 | validation: 0.4167\r",
      "(2642 / 10000) training: 0.4223 | validation: 0.4167\r",
      "(2643 / 10000) training: 0.4223 | validation: 0.4166\r",
      "(2644 / 10000) training: 0.4223 | validation: 0.4166\r",
      "(2645 / 10000) training: 0.4223 | validation: 0.4166\r",
      "(2646 / 10000) training: 0.4223 | validation: 0.4166\r",
      "(2647 / 10000) training: 0.4223 | validation: 0.4166\r",
      "(2648 / 10000) training: 0.4223 | validation: 0.4166\r",
      "(2649 / 10000) training: 0.4223 | validation: 0.4166\r",
      "(2650 / 10000) training: 0.4223 | validation: 0.4166\r",
      "(2651 / 10000) training: 0.4223 | validation: 0.4166\r",
      "(2652 / 10000) training: 0.4222 | validation: 0.4166\r",
      "(2653 / 10000) training: 0.4222 | validation: 0.4166\r",
      "(2654 / 10000) training: 0.4222 | validation: 0.4166\r",
      "(2655 / 10000) training: 0.4222 | validation: 0.4166\r",
      "(2656 / 10000) training: 0.4222 | validation: 0.4166\r",
      "(2657 / 10000) training: 0.4222 | validation: 0.4166\r",
      "(2658 / 10000) training: 0.4222 | validation: 0.4166\r",
      "(2659 / 10000) training: 0.4222 | validation: 0.4166\r",
      "(2660 / 10000) training: 0.4222 | validation: 0.4165\r",
      "(2661 / 10000) training: 0.4222 | validation: 0.4165\r",
      "(2662 / 10000) training: 0.4222 | validation: 0.4165\r",
      "(2663 / 10000) training: 0.4222 | validation: 0.4165\r",
      "(2664 / 10000) training: 0.4222 | validation: 0.4165\r",
      "(2665 / 10000) training: 0.4222 | validation: 0.4165\r",
      "(2666 / 10000) training: 0.4222 | validation: 0.4165\r",
      "(2667 / 10000) training: 0.4222 | validation: 0.4165\r",
      "(2668 / 10000) training: 0.4222 | validation: 0.4165\r",
      "(2669 / 10000) training: 0.4222 | validation: 0.4165\r",
      "(2670 / 10000) training: 0.4222 | validation: 0.4165\r",
      "(2671 / 10000) training: 0.4221 | validation: 0.4165\r",
      "(2672 / 10000) training: 0.4221 | validation: 0.4165\r",
      "(2673 / 10000) training: 0.4221 | validation: 0.4165\r",
      "(2674 / 10000) training: 0.4221 | validation: 0.4165\r",
      "(2675 / 10000) training: 0.4221 | validation: 0.4165\r",
      "(2676 / 10000) training: 0.4221 | validation: 0.4165\r",
      "(2677 / 10000) training: 0.4221 | validation: 0.4165\r",
      "(2678 / 10000) training: 0.4221 | validation: 0.4164\r",
      "(2679 / 10000) training: 0.4221 | validation: 0.4164\r",
      "(2680 / 10000) training: 0.4221 | validation: 0.4164\r",
      "(2681 / 10000) training: 0.4221 | validation: 0.4164\r",
      "(2682 / 10000) training: 0.4221 | validation: 0.4164\r",
      "(2683 / 10000) training: 0.4221 | validation: 0.4164\r",
      "(2684 / 10000) training: 0.4221 | validation: 0.4164\r",
      "(2685 / 10000) training: 0.4221 | validation: 0.4164\r",
      "(2686 / 10000) training: 0.4221 | validation: 0.4164\r",
      "(2687 / 10000) training: 0.4221 | validation: 0.4164\r",
      "(2688 / 10000) training: 0.4221 | validation: 0.4164\r",
      "(2689 / 10000) training: 0.4221 | validation: 0.4164\r",
      "(2690 / 10000) training: 0.4220 | validation: 0.4164\r",
      "(2691 / 10000) training: 0.4220 | validation: 0.4164\r",
      "(2692 / 10000) training: 0.4220 | validation: 0.4164\r",
      "(2693 / 10000) training: 0.4220 | validation: 0.4164\r",
      "(2694 / 10000) training: 0.4220 | validation: 0.4164\r",
      "(2695 / 10000) training: 0.4220 | validation: 0.4164\r",
      "(2696 / 10000) training: 0.4220 | validation: 0.4163\r",
      "(2697 / 10000) training: 0.4220 | validation: 0.4163\r",
      "(2698 / 10000) training: 0.4220 | validation: 0.4163\r",
      "(2699 / 10000) training: 0.4220 | validation: 0.4163\r",
      "(2700 / 10000) training: 0.4220 | validation: 0.4163\r",
      "(2701 / 10000) training: 0.4220 | validation: 0.4163\r",
      "(2702 / 10000) training: 0.4220 | validation: 0.4163\r",
      "(2703 / 10000) training: 0.4220 | validation: 0.4163\r",
      "(2704 / 10000) training: 0.4220 | validation: 0.4163\r",
      "(2705 / 10000) training: 0.4220 | validation: 0.4163\r",
      "(2706 / 10000) training: 0.4220 | validation: 0.4163\r",
      "(2707 / 10000) training: 0.4220 | validation: 0.4163\r",
      "(2708 / 10000) training: 0.4220 | validation: 0.4163\r",
      "(2709 / 10000) training: 0.4219 | validation: 0.4163\r",
      "(2710 / 10000) training: 0.4219 | validation: 0.4163\r",
      "(2711 / 10000) training: 0.4219 | validation: 0.4163\r",
      "(2712 / 10000) training: 0.4219 | validation: 0.4163\r",
      "(2713 / 10000) training: 0.4219 | validation: 0.4163\r",
      "(2714 / 10000) training: 0.4219 | validation: 0.4162\r",
      "(2715 / 10000) training: 0.4219 | validation: 0.4162\r",
      "(2716 / 10000) training: 0.4219 | validation: 0.4162\r",
      "(2717 / 10000) training: 0.4219 | validation: 0.4162\r",
      "(2718 / 10000) training: 0.4219 | validation: 0.4162\r",
      "(2719 / 10000) training: 0.4219 | validation: 0.4162\r",
      "(2720 / 10000) training: 0.4219 | validation: 0.4162\r",
      "(2721 / 10000) training: 0.4219 | validation: 0.4162\r",
      "(2722 / 10000) training: 0.4219 | validation: 0.4162\r",
      "(2723 / 10000) training: 0.4219 | validation: 0.4162\r",
      "(2724 / 10000) training: 0.4219 | validation: 0.4162\r",
      "(2725 / 10000) training: 0.4219 | validation: 0.4162\r",
      "(2726 / 10000) training: 0.4219 | validation: 0.4162"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000 / 10000) training: 0.4160 | validation: 0.4100\n",
      "\n",
      "Best validation loss: 0.410024 (at epoch 10000)\n"
     ]
    }
   ],
   "source": [
    "vanilla_run = run_GD(learning_rate=0.0005, n_epochs=10000, GD_flavor=\"vanilla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_GD_run(*vanilla_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000 / 1000) training: 0.4131 | validation: 0.4085\n",
      "\n",
      "Best validation loss: 0.408471 (at epoch 486)\n"
     ]
    }
   ],
   "source": [
    "mini_batch_run = run_GD(learning_rate=0.0005, n_epochs=1000, GD_flavor=\"mini batch\", batch_size=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_GD_run(*mini_batch_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200 / 200) training: 0.4133 | validation: 0.4086\n",
      "\n",
      "Best validation loss: 0.408161 (at epoch 13)\n"
     ]
    }
   ],
   "source": [
    "stochastic_run = run_GD(learning_rate=0.0005, n_epochs=200, GD_flavor=\"stochastic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_GD_run(*stochastic_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 Learning rate of ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
